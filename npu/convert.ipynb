{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from torch to tflite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# set cuda device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from npu.converter import Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolo\n",
    "\n",
    "see also ultralytics/customizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "MODEL_FOLDER = \"/mnt/ssd2/xxx/repo/ultralytics/customization\"\n",
    "MODEL_NAMES = MODEL_NAMES = [\n",
    "    \"yolov8n\",\n",
    "    \"yolov8s\",\n",
    "    \"yolov8m\",\n",
    "    \"yolov8l\",\n",
    "    \"yolov8x\",\n",
    "    \"yolo11n\",\n",
    "    \"yolo11s\",\n",
    "    \"yolo11m\",\n",
    "    \"yolo11l\",\n",
    "    \"yolo11x\",\n",
    "]\n",
    "for model_name in MODEL_NAMES:\n",
    "    model_path = os.path.join(MODEL_FOLDER, model_name + \".pt\")\n",
    "    model = YOLO(model_path).model\n",
    "\n",
    "    image_size = (320, 320)\n",
    "    model_name = f\"{model_name}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initilized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobilenetv4FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs_list = [\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "]\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for num_outs in num_outs_list:\n",
    "    for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "        backbone_value = backbone_dict[backbone_key]\n",
    "        model = OCDFPN(\n",
    "            backbone=backbone_value,\n",
    "            n_classes=1,\n",
    "            num_outs=num_outs,\n",
    "            out_channel=out_channel,\n",
    "            fpn_type=fpn_type,\n",
    "        )\n",
    "\n",
    "        model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"extra_dw\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"ib\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"convnext\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs_list = [\n",
    "    3,\n",
    "    #  4,\n",
    "    5,\n",
    "]\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for num_outs in num_outs_list:\n",
    "    for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "        backbone_value = backbone_dict[backbone_key]\n",
    "        model = OCDFPN(\n",
    "            backbone=backbone_value,\n",
    "            n_classes=80,\n",
    "            num_outs=num_outs,\n",
    "            out_channel=out_channel,\n",
    "            fpn_type=fpn_type,\n",
    "        )\n",
    "\n",
    "        model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"extra_dw\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"ib\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"convnext\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobilenetv4PAFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs_list = [\n",
    "    3,\n",
    "    4,\n",
    "]\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for num_outs in num_outs_list:\n",
    "    for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "        backbone_value = backbone_dict[backbone_key]\n",
    "        model = OCDPAFPN(\n",
    "            backbone=backbone_value,\n",
    "            n_classes=1,\n",
    "            num_outs=num_outs,\n",
    "            out_channel=out_channel,\n",
    "            fpn_type=fpn_type,\n",
    "        )\n",
    "\n",
    "        model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"extra_dw\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"ib\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"convnext\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=1,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs_list = [\n",
    "    3,\n",
    "    4,\n",
    "]\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for num_outs in num_outs_list:\n",
    "    for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "        backbone_value = backbone_dict[backbone_key]\n",
    "        model = OCDPAFPN(\n",
    "            backbone=backbone_value,\n",
    "            n_classes=80,\n",
    "            num_outs=num_outs,\n",
    "            out_channel=out_channel,\n",
    "            fpn_type=fpn_type,\n",
    "        )\n",
    "\n",
    "        model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"mm\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"extra_dw\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"ib\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fpn_type: convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "num_outs = 4\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "fpn_type = \"convnext\"\n",
    "\n",
    "list_out_channel = [64, 96, 128]\n",
    "\n",
    "for out_channel, backbone_key in zip(list_out_channel, backbone_dict.keys()):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDPAFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "        fpn_type=fpn_type,\n",
    "    )\n",
    "\n",
    "    model_name = f\"pafpn_mobilenetv4_conv_{backbone_key}_{fpn_type}_o{num_outs}_oc{out_channel}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV4Unet\n",
    "\n",
    "only works with Converter1 if padding code is commented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "scales = [0.25, 0.5, 0.75]\n",
    "modes = [\"bilinear\", \"convtranspose\"]\n",
    "\n",
    "for mode in modes:\n",
    "    for scale, backbone_key in zip(scales, backbone_dict.keys()):\n",
    "        model = MobileNetV4Unet(\n",
    "            backbone=backbone_dict[backbone_key],\n",
    "            mode=mode,\n",
    "            n_classes=1,\n",
    "            width_scale=scale,\n",
    "        )\n",
    "\n",
    "        model_name = (\n",
    "            f\"unet_mobilenetv4_conv_{backbone_key}_{mode}_r{image_size[0]}_w{scale}\"\n",
    "        )\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "scales = [0.25, 0.5, 0.75]\n",
    "modes = [\"bilinear\", \"convtranspose\"]\n",
    "\n",
    "for mode in modes:\n",
    "    for scale, backbone_key in zip(scales, backbone_dict.keys()):\n",
    "        model = MobileNetV4Unet(\n",
    "            backbone=backbone_dict[backbone_key],\n",
    "            mode=mode,\n",
    "            n_classes=80,\n",
    "            width_scale=scale,\n",
    "        )\n",
    "\n",
    "        model_name = f\"unet_mobilenetv4_conv_{backbone_key}_{mode}_r{image_size[0]}_w{scale}_coco\"\n",
    "        torch_model_path = None  # use initialized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=11,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiteHRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from npu.converter import Converter\n",
    "from models.lite_hrnet import LiteHRNet30\n",
    "\n",
    "image_size = (320, 320)\n",
    "n_classes = 1\n",
    "\n",
    "model = LiteHRNet30(n_classes)\n",
    "model.eval()\n",
    "model_name = f\"lite_hrnet_30_r{image_size[0]}\"\n",
    "torch_model_path = None  # use initilized model\n",
    "onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "tf_folder_path = f\"saved_model/{model_name}\"\n",
    "tflite_model_path = onnx_model_path.replace(\".onnx\", \"_full_integer_quant_uint8.tflite\")\n",
    "calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "converter = Converter(\n",
    "    model,\n",
    "    image_size,\n",
    "    torch_model_path,\n",
    "    onnx_model_path,\n",
    "    tf_folder_path,\n",
    "    tflite_model_path,\n",
    "    calib_data_path,\n",
    "    opset_version=11,\n",
    ")\n",
    "converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV4SimpleBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "modes = [\n",
    "    \"bilinear\",\n",
    "    #  \"nearest\",\n",
    "    \"convtranspose\",\n",
    "]\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "image_size = (320, 320)\n",
    "for mode in modes:\n",
    "    for backbone_key, backbone_value in backbone_dict.items():\n",
    "        model = (\n",
    "            MobilenetV4SimpleBaseline(backbone=backbone_value, n_classes=1, mode=mode)\n",
    "            .float()\n",
    "            .eval()\n",
    "        )\n",
    "\n",
    "        model_name = f\"simple_mobilenetv4_conv_{backbone_key}_{mode}_r{image_size[0]}\"\n",
    "        torch_model_path = None  # use initilized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=13,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "modes = [\n",
    "    \"bilinear\",\n",
    "    #  \"nearest\",\n",
    "    \"convtranspose\",\n",
    "]\n",
    "backbone_dict = {\n",
    "    \"small\": \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    \"medium\": \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    \"large\": \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "}\n",
    "image_size = (320, 320)\n",
    "for mode in modes:\n",
    "    for backbone_key, backbone_value in backbone_dict.items():\n",
    "        model = (\n",
    "            MobilenetV4SimpleBaseline(backbone=backbone_value, n_classes=80, mode=mode)\n",
    "            .float()\n",
    "            .eval()\n",
    "        )\n",
    "\n",
    "        model_name = (\n",
    "            f\"simple_mobilenetv4_conv_{backbone_key}_{mode}_r{image_size[0]}_coco\"\n",
    "        )\n",
    "        torch_model_path = None  # use initilized model\n",
    "        onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "        tf_folder_path = f\"saved_model/{model_name}\"\n",
    "        tflite_model_path = onnx_model_path.replace(\n",
    "            \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "        )\n",
    "        calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "        converter = Converter(\n",
    "            model,\n",
    "            image_size,\n",
    "            torch_model_path,\n",
    "            onnx_model_path,\n",
    "            tf_folder_path,\n",
    "            tflite_model_path,\n",
    "            calib_data_path,\n",
    "            opset_version=13,\n",
    "        )\n",
    "        converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"efficientnet_b0\": \"efficientnet_b0\",\n",
    "    \"efficientnet_b3\": \"efficientnet_b3\",\n",
    "    \"efficientnet_b5\": \"efficientnet_b5\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 96, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"efficientnet_b0\": \"efficientnet_b0\",\n",
    "    \"efficientnet_b3\": \"efficientnet_b3\",\n",
    "    \"efficientnet_b5\": \"efficientnet_b5\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 96, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetV2FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"efficientnetv2_tiny\": \"efficientnetv2_rw_t\",\n",
    "    \"efficientnetv2_small\": \"efficientnetv2_rw_s\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 64]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"efficientnetv2_tiny\": \"efficientnetv2_rw_t\",\n",
    "    \"efficientnetv2_small\": \"efficientnetv2_rw_s\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 64]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=80,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RepVGGFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"repvgg_a0\": \"repvgg_a0\",\n",
    "    \"repvgg_a1\": \"repvgg_a1\",\n",
    "    \"repvgg_a2\": \"repvgg_a2\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 96, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"repvgg_b1\": \"repvgg_b1\",\n",
    "    \"repvgg_b1g4\": \"repvgg_b1g4\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [128, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"repvgg_a0\": \"repvgg_a0\",\n",
    "    \"repvgg_a1\": \"repvgg_a1\",\n",
    "    \"repvgg_a2\": \"repvgg_a2\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [32, 96, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNextFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"convnext_tiny\": \"convnext_tiny\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetOneFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"mobileone_s0\": \"mobileone_s0\",\n",
    "    \"mobileone_s4\": \"mobileone_s4\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [80, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    \"mobileone_s0\": \"mobileone_s0\",\n",
    "    \"mobileone_s4\": \"mobileone_s4\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [80, 128]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV2FPN\n",
    "\n",
    "by transformers api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import MobileNetV2FPN\n",
    "\n",
    "image_size = (320, 320)\n",
    "width_multiplier_dict = {\n",
    "    \"mobilenetv2_075\": 0.75,\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [\n",
    "    64,\n",
    "]\n",
    "\n",
    "for backbone_key, out_channel in zip(width_multiplier_dict.keys(), out_channel_list):\n",
    "    width_multiplier = width_multiplier_dict[backbone_key]\n",
    "    model = MobileNetV2FPN(\n",
    "        width_multiplier=width_multiplier,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV123FPN\n",
    "\n",
    "by timm api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    # \"mobilenetv1\": \"mobilenetv1_100\",\n",
    "    # \"mobilenetv2_050\": \"mobilenetv2_050\",\n",
    "    # \"mobilenetv2_075\": \"mobilenetv2_075\",\n",
    "    # \"mobilenetv2_100\": \"mobilenetv2_100\",\n",
    "    # \"mobilenetv2_140\": \"mobilenetv2_140\",\n",
    "    # \"mobilenetv3_small_100\": \"mobilenetv3_small_100\",\n",
    "    \"mobilenetv3_large_075\": \"mobilenetv3_large_075\",\n",
    "    # \"mobilenetv3_large_100\": \"mobilenetv3_large_100\",\n",
    "}\n",
    "n_classes = 1\n",
    "num_outs = 4\n",
    "out_channel_list = [\n",
    "    # # 16,\n",
    "    # 64,\n",
    "    # 64,\n",
    "    # 64,\n",
    "    # 128,\n",
    "    # 64,\n",
    "    64,\n",
    "    # 128,\n",
    "]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fpn import OCDFPN\n",
    "\n",
    "\n",
    "image_size = (320, 320)\n",
    "backbone_dict = {\n",
    "    # \"mobilenetv1\": \"mobilenetv1_100\",\n",
    "    \"mobilenetv2_050\": \"mobilenetv2_050\",\n",
    "    \"mobilenetv2_100\": \"mobilenetv2_100\",\n",
    "    \"mobilenetv2_140\": \"mobilenetv2_140\",\n",
    "    \"mobilenetv3_small_100\": \"mobilenetv3_small_100\",\n",
    "    \"mobilenetv3_large_100\": \"tf_mobilenetv3_large_100\",\n",
    "    \"mobilenetv3_large_100\": \"mobilenetv3_large_100\",\n",
    "}\n",
    "n_classes = 80\n",
    "num_outs = 4\n",
    "out_channel_list = [\n",
    "    # 16,\n",
    "    64,\n",
    "    64,\n",
    "    128,\n",
    "    64,\n",
    "    64,\n",
    "    128,\n",
    "]\n",
    "\n",
    "for backbone_key, out_channel in zip(backbone_dict.keys(), out_channel_list):\n",
    "    backbone_value = backbone_dict[backbone_key]\n",
    "    model = OCDFPN(\n",
    "        backbone=backbone_value,\n",
    "        n_classes=n_classes,\n",
    "        num_outs=num_outs,\n",
    "        out_channel=out_channel,\n",
    "    )\n",
    "\n",
    "    model_name = f\"fpn_{backbone_key}_o{num_outs}_r{image_size[0]}_coco\"\n",
    "    torch_model_path = None  # use initialized model\n",
    "    onnx_model_path = f\"saved_model/{model_name}/{model_name}.onnx\"\n",
    "    tf_folder_path = f\"saved_model/{model_name}\"\n",
    "    tflite_model_path = onnx_model_path.replace(\n",
    "        \".onnx\", \"_full_integer_quant_uint8.tflite\"\n",
    "    )\n",
    "    calib_data_path = \"calibdata.npy\"\n",
    "\n",
    "    converter = Converter(\n",
    "        model,\n",
    "        image_size,\n",
    "        torch_model_path,\n",
    "        onnx_model_path,\n",
    "        tf_folder_path,\n",
    "        tflite_model_path,\n",
    "        calib_data_path,\n",
    "        opset_version=11,\n",
    "    )\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
