{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: yolov8n\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 3.157M                 | 1.1G       |\\n'\n",
      " '|  0                    |  0.464K                |  11.878M   |\\n'\n",
      " '|   0.conv              |   0.432K               |   11.059M  |\\n'\n",
      " '|    0.conv.weight      |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   32                   |   0.819M   |\\n'\n",
      " '|    0.bn.weight        |    (16,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (16,)               |            |\\n'\n",
      " '|  1                    |  4.672K                |  29.901M   |\\n'\n",
      " '|   1.conv              |   4.608K               |   29.491M  |\\n'\n",
      " '|    1.conv.weight      |    (32, 16, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   64                   |   0.41M    |\\n'\n",
      " '|    1.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  2                    |  7.36K                 |  47.104M   |\\n'\n",
      " '|   2.cv1               |   1.088K               |   6.963M   |\\n'\n",
      " '|    2.cv1.conv         |    1.024K              |    6.554M  |\\n'\n",
      " '|    2.cv1.bn           |    64                  |    0.41M   |\\n'\n",
      " '|   2.cv2               |   1.6K                 |   10.24M   |\\n'\n",
      " '|    2.cv2.conv         |    1.536K              |    9.83M   |\\n'\n",
      " '|    2.cv2.bn           |    64                  |    0.41M   |\\n'\n",
      " '|   2.m.0               |   4.672K               |   29.901M  |\\n'\n",
      " '|    2.m.0.cv1          |    2.336K              |    14.95M  |\\n'\n",
      " '|    2.m.0.cv2          |    2.336K              |    14.95M  |\\n'\n",
      " '|  3                    |  18.56K                |  29.696M   |\\n'\n",
      " '|   3.conv              |   18.432K              |   29.491M  |\\n'\n",
      " '|    3.conv.weight      |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   3.bn                |   0.128K               |   0.205M   |\\n'\n",
      " '|    3.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    3.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  4                    |  49.664K               |  79.462M   |\\n'\n",
      " '|   4.cv1               |   4.224K               |   6.758M   |\\n'\n",
      " '|    4.cv1.conv         |    4.096K              |    6.554M  |\\n'\n",
      " '|    4.cv1.bn           |    0.128K              |    0.205M  |\\n'\n",
      " '|   4.cv2               |   8.32K                |   13.312M  |\\n'\n",
      " '|    4.cv2.conv         |    8.192K              |    13.107M |\\n'\n",
      " '|    4.cv2.bn           |    0.128K              |    0.205M  |\\n'\n",
      " '|   4.m                 |   37.12K               |   59.392M  |\\n'\n",
      " '|    4.m.0              |    18.56K              |    29.696M |\\n'\n",
      " '|    4.m.1              |    18.56K              |    29.696M |\\n'\n",
      " '|  5                    |  73.984K               |  29.594M   |\\n'\n",
      " '|   5.conv              |   73.728K              |   29.491M  |\\n'\n",
      " '|    5.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   5.bn                |   0.256K               |   0.102M   |\\n'\n",
      " '|    5.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  6                    |  0.198M                |  79.053M   |\\n'\n",
      " '|   6.cv1               |   16.64K               |   6.656M   |\\n'\n",
      " '|    6.cv1.conv         |    16.384K             |    6.554M  |\\n'\n",
      " '|    6.cv1.bn           |    0.256K              |    0.102M  |\\n'\n",
      " '|   6.cv2               |   33.024K              |   13.21M   |\\n'\n",
      " '|    6.cv2.conv         |    32.768K             |    13.107M |\\n'\n",
      " '|    6.cv2.bn           |    0.256K              |    0.102M  |\\n'\n",
      " '|   6.m                 |   0.148M               |   59.187M  |\\n'\n",
      " '|    6.m.0              |    73.984K             |    29.594M |\\n'\n",
      " '|    6.m.1              |    73.984K             |    29.594M |\\n'\n",
      " '|  7                    |  0.295M                |  29.542M   |\\n'\n",
      " '|   7.conv              |   0.295M               |   29.491M  |\\n'\n",
      " '|    7.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   0.512K               |   51.2K    |\\n'\n",
      " '|    7.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  8                    |  0.46M                 |  46.029M   |\\n'\n",
      " '|   8.cv1               |   66.048K              |   6.605M   |\\n'\n",
      " '|    8.cv1.conv         |    65.536K             |    6.554M  |\\n'\n",
      " '|    8.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   8.cv2               |   98.816K              |   9.882M   |\\n'\n",
      " '|    8.cv2.conv         |    98.304K             |    9.83M   |\\n'\n",
      " '|    8.cv2.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   8.m.0               |   0.295M               |   29.542M  |\\n'\n",
      " '|    8.m.0.cv1          |    0.148M              |    14.771M |\\n'\n",
      " '|    8.m.0.cv2          |    0.148M              |    14.771M |\\n'\n",
      " '|  9                    |  0.165M                |  16.461M   |\\n'\n",
      " '|   9.cv1               |   33.024K              |   3.302M   |\\n'\n",
      " '|    9.cv1.conv         |    32.768K             |    3.277M  |\\n'\n",
      " '|    9.cv1.bn           |    0.256K              |    25.6K   |\\n'\n",
      " '|   9.cv2               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv2.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv2.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|  12                   |  0.148M                |  59.29M    |\\n'\n",
      " '|   12.cv1              |   49.408K              |   19.763M  |\\n'\n",
      " '|    12.cv1.conv        |    49.152K             |    19.661M |\\n'\n",
      " '|    12.cv1.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   12.cv2              |   24.832K              |   9.933M   |\\n'\n",
      " '|    12.cv2.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    12.cv2.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   12.m.0              |   73.984K              |   29.594M  |\\n'\n",
      " '|    12.m.0.cv1         |    36.992K             |    14.797M |\\n'\n",
      " '|    12.m.0.cv2         |    36.992K             |    14.797M |\\n'\n",
      " '|  15                   |  37.248K               |  59.597M   |\\n'\n",
      " '|   15.cv1              |   12.416K              |   19.866M  |\\n'\n",
      " '|    15.cv1.conv        |    12.288K             |    19.661M |\\n'\n",
      " '|    15.cv1.bn          |    0.128K              |    0.205M  |\\n'\n",
      " '|   15.cv2              |   6.272K               |   10.035M  |\\n'\n",
      " '|    15.cv2.conv        |    6.144K              |    9.83M   |\\n'\n",
      " '|    15.cv2.bn          |    0.128K              |    0.205M  |\\n'\n",
      " '|   15.m.0              |   18.56K               |   29.696M  |\\n'\n",
      " '|    15.m.0.cv1         |    9.28K               |    14.848M |\\n'\n",
      " '|    15.m.0.cv2         |    9.28K               |    14.848M |\\n'\n",
      " '|  16                   |  36.992K               |  14.797M   |\\n'\n",
      " '|   16.conv             |   36.864K              |   14.746M  |\\n'\n",
      " '|    16.conv.weight     |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   16.bn               |   0.128K               |   51.2K    |\\n'\n",
      " '|    16.bn.weight       |    (64,)               |            |\\n'\n",
      " '|    16.bn.bias         |    (64,)               |            |\\n'\n",
      " '|  18                   |  0.124M                |  49.459M   |\\n'\n",
      " '|   18.cv1              |   24.832K              |   9.933M   |\\n'\n",
      " '|    18.cv1.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    18.cv1.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   18.cv2              |   24.832K              |   9.933M   |\\n'\n",
      " '|    18.cv2.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    18.cv2.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   18.m.0              |   73.984K              |   29.594M  |\\n'\n",
      " '|    18.m.0.cv1         |    36.992K             |    14.797M |\\n'\n",
      " '|    18.m.0.cv2         |    36.992K             |    14.797M |\\n'\n",
      " '|  19                   |  0.148M                |  14.771M   |\\n'\n",
      " '|   19.conv             |   0.147M               |   14.746M  |\\n'\n",
      " '|    19.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.256K               |   25.6K    |\\n'\n",
      " '|    19.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  21                   |  0.493M                |  49.306M   |\\n'\n",
      " '|   21.cv1              |   98.816K              |   9.882M   |\\n'\n",
      " '|    21.cv1.conv        |    98.304K             |    9.83M   |\\n'\n",
      " '|    21.cv1.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   21.cv2              |   98.816K              |   9.882M   |\\n'\n",
      " '|    21.cv2.conv        |    98.304K             |    9.83M   |\\n'\n",
      " '|    21.cv2.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   21.m.0              |   0.295M               |   29.542M  |\\n'\n",
      " '|    21.m.0.cv1         |    0.148M              |    14.771M |\\n'\n",
      " '|    21.m.0.cv2         |    0.148M              |    14.771M |\\n'\n",
      " '|  22                   |  0.898M                |  0.454G    |\\n'\n",
      " '|   22.cv2              |   0.382M               |   0.19G    |\\n'\n",
      " '|    22.cv2.0           |    78.144K             |    0.125G  |\\n'\n",
      " '|    22.cv2.1           |    0.115M              |    45.978M |\\n'\n",
      " '|    22.cv2.2           |    0.189M              |    18.867M |\\n'\n",
      " '|   22.cv3              |   0.516M               |   0.264G   |\\n'\n",
      " '|    22.cv3.0           |    0.11M               |    0.177G  |\\n'\n",
      " '|    22.cv3.1           |    0.157M              |    62.592M |\\n'\n",
      " '|    22.cv3.2           |    0.249M              |    24.864M |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.102M    |\\n'\n",
      " '|  13                   |                        |  0.205M    |')\n",
      "--------------------\n",
      "Model: yolov8s\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 11.167M                | 3.589G     |\\n'\n",
      " '|  0                    |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.conv              |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.conv.weight      |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   64                   |   1.638M   |\\n'\n",
      " '|    0.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  1                    |  18.56K                |  0.119G    |\\n'\n",
      " '|   1.conv              |   18.432K              |   0.118G   |\\n'\n",
      " '|    1.conv.weight      |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.128K               |   0.819M   |\\n'\n",
      " '|    1.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  2                    |  29.056K               |  0.186G    |\\n'\n",
      " '|   2.cv1               |   4.224K               |   27.034M  |\\n'\n",
      " '|    2.cv1.conv         |    4.096K              |    26.214M |\\n'\n",
      " '|    2.cv1.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.cv2               |   6.272K               |   40.141M  |\\n'\n",
      " '|    2.cv2.conv         |    6.144K              |    39.322M |\\n'\n",
      " '|    2.cv2.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.m.0               |   18.56K               |   0.119G   |\\n'\n",
      " '|    2.m.0.cv1          |    9.28K               |    59.392M |\\n'\n",
      " '|    2.m.0.cv2          |    9.28K               |    59.392M |\\n'\n",
      " '|  3                    |  73.984K               |  0.118G    |\\n'\n",
      " '|   3.conv              |   73.728K              |   0.118G   |\\n'\n",
      " '|    3.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.256K               |   0.41M    |\\n'\n",
      " '|    3.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  4                    |  0.198M                |  0.316G    |\\n'\n",
      " '|   4.cv1               |   16.64K               |   26.624M  |\\n'\n",
      " '|    4.cv1.conv         |    16.384K             |    26.214M |\\n'\n",
      " '|    4.cv1.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.cv2               |   33.024K              |   52.838M  |\\n'\n",
      " '|    4.cv2.conv         |    32.768K             |    52.429M |\\n'\n",
      " '|    4.cv2.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.m                 |   0.148M               |   0.237G   |\\n'\n",
      " '|    4.m.0              |    73.984K             |    0.118G  |\\n'\n",
      " '|    4.m.1              |    73.984K             |    0.118G  |\\n'\n",
      " '|  5                    |  0.295M                |  0.118G    |\\n'\n",
      " '|   5.conv              |   0.295M               |   0.118G   |\\n'\n",
      " '|    5.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.512K               |   0.205M   |\\n'\n",
      " '|    5.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  6                    |  0.788M                |  0.315G    |\\n'\n",
      " '|   6.cv1               |   66.048K              |   26.419M  |\\n'\n",
      " '|    6.cv1.conv         |    65.536K             |    26.214M |\\n'\n",
      " '|    6.cv1.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.cv2               |   0.132M               |   52.634M  |\\n'\n",
      " '|    6.cv2.conv         |    0.131M              |    52.429M |\\n'\n",
      " '|    6.cv2.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.m                 |   0.591M               |   0.236G   |\\n'\n",
      " '|    6.m.0              |    0.295M              |    0.118G  |\\n'\n",
      " '|    6.m.1              |    0.295M              |    0.118G  |\\n'\n",
      " '|  7                    |  1.181M                |  0.118G    |\\n'\n",
      " '|   7.conv              |   1.18M                |   0.118G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  1.838M                |  0.184G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.394M               |   39.424M  |\\n'\n",
      " '|    8.cv2.conv         |    0.393M              |    39.322M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m.0               |   1.181M               |   0.118G   |\\n'\n",
      " '|    8.m.0.cv1          |    0.59M               |    59.034M |\\n'\n",
      " '|    8.m.0.cv2          |    0.59M               |    59.034M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  12                   |  0.591M                |  0.237G    |\\n'\n",
      " '|   12.cv1              |   0.197M               |   78.848M  |\\n'\n",
      " '|    12.cv1.conv        |    0.197M              |    78.643M |\\n'\n",
      " '|    12.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    12.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    12.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    12.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    12.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  15                   |  0.148M                |  0.237G    |\\n'\n",
      " '|   15.cv1              |   49.408K              |   79.053M  |\\n'\n",
      " '|    15.cv1.conv        |    49.152K             |    78.643M |\\n'\n",
      " '|    15.cv1.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.cv2              |   24.832K              |   39.731M  |\\n'\n",
      " '|    15.cv2.conv        |    24.576K             |    39.322M |\\n'\n",
      " '|    15.cv2.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.m.0              |   73.984K              |   0.118G   |\\n'\n",
      " '|    15.m.0.cv1         |    36.992K             |    59.187M |\\n'\n",
      " '|    15.m.0.cv2         |    36.992K             |    59.187M |\\n'\n",
      " '|  16                   |  0.148M                |  59.085M   |\\n'\n",
      " '|   16.conv             |   0.147M               |   58.982M  |\\n'\n",
      " '|    16.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.256K               |   0.102M   |\\n'\n",
      " '|    16.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  18                   |  0.493M                |  0.197G    |\\n'\n",
      " '|   18.cv1              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv1.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    18.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    18.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  19                   |  0.59M                 |  59.034M   |\\n'\n",
      " '|   19.conv             |   0.59M                |   58.982M  |\\n'\n",
      " '|    19.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.512K               |   51.2K    |\\n'\n",
      " '|    19.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  21                   |  1.969M                |  0.197G    |\\n'\n",
      " '|   21.cv1              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv1.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.cv2              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv2.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.m.0              |   1.181M               |   0.118G   |\\n'\n",
      " '|    21.m.0.cv1         |    0.59M               |    59.034M |\\n'\n",
      " '|    21.m.0.cv2         |    0.59M               |    59.034M |\\n'\n",
      " '|  22                   |  2.147M                |  1.038G    |\\n'\n",
      " '|   22.cv2              |   0.64M                |   0.293G   |\\n'\n",
      " '|    22.cv2.0           |    0.115M              |    0.184G  |\\n'\n",
      " '|    22.cv2.1           |    0.189M              |    75.469M |\\n'\n",
      " '|    22.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   22.cv3              |   1.507M               |   0.745G   |\\n'\n",
      " '|    22.cv3.0           |    0.306M              |    0.489G  |\\n'\n",
      " '|    22.cv3.1           |    0.453M              |    0.181G  |\\n'\n",
      " '|    22.cv3.2           |    0.748M              |    74.803M |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.205M    |\\n'\n",
      " '|  13                   |                        |  0.41M     |')\n",
      "--------------------\n",
      "Model: yolov8m\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 25.903M                | 9.891G     |\\n'\n",
      " '|  0                    |  1.392K                |  35.635M   |\\n'\n",
      " '|   0.conv              |   1.296K               |   33.178M  |\\n'\n",
      " '|    0.conv.weight      |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   96                   |   2.458M   |\\n'\n",
      " '|    0.bn.weight        |    (48,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (48,)               |            |\\n'\n",
      " '|  1                    |  41.664K               |  0.267G    |\\n'\n",
      " '|   1.conv              |   41.472K              |   0.265G   |\\n'\n",
      " '|    1.conv.weight      |    (96, 48, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.192K               |   1.229M   |\\n'\n",
      " '|    1.bn.weight        |    (96,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (96,)               |            |\\n'\n",
      " '|  2                    |  0.111M                |  0.713G    |\\n'\n",
      " '|   2.cv1               |   9.408K               |   60.211M  |\\n'\n",
      " '|    2.cv1.conv         |    9.216K              |    58.982M |\\n'\n",
      " '|    2.cv1.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.cv2               |   18.624K              |   0.119G   |\\n'\n",
      " '|    2.cv2.conv         |    18.432K             |    0.118G  |\\n'\n",
      " '|    2.cv2.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.m                 |   83.328K              |   0.533G   |\\n'\n",
      " '|    2.m.0              |    41.664K             |    0.267G  |\\n'\n",
      " '|    2.m.1              |    41.664K             |    0.267G  |\\n'\n",
      " '|  3                    |  0.166M                |  0.266G    |\\n'\n",
      " '|   3.conv              |   0.166M               |   0.265G   |\\n'\n",
      " '|    3.conv.weight      |    (192, 96, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.384K               |   0.614M   |\\n'\n",
      " '|    3.bn.weight        |    (192,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (192,)              |            |\\n'\n",
      " '|  4                    |  0.813M                |  1.301G    |\\n'\n",
      " '|   4.cv1               |   37.248K              |   59.597M  |\\n'\n",
      " '|    4.cv1.conv         |    36.864K             |    58.982M |\\n'\n",
      " '|    4.cv1.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.cv2               |   0.111M               |   0.178G   |\\n'\n",
      " '|    4.cv2.conv         |    0.111M              |    0.177G  |\\n'\n",
      " '|    4.cv2.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.m                 |   0.665M               |   1.064G   |\\n'\n",
      " '|    4.m.0              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.1              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.2              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.3              |    0.166M              |    0.266G  |\\n'\n",
      " '|  5                    |  0.664M                |  0.266G    |\\n'\n",
      " '|   5.conv              |   0.664M               |   0.265G   |\\n'\n",
      " '|    5.conv.weight      |    (384, 192, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.768K               |   0.307M   |\\n'\n",
      " '|    5.bn.weight        |    (384,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (384,)              |            |\\n'\n",
      " '|  6                    |  3.249M                |  1.299G    |\\n'\n",
      " '|   6.cv1               |   0.148M               |   59.29M   |\\n'\n",
      " '|    6.cv1.conv         |    0.147M              |    58.982M |\\n'\n",
      " '|    6.cv1.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.cv2               |   0.443M               |   0.177G   |\\n'\n",
      " '|    6.cv2.conv         |    0.442M              |    0.177G  |\\n'\n",
      " '|    6.cv2.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.m                 |   2.657M               |   1.063G   |\\n'\n",
      " '|    6.m.0              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.1              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.2              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.3              |    0.664M              |    0.266G  |\\n'\n",
      " '|  7                    |  1.992M                |  0.199G    |\\n'\n",
      " '|   7.conv              |   1.991M               |   0.199G   |\\n'\n",
      " '|    7.conv.weight      |    (576, 384, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.152K               |   0.115M   |\\n'\n",
      " '|    7.bn.weight        |    (576,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (576,)              |            |\\n'\n",
      " '|  8                    |  3.986M                |  0.399G    |\\n'\n",
      " '|   8.cv1               |   0.333M               |   33.293M  |\\n'\n",
      " '|    8.cv1.conv         |    0.332M              |    33.178M |\\n'\n",
      " '|    8.cv1.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    8.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    8.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.m                 |   2.988M               |   0.299G   |\\n'\n",
      " '|    8.m.0              |    1.494M              |    0.149G  |\\n'\n",
      " '|    8.m.1              |    1.494M              |    0.149G  |\\n'\n",
      " '|  9                    |  0.831M                |  83.117M   |\\n'\n",
      " '|   9.cv1               |   0.166M               |   16.646M  |\\n'\n",
      " '|    9.cv1.conv         |    0.166M              |    16.589M |\\n'\n",
      " '|    9.cv1.bn           |    0.576K              |    57.6K   |\\n'\n",
      " '|   9.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    9.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    9.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|  12                   |  1.994M                |  0.797G    |\\n'\n",
      " '|   12.cv1              |   0.369M               |   0.148G   |\\n'\n",
      " '|    12.cv1.conv        |    0.369M              |    0.147G  |\\n'\n",
      " '|    12.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    12.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    12.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    12.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    12.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  15                   |  0.518M                |  0.828G    |\\n'\n",
      " '|   15.cv1              |   0.111M               |   0.178G   |\\n'\n",
      " '|    15.cv1.conv        |    0.111M              |    0.177G  |\\n'\n",
      " '|    15.cv1.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.cv2              |   74.112K              |   0.119G   |\\n'\n",
      " '|    15.cv2.conv        |    73.728K             |    0.118G  |\\n'\n",
      " '|    15.cv2.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.m                |   0.333M               |   0.532G   |\\n'\n",
      " '|    15.m.0             |    0.166M              |    0.266G  |\\n'\n",
      " '|    15.m.1             |    0.166M              |    0.266G  |\\n'\n",
      " '|  16                   |  0.332M                |  0.133G    |\\n'\n",
      " '|   16.conv             |   0.332M               |   0.133G   |\\n'\n",
      " '|    16.conv.weight     |    (192, 192, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.384K               |   0.154M   |\\n'\n",
      " '|    16.bn.weight       |    (192,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (192,)              |            |\\n'\n",
      " '|  18                   |  1.846M                |  0.739G    |\\n'\n",
      " '|   18.cv1              |   0.222M               |   88.781M  |\\n'\n",
      " '|    18.cv1.conv        |    0.221M              |    88.474M |\\n'\n",
      " '|    18.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    18.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    18.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    18.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    18.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  19                   |  1.328M                |  0.133G    |\\n'\n",
      " '|   19.conv             |   1.327M               |   0.133G   |\\n'\n",
      " '|    19.conv.weight     |    (384, 384, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.768K               |   76.8K    |\\n'\n",
      " '|    19.bn.weight       |    (384,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (384,)              |            |\\n'\n",
      " '|  21                   |  4.207M                |  0.421G    |\\n'\n",
      " '|   21.cv1              |   0.554M               |   55.411M  |\\n'\n",
      " '|    21.cv1.conv        |    0.553M              |    55.296M |\\n'\n",
      " '|    21.cv1.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.cv2              |   0.665M               |   66.47M   |\\n'\n",
      " '|    21.cv2.conv        |    0.664M              |    66.355M |\\n'\n",
      " '|    21.cv2.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.m                |   2.988M               |   0.299G   |\\n'\n",
      " '|    21.m.0             |    1.494M              |    0.149G  |\\n'\n",
      " '|    21.m.1             |    1.494M              |    0.149G  |\\n'\n",
      " '|  22                   |  3.822M                |  2.012G    |\\n'\n",
      " '|   22.cv2              |   0.787M               |   0.385G   |\\n'\n",
      " '|    22.cv2.0           |    0.152M              |    0.243G  |\\n'\n",
      " '|    22.cv2.1           |    0.262M              |    0.105G  |\\n'\n",
      " '|    22.cv2.2           |    0.373M              |    37.299M |\\n'\n",
      " '|   22.cv3              |   3.035M               |   1.626G   |\\n'\n",
      " '|    22.cv3.0           |    0.68M               |    1.087G  |\\n'\n",
      " '|    22.cv3.1           |    1.012M              |    0.405G  |\\n'\n",
      " '|    22.cv3.2           |    1.343M              |    0.134G  |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.23M     |\\n'\n",
      " '|  13                   |                        |  0.614M    |')\n",
      "--------------------\n",
      "Model: yolov8l\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 43.692M                | 20.681G    |\\n'\n",
      " '|  0                    |  1.856K                |  47.514M   |\\n'\n",
      " '|   0.conv              |   1.728K               |   44.237M  |\\n'\n",
      " '|    0.conv.weight      |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   0.128K               |   3.277M   |\\n'\n",
      " '|    0.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  1                    |  73.984K               |  0.473G    |\\n'\n",
      " '|   1.conv              |   73.728K              |   0.472G   |\\n'\n",
      " '|    1.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   1.bn                |   0.256K               |   1.638M   |\\n'\n",
      " '|    1.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    1.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  2                    |  0.28M                 |  1.791G    |\\n'\n",
      " '|   2.cv1               |   16.64K               |   0.106G   |\\n'\n",
      " '|    2.cv1.conv         |    16.384K             |    0.105G  |\\n'\n",
      " '|    2.cv1.bn           |    0.256K              |    1.638M  |\\n'\n",
      " '|   2.cv2               |   41.216K              |   0.264G   |\\n'\n",
      " '|    2.cv2.conv         |    40.96K              |    0.262G  |\\n'\n",
      " '|    2.cv2.bn           |    0.256K              |    1.638M  |\\n'\n",
      " '|   2.m                 |   0.222M               |   1.42G    |\\n'\n",
      " '|    2.m.0              |    73.984K             |    0.473G  |\\n'\n",
      " '|    2.m.1              |    73.984K             |    0.473G  |\\n'\n",
      " '|    2.m.2              |    73.984K             |    0.473G  |\\n'\n",
      " '|  3                    |  0.295M                |  0.473G    |\\n'\n",
      " '|   3.conv              |   0.295M               |   0.472G   |\\n'\n",
      " '|    3.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.512K               |   0.819M   |\\n'\n",
      " '|    3.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  4                    |  2.101M                |  3.362G    |\\n'\n",
      " '|   4.cv1               |   66.048K              |   0.106G   |\\n'\n",
      " '|    4.cv1.conv         |    65.536K             |    0.105G  |\\n'\n",
      " '|    4.cv1.bn           |    0.512K              |    0.819M  |\\n'\n",
      " '|   4.cv2               |   0.263M               |   0.42G    |\\n'\n",
      " '|    4.cv2.conv         |    0.262M              |    0.419G  |\\n'\n",
      " '|    4.cv2.bn           |    0.512K              |    0.819M  |\\n'\n",
      " '|   4.m                 |   1.773M               |   2.836G   |\\n'\n",
      " '|    4.m.0              |    0.295M              |    0.473G  |\\n'\n",
      " '|    4.m.1              |    0.295M              |    0.473G  |\\n'\n",
      " '|    4.m.2              |    0.295M              |    0.473G  |\\n'\n",
      " '|    4.m.3              |    0.295M              |    0.473G  |\\n'\n",
      " '|    4.m.4              |    0.295M              |    0.473G  |\\n'\n",
      " '|    4.m.5              |    0.295M              |    0.473G  |\\n'\n",
      " '|  5                    |  1.181M                |  0.472G    |\\n'\n",
      " '|   5.conv              |   1.18M                |   0.472G   |\\n'\n",
      " '|    5.conv.weight      |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   1.024K               |   0.41M    |\\n'\n",
      " '|    5.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  6                    |  8.397M                |  3.359G    |\\n'\n",
      " '|   6.cv1               |   0.263M               |   0.105G   |\\n'\n",
      " '|    6.cv1.conv         |    0.262M              |    0.105G  |\\n'\n",
      " '|    6.cv1.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.cv2               |   1.05M                |   0.42G    |\\n'\n",
      " '|    6.cv2.conv         |    1.049M              |    0.419G  |\\n'\n",
      " '|    6.cv2.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.m                 |   7.084M               |   2.834G   |\\n'\n",
      " '|    6.m.0              |    1.181M              |    0.472G  |\\n'\n",
      " '|    6.m.1              |    1.181M              |    0.472G  |\\n'\n",
      " '|    6.m.2              |    1.181M              |    0.472G  |\\n'\n",
      " '|    6.m.3              |    1.181M              |    0.472G  |\\n'\n",
      " '|    6.m.4              |    1.181M              |    0.472G  |\\n'\n",
      " '|    6.m.5              |    1.181M              |    0.472G  |\\n'\n",
      " '|  7                    |  2.36M                 |  0.236G    |\\n'\n",
      " '|   7.conv              |   2.359M               |   0.236G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  4.462M                |  0.446G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.656M               |   65.638M  |\\n'\n",
      " '|    8.cv2.conv         |    0.655M              |    65.536M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m                 |   3.542M               |   0.354G   |\\n'\n",
      " '|    8.m.0              |    1.181M              |    0.118G  |\\n'\n",
      " '|    8.m.1              |    1.181M              |    0.118G  |\\n'\n",
      " '|    8.m.2              |    1.181M              |    0.118G  |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  12                   |  4.724M                |  1.889G    |\\n'\n",
      " '|   12.cv1              |   0.525M               |   0.21G    |\\n'\n",
      " '|    12.cv1.conv        |    0.524M              |    0.21G   |\\n'\n",
      " '|    12.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   12.cv2              |   0.656M               |   0.263G   |\\n'\n",
      " '|    12.cv2.conv        |    0.655M              |    0.262G  |\\n'\n",
      " '|    12.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   12.m                |   3.542M               |   1.417G   |\\n'\n",
      " '|    12.m.0             |    1.181M              |    0.472G  |\\n'\n",
      " '|    12.m.1             |    1.181M              |    0.472G  |\\n'\n",
      " '|    12.m.2             |    1.181M              |    0.472G  |\\n'\n",
      " '|  15                   |  1.248M                |  1.996G    |\\n'\n",
      " '|   15.cv1              |   0.197M               |   0.315G   |\\n'\n",
      " '|    15.cv1.conv        |    0.197M              |    0.315G  |\\n'\n",
      " '|    15.cv1.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   15.cv2              |   0.164M               |   0.263G   |\\n'\n",
      " '|    15.cv2.conv        |    0.164M              |    0.262G  |\\n'\n",
      " '|    15.cv2.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   15.m                |   0.886M               |   1.418G   |\\n'\n",
      " '|    15.m.0             |    0.295M              |    0.473G  |\\n'\n",
      " '|    15.m.1             |    0.295M              |    0.473G  |\\n'\n",
      " '|    15.m.2             |    0.295M              |    0.473G  |\\n'\n",
      " '|  16                   |  0.59M                 |  0.236G    |\\n'\n",
      " '|   16.conv             |   0.59M                |   0.236G   |\\n'\n",
      " '|    16.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.512K               |   0.205M   |\\n'\n",
      " '|    16.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  18                   |  4.593M                |  1.837G    |\\n'\n",
      " '|   18.cv1              |   0.394M               |   0.158G   |\\n'\n",
      " '|    18.cv1.conv        |    0.393M              |    0.157G  |\\n'\n",
      " '|    18.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   18.cv2              |   0.656M               |   0.263G   |\\n'\n",
      " '|    18.cv2.conv        |    0.655M              |    0.262G  |\\n'\n",
      " '|    18.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   18.m                |   3.542M               |   1.417G   |\\n'\n",
      " '|    18.m.0             |    1.181M              |    0.472G  |\\n'\n",
      " '|    18.m.1             |    1.181M              |    0.472G  |\\n'\n",
      " '|    18.m.2             |    1.181M              |    0.472G  |\\n'\n",
      " '|  19                   |  2.36M                 |  0.236G    |\\n'\n",
      " '|   19.conv             |   2.359M               |   0.236G   |\\n'\n",
      " '|    19.conv.weight     |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   1.024K               |   0.102M   |\\n'\n",
      " '|    19.bn.weight       |    (512,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (512,)              |            |\\n'\n",
      " '|  21                   |  4.724M                |  0.472G    |\\n'\n",
      " '|   21.cv1              |   0.525M               |   52.531M  |\\n'\n",
      " '|    21.cv1.conv        |    0.524M              |    52.429M |\\n'\n",
      " '|    21.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.cv2              |   0.656M               |   65.638M  |\\n'\n",
      " '|    21.cv2.conv        |    0.655M              |    65.536M |\\n'\n",
      " '|    21.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.m                |   3.542M               |   0.354G   |\\n'\n",
      " '|    21.m.0             |    1.181M              |    0.118G  |\\n'\n",
      " '|    21.m.1             |    1.181M              |    0.118G  |\\n'\n",
      " '|    21.m.2             |    1.181M              |    0.118G  |\\n'\n",
      " '|  22                   |  5.644M                |  3.287G    |\\n'\n",
      " '|   22.cv2              |   0.861M               |   0.47G    |\\n'\n",
      " '|    22.cv2.0           |    0.189M              |    0.302G  |\\n'\n",
      " '|    22.cv2.1           |    0.336M              |    0.134G  |\\n'\n",
      " '|    22.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   22.cv3              |   4.783M               |   2.817G   |\\n'\n",
      " '|    22.cv3.0           |    1.201M              |    1.922G  |\\n'\n",
      " '|    22.cv3.1           |    1.791M              |    0.716G  |\\n'\n",
      " '|    22.cv3.2           |    1.791M              |    0.179G  |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.205M    |\\n'\n",
      " '|  13                   |                        |  0.819M    |')\n",
      "--------------------\n",
      "Model: yolov8x\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 68.23M                 | 32.273G    |\\n'\n",
      " '|  0                    |  2.32K                 |  59.392M   |\\n'\n",
      " '|   0.conv              |   2.16K                |   55.296M  |\\n'\n",
      " '|    0.conv.weight      |    (80, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   0.16K                |   4.096M   |\\n'\n",
      " '|    0.bn.weight        |    (80,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (80,)               |            |\\n'\n",
      " '|  1                    |  0.116M                |  0.739G    |\\n'\n",
      " '|   1.conv              |   0.115M               |   0.737G   |\\n'\n",
      " '|    1.conv.weight      |    (160, 80, 3, 3)     |            |\\n'\n",
      " '|   1.bn                |   0.32K                |   2.048M   |\\n'\n",
      " '|    1.bn.weight        |    (160,)              |            |\\n'\n",
      " '|    1.bn.bias          |    (160,)              |            |\\n'\n",
      " '|  2                    |  0.437M                |  2.796G    |\\n'\n",
      " '|   2.cv1               |   25.92K               |   0.166G   |\\n'\n",
      " '|    2.cv1.conv         |    25.6K               |    0.164G  |\\n'\n",
      " '|    2.cv1.bn           |    0.32K               |    2.048M  |\\n'\n",
      " '|   2.cv2               |   64.32K               |   0.412G   |\\n'\n",
      " '|    2.cv2.conv         |    64K                 |    0.41G   |\\n'\n",
      " '|    2.cv2.bn           |    0.32K               |    2.048M  |\\n'\n",
      " '|   2.m                 |   0.347M               |   2.218G   |\\n'\n",
      " '|    2.m.0              |    0.116M              |    0.739G  |\\n'\n",
      " '|    2.m.1              |    0.116M              |    0.739G  |\\n'\n",
      " '|    2.m.2              |    0.116M              |    0.739G  |\\n'\n",
      " '|  3                    |  0.461M                |  0.738G    |\\n'\n",
      " '|   3.conv              |   0.461M               |   0.737G   |\\n'\n",
      " '|    3.conv.weight      |    (320, 160, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.64K                |   1.024M   |\\n'\n",
      " '|    3.bn.weight        |    (320,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (320,)              |            |\\n'\n",
      " '|  4                    |  3.282M                |  5.251G    |\\n'\n",
      " '|   4.cv1               |   0.103M               |   0.165G   |\\n'\n",
      " '|    4.cv1.conv         |    0.102M              |    0.164G  |\\n'\n",
      " '|    4.cv1.bn           |    0.64K               |    1.024M  |\\n'\n",
      " '|   4.cv2               |   0.41M                |   0.656G   |\\n'\n",
      " '|    4.cv2.conv         |    0.41M               |    0.655G  |\\n'\n",
      " '|    4.cv2.bn           |    0.64K               |    1.024M  |\\n'\n",
      " '|   4.m                 |   2.769M               |   4.43G    |\\n'\n",
      " '|    4.m.0              |    0.461M              |    0.738G  |\\n'\n",
      " '|    4.m.1              |    0.461M              |    0.738G  |\\n'\n",
      " '|    4.m.2              |    0.461M              |    0.738G  |\\n'\n",
      " '|    4.m.3              |    0.461M              |    0.738G  |\\n'\n",
      " '|    4.m.4              |    0.461M              |    0.738G  |\\n'\n",
      " '|    4.m.5              |    0.461M              |    0.738G  |\\n'\n",
      " '|  5                    |  1.844M                |  0.738G    |\\n'\n",
      " '|   5.conv              |   1.843M               |   0.737G   |\\n'\n",
      " '|    5.conv.weight      |    (640, 320, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   1.28K                |   0.512M   |\\n'\n",
      " '|    5.bn.weight        |    (640,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (640,)              |            |\\n'\n",
      " '|  6                    |  13.117M               |  5.247G    |\\n'\n",
      " '|   6.cv1               |   0.411M               |   0.164G   |\\n'\n",
      " '|    6.cv1.conv         |    0.41M               |    0.164G  |\\n'\n",
      " '|    6.cv1.bn           |    1.28K               |    0.512M  |\\n'\n",
      " '|   6.cv2               |   1.64M                |   0.656G   |\\n'\n",
      " '|    6.cv2.conv         |    1.638M              |    0.655G  |\\n'\n",
      " '|    6.cv2.bn           |    1.28K               |    0.512M  |\\n'\n",
      " '|   6.m                 |   11.067M              |   4.427G   |\\n'\n",
      " '|    6.m.0              |    1.844M              |    0.738G  |\\n'\n",
      " '|    6.m.1              |    1.844M              |    0.738G  |\\n'\n",
      " '|    6.m.2              |    1.844M              |    0.738G  |\\n'\n",
      " '|    6.m.3              |    1.844M              |    0.738G  |\\n'\n",
      " '|    6.m.4              |    1.844M              |    0.738G  |\\n'\n",
      " '|    6.m.5              |    1.844M              |    0.738G  |\\n'\n",
      " '|  7                    |  3.688M                |  0.369G    |\\n'\n",
      " '|   7.conv              |   3.686M               |   0.369G   |\\n'\n",
      " '|    7.conv.weight      |    (640, 640, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.28K                |   0.128M   |\\n'\n",
      " '|    7.bn.weight        |    (640,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (640,)              |            |\\n'\n",
      " '|  8                    |  6.97M                 |  0.697G    |\\n'\n",
      " '|   8.cv1               |   0.411M               |   41.088M  |\\n'\n",
      " '|    8.cv1.conv         |    0.41M               |    40.96M  |\\n'\n",
      " '|    8.cv1.bn           |    1.28K               |    0.128M  |\\n'\n",
      " '|   8.cv2               |   1.025M               |   0.103G   |\\n'\n",
      " '|    8.cv2.conv         |    1.024M              |    0.102G  |\\n'\n",
      " '|    8.cv2.bn           |    1.28K               |    0.128M  |\\n'\n",
      " '|   8.m                 |   5.533M               |   0.553G   |\\n'\n",
      " '|    8.m.0              |    1.844M              |    0.184G  |\\n'\n",
      " '|    8.m.1              |    1.844M              |    0.184G  |\\n'\n",
      " '|    8.m.2              |    1.844M              |    0.184G  |\\n'\n",
      " '|  9                    |  1.026M                |  0.103G    |\\n'\n",
      " '|   9.cv1               |   0.205M               |   20.544M  |\\n'\n",
      " '|    9.cv1.conv         |    0.205M              |    20.48M  |\\n'\n",
      " '|    9.cv1.bn           |    0.64K               |    64K     |\\n'\n",
      " '|   9.cv2               |   0.82M                |   82.048M  |\\n'\n",
      " '|    9.cv2.conv         |    0.819M              |    81.92M  |\\n'\n",
      " '|    9.cv2.bn           |    1.28K               |    0.128M  |\\n'\n",
      " '|  12                   |  7.379M                |  2.952G    |\\n'\n",
      " '|   12.cv1              |   0.82M                |   0.328G   |\\n'\n",
      " '|    12.cv1.conv        |    0.819M              |    0.328G  |\\n'\n",
      " '|    12.cv1.bn          |    1.28K               |    0.512M  |\\n'\n",
      " '|   12.cv2              |   1.025M               |   0.41G    |\\n'\n",
      " '|    12.cv2.conv        |    1.024M              |    0.41G   |\\n'\n",
      " '|    12.cv2.bn          |    1.28K               |    0.512M  |\\n'\n",
      " '|   12.m                |   5.533M               |   2.213G   |\\n'\n",
      " '|    12.m.0             |    1.844M              |    0.738G  |\\n'\n",
      " '|    12.m.1             |    1.844M              |    0.738G  |\\n'\n",
      " '|    12.m.2             |    1.844M              |    0.738G  |\\n'\n",
      " '|  15                   |  1.949M                |  3.118G    |\\n'\n",
      " '|   15.cv1              |   0.308M               |   0.493G   |\\n'\n",
      " '|    15.cv1.conv        |    0.307M              |    0.492G  |\\n'\n",
      " '|    15.cv1.bn          |    0.64K               |    1.024M  |\\n'\n",
      " '|   15.cv2              |   0.257M               |   0.411G   |\\n'\n",
      " '|    15.cv2.conv        |    0.256M              |    0.41G   |\\n'\n",
      " '|    15.cv2.bn          |    0.64K               |    1.024M  |\\n'\n",
      " '|   15.m                |   1.384M               |   2.215G   |\\n'\n",
      " '|    15.m.0             |    0.461M              |    0.738G  |\\n'\n",
      " '|    15.m.1             |    0.461M              |    0.738G  |\\n'\n",
      " '|    15.m.2             |    0.461M              |    0.738G  |\\n'\n",
      " '|  16                   |  0.922M                |  0.369G    |\\n'\n",
      " '|   16.conv             |   0.922M               |   0.369G   |\\n'\n",
      " '|    16.conv.weight     |    (320, 320, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.64K                |   0.256M   |\\n'\n",
      " '|    16.bn.weight       |    (320,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (320,)              |            |\\n'\n",
      " '|  18                   |  7.174M                |  2.87G     |\\n'\n",
      " '|   18.cv1              |   0.616M               |   0.246G   |\\n'\n",
      " '|    18.cv1.conv        |    0.614M              |    0.246G  |\\n'\n",
      " '|    18.cv1.bn          |    1.28K               |    0.512M  |\\n'\n",
      " '|   18.cv2              |   1.025M               |   0.41G    |\\n'\n",
      " '|    18.cv2.conv        |    1.024M              |    0.41G   |\\n'\n",
      " '|    18.cv2.bn          |    1.28K               |    0.512M  |\\n'\n",
      " '|   18.m                |   5.533M               |   2.213G   |\\n'\n",
      " '|    18.m.0             |    1.844M              |    0.738G  |\\n'\n",
      " '|    18.m.1             |    1.844M              |    0.738G  |\\n'\n",
      " '|    18.m.2             |    1.844M              |    0.738G  |\\n'\n",
      " '|  19                   |  3.688M                |  0.369G    |\\n'\n",
      " '|   19.conv             |   3.686M               |   0.369G   |\\n'\n",
      " '|    19.conv.weight     |    (640, 640, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   1.28K                |   0.128M   |\\n'\n",
      " '|    19.bn.weight       |    (640,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (640,)              |            |\\n'\n",
      " '|  21                   |  7.379M                |  0.738G    |\\n'\n",
      " '|   21.cv1              |   0.82M                |   82.048M  |\\n'\n",
      " '|    21.cv1.conv        |    0.819M              |    81.92M  |\\n'\n",
      " '|    21.cv1.bn          |    1.28K               |    0.128M  |\\n'\n",
      " '|   21.cv2              |   1.025M               |   0.103G   |\\n'\n",
      " '|    21.cv2.conv        |    1.024M              |    0.102G  |\\n'\n",
      " '|    21.cv2.bn          |    1.28K               |    0.128M  |\\n'\n",
      " '|   21.m                |   5.533M               |   0.553G   |\\n'\n",
      " '|    21.m.0             |    1.844M              |    0.184G  |\\n'\n",
      " '|    21.m.1             |    1.844M              |    0.184G  |\\n'\n",
      " '|    21.m.2             |    1.844M              |    0.184G  |\\n'\n",
      " '|  22                   |  8.795M                |  5.12G     |\\n'\n",
      " '|   22.cv2              |   1.341M               |   0.731G   |\\n'\n",
      " '|    22.cv2.0           |    0.294M              |    0.47G   |\\n'\n",
      " '|    22.cv2.1           |    0.524M              |    0.21G   |\\n'\n",
      " '|    22.cv2.2           |    0.524M              |    52.384M |\\n'\n",
      " '|   22.cv3              |   7.454M               |   4.388G   |\\n'\n",
      " '|    22.cv3.0           |    1.87M               |    2.992G  |\\n'\n",
      " '|    22.cv3.1           |    2.792M              |    1.117G  |\\n'\n",
      " '|    22.cv3.2           |    2.792M              |    0.279G  |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.256M    |\\n'\n",
      " '|  13                   |                        |  1.024M    |')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"yolov8n\",\n",
    "    \"yolov8s\",\n",
    "    \"yolov8m\",\n",
    "    \"yolov8l\",\n",
    "    \"yolov8x\",\n",
    "]\n",
    "MODEL_FOLDER = \"/mnt/ssd2/xxx/repo/ultralytics/customization\"\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    model_path = os.path.join(MODEL_FOLDER, model_name)\n",
    "    model = YOLO(model_path).model\n",
    "\n",
    "    input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "    flops = FlopCountAnalysis(model, input)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    pp.pprint(flop_count_table(flops))\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolo11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: yolo11n\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 2.624M                 | 0.821G     |\\n'\n",
      " '|  0                    |  0.464K                |  11.878M   |\\n'\n",
      " '|   0.conv              |   0.432K               |   11.059M  |\\n'\n",
      " '|    0.conv.weight      |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   32                   |   0.819M   |\\n'\n",
      " '|    0.bn.weight        |    (16,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (16,)               |            |\\n'\n",
      " '|  1                    |  4.672K                |  29.901M   |\\n'\n",
      " '|   1.conv              |   4.608K               |   29.491M  |\\n'\n",
      " '|    1.conv.weight      |    (32, 16, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   64                   |   0.41M    |\\n'\n",
      " '|    1.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  2                    |  6.64K                 |  42.496M   |\\n'\n",
      " '|   2.cv1               |   1.088K               |   6.963M   |\\n'\n",
      " '|    2.cv1.conv         |    1.024K              |    6.554M  |\\n'\n",
      " '|    2.cv1.bn           |    64                  |    0.41M   |\\n'\n",
      " '|   2.cv2               |   3.2K                 |   20.48M   |\\n'\n",
      " '|    2.cv2.conv         |    3.072K              |    19.661M |\\n'\n",
      " '|    2.cv2.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.m.0               |   2.352K               |   15.053M  |\\n'\n",
      " '|    2.m.0.cv1          |    1.168K              |    7.475M  |\\n'\n",
      " '|    2.m.0.cv2          |    1.184K              |    7.578M  |\\n'\n",
      " '|  3                    |  36.992K               |  59.187M   |\\n'\n",
      " '|   3.conv              |   36.864K              |   58.982M  |\\n'\n",
      " '|    3.conv.weight      |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   3.bn                |   0.128K               |   0.205M   |\\n'\n",
      " '|    3.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    3.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  4                    |  26.08K                |  41.728M   |\\n'\n",
      " '|   4.cv1               |   4.224K               |   6.758M   |\\n'\n",
      " '|    4.cv1.conv         |    4.096K              |    6.554M  |\\n'\n",
      " '|    4.cv1.bn           |    0.128K              |    0.205M  |\\n'\n",
      " '|   4.cv2               |   12.544K              |   20.07M   |\\n'\n",
      " '|    4.cv2.conv         |    12.288K             |    19.661M |\\n'\n",
      " '|    4.cv2.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.m.0               |   9.312K               |   14.899M  |\\n'\n",
      " '|    4.m.0.cv1          |    4.64K               |    7.424M  |\\n'\n",
      " '|    4.m.0.cv2          |    4.672K              |    7.475M  |\\n'\n",
      " '|  5                    |  0.148M                |  59.085M   |\\n'\n",
      " '|   5.conv              |   0.147M               |   58.982M  |\\n'\n",
      " '|    5.conv.weight      |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.256K               |   0.102M   |\\n'\n",
      " '|    5.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  6                    |  87.04K                |  34.816M   |\\n'\n",
      " '|   6.cv1               |   16.64K               |   6.656M   |\\n'\n",
      " '|    6.cv1.conv         |    16.384K             |    6.554M  |\\n'\n",
      " '|    6.cv1.bn           |    0.256K              |    0.102M  |\\n'\n",
      " '|   6.cv2               |   24.832K              |   9.933M   |\\n'\n",
      " '|    6.cv2.conv         |    24.576K             |    9.83M   |\\n'\n",
      " '|    6.cv2.bn           |    0.256K              |    0.102M  |\\n'\n",
      " '|   6.m.0               |   45.568K              |   18.227M  |\\n'\n",
      " '|    6.m.0.cv1          |    2.112K              |    0.845M  |\\n'\n",
      " '|    6.m.0.cv2          |    2.112K              |    0.845M  |\\n'\n",
      " '|    6.m.0.cv3          |    4.224K              |    1.69M   |\\n'\n",
      " '|    6.m.0.m            |    37.12K              |    14.848M |\\n'\n",
      " '|  7                    |  0.295M                |  29.542M   |\\n'\n",
      " '|   7.conv              |   0.295M               |   29.491M  |\\n'\n",
      " '|    7.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   0.512K               |   51.2K    |\\n'\n",
      " '|    7.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  8                    |  0.346M                |  34.611M   |\\n'\n",
      " '|   8.cv1               |   66.048K              |   6.605M   |\\n'\n",
      " '|    8.cv1.conv         |    65.536K             |    6.554M  |\\n'\n",
      " '|    8.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   8.cv2               |   98.816K              |   9.882M   |\\n'\n",
      " '|    8.cv2.conv         |    98.304K             |    9.83M   |\\n'\n",
      " '|    8.cv2.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   8.m.0               |   0.181M               |   18.125M  |\\n'\n",
      " '|    8.m.0.cv1          |    8.32K               |    0.832M  |\\n'\n",
      " '|    8.m.0.cv2          |    8.32K               |    0.832M  |\\n'\n",
      " '|    8.m.0.cv3          |    16.64K              |    1.664M  |\\n'\n",
      " '|    8.m.0.m            |    0.148M              |    14.797M |\\n'\n",
      " '|  9                    |  0.165M                |  16.461M   |\\n'\n",
      " '|   9.cv1               |   33.024K              |   3.302M   |\\n'\n",
      " '|    9.cv1.conv         |    32.768K             |    3.277M  |\\n'\n",
      " '|    9.cv1.bn           |    0.256K              |    25.6K   |\\n'\n",
      " '|   9.cv2               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv2.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv2.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|  10                   |  0.25M                 |  26.893M   |\\n'\n",
      " '|   10.cv1              |   66.048K              |   6.605M   |\\n'\n",
      " '|    10.cv1.conv        |    65.536K             |    6.554M  |\\n'\n",
      " '|    10.cv1.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   10.cv2              |   66.048K              |   6.605M   |\\n'\n",
      " '|    10.cv2.conv        |    65.536K             |    6.554M  |\\n'\n",
      " '|    10.cv2.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   10.m.0              |   0.118M               |   13.683M  |\\n'\n",
      " '|    10.m.0.attn        |    51.328K             |    7.053M  |\\n'\n",
      " '|    10.m.0.ffn         |    66.304K             |    6.63M   |\\n'\n",
      " '|  13                   |  0.111M                |  44.518M   |\\n'\n",
      " '|   13.cv1              |   49.408K              |   19.763M  |\\n'\n",
      " '|    13.cv1.conv        |    49.152K             |    19.661M |\\n'\n",
      " '|    13.cv1.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   13.cv2              |   24.832K              |   9.933M   |\\n'\n",
      " '|    13.cv2.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    13.cv2.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   13.m.0              |   37.056K              |   14.822M  |\\n'\n",
      " '|    13.m.0.cv1         |    18.496K             |    7.398M  |\\n'\n",
      " '|    13.m.0.cv2         |    18.56K              |    7.424M  |\\n'\n",
      " '|  16                   |  32.096K               |  51.354M   |\\n'\n",
      " '|   16.cv1              |   16.512K              |   26.419M  |\\n'\n",
      " '|    16.cv1.conv        |    16.384K             |    26.214M |\\n'\n",
      " '|    16.cv1.bn          |    0.128K              |    0.205M  |\\n'\n",
      " '|   16.cv2              |   6.272K               |   10.035M  |\\n'\n",
      " '|    16.cv2.conv        |    6.144K              |    9.83M   |\\n'\n",
      " '|    16.cv2.bn          |    0.128K              |    0.205M  |\\n'\n",
      " '|   16.m.0              |   9.312K               |   14.899M  |\\n'\n",
      " '|    16.m.0.cv1         |    4.64K               |    7.424M  |\\n'\n",
      " '|    16.m.0.cv2         |    4.672K              |    7.475M  |\\n'\n",
      " '|  17                   |  36.992K               |  14.797M   |\\n'\n",
      " '|   17.conv             |   36.864K              |   14.746M  |\\n'\n",
      " '|    17.conv.weight     |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   17.bn               |   0.128K               |   51.2K    |\\n'\n",
      " '|    17.bn.weight       |    (64,)               |            |\\n'\n",
      " '|    17.bn.bias         |    (64,)               |            |\\n'\n",
      " '|  19                   |  86.72K                |  34.688M   |\\n'\n",
      " '|   19.cv1              |   24.832K              |   9.933M   |\\n'\n",
      " '|    19.cv1.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    19.cv1.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   19.cv2              |   24.832K              |   9.933M   |\\n'\n",
      " '|    19.cv2.conv        |    24.576K             |    9.83M   |\\n'\n",
      " '|    19.cv2.bn          |    0.256K              |    0.102M  |\\n'\n",
      " '|   19.m.0              |   37.056K              |   14.822M  |\\n'\n",
      " '|    19.m.0.cv1         |    18.496K             |    7.398M  |\\n'\n",
      " '|    19.m.0.cv2         |    18.56K              |    7.424M  |\\n'\n",
      " '|  20                   |  0.148M                |  14.771M   |\\n'\n",
      " '|   20.conv             |   0.147M               |   14.746M  |\\n'\n",
      " '|    20.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   20.bn               |   0.256K               |   25.6K    |\\n'\n",
      " '|    20.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    20.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  22                   |  0.379M                |  37.888M   |\\n'\n",
      " '|   22.cv1              |   98.816K              |   9.882M   |\\n'\n",
      " '|    22.cv1.conv        |    98.304K             |    9.83M   |\\n'\n",
      " '|    22.cv1.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   22.cv2              |   98.816K              |   9.882M   |\\n'\n",
      " '|    22.cv2.conv        |    98.304K             |    9.83M   |\\n'\n",
      " '|    22.cv2.bn          |    0.512K              |    51.2K   |\\n'\n",
      " '|   22.m.0              |   0.181M               |   18.125M  |\\n'\n",
      " '|    22.m.0.cv1         |    8.32K               |    0.832M  |\\n'\n",
      " '|    22.m.0.cv2         |    8.32K               |    0.832M  |\\n'\n",
      " '|    22.m.0.cv3         |    16.64K              |    1.664M  |\\n'\n",
      " '|    22.m.0.m           |    0.148M              |    14.797M |\\n'\n",
      " '|  23                   |  0.465M                |  0.236G    |\\n'\n",
      " '|   23.cv2              |   0.382M               |   0.19G    |\\n'\n",
      " '|    23.cv2.0           |    78.144K             |    0.125G  |\\n'\n",
      " '|    23.cv2.1           |    0.115M              |    45.978M |\\n'\n",
      " '|    23.cv2.2           |    0.189M              |    18.867M |\\n'\n",
      " '|   23.cv3              |   83.008K              |   45.707M  |\\n'\n",
      " '|    23.cv3.0           |    19.904K             |    31.718M |\\n'\n",
      " '|    23.cv3.1           |    25.728K             |    10.259M |\\n'\n",
      " '|    23.cv3.2           |    37.376K             |    3.73M   |\\n'\n",
      " '|   23.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    23.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  11                   |                        |  0.102M    |\\n'\n",
      " '|  14                   |                        |  0.205M    |')\n",
      "--------------------\n",
      "Model: yolo11s\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 9.459M                 | 2.703G     |\\n'\n",
      " '|  0                    |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.conv              |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.conv.weight      |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   64                   |   1.638M   |\\n'\n",
      " '|    0.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  1                    |  18.56K                |  0.119G    |\\n'\n",
      " '|   1.conv              |   18.432K              |   0.118G   |\\n'\n",
      " '|    1.conv.weight      |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.128K               |   0.819M   |\\n'\n",
      " '|    1.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  2                    |  26.08K                |  0.167G    |\\n'\n",
      " '|   2.cv1               |   4.224K               |   27.034M  |\\n'\n",
      " '|    2.cv1.conv         |    4.096K              |    26.214M |\\n'\n",
      " '|    2.cv1.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.cv2               |   12.544K              |   80.282M  |\\n'\n",
      " '|    2.cv2.conv         |    12.288K             |    78.643M |\\n'\n",
      " '|    2.cv2.bn           |    0.256K              |    1.638M  |\\n'\n",
      " '|   2.m.0               |   9.312K               |   59.597M  |\\n'\n",
      " '|    2.m.0.cv1          |    4.64K               |    29.696M |\\n'\n",
      " '|    2.m.0.cv2          |    4.672K              |    29.901M |\\n'\n",
      " '|  3                    |  0.148M                |  0.236G    |\\n'\n",
      " '|   3.conv              |   0.147M               |   0.236G   |\\n'\n",
      " '|    3.conv.weight      |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.256K               |   0.41M    |\\n'\n",
      " '|    3.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  4                    |  0.103M                |  0.165G    |\\n'\n",
      " '|   4.cv1               |   16.64K               |   26.624M  |\\n'\n",
      " '|    4.cv1.conv         |    16.384K             |    26.214M |\\n'\n",
      " '|    4.cv1.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.cv2               |   49.664K              |   79.462M  |\\n'\n",
      " '|    4.cv2.conv         |    49.152K             |    78.643M |\\n'\n",
      " '|    4.cv2.bn           |    0.512K              |    0.819M  |\\n'\n",
      " '|   4.m.0               |   37.056K              |   59.29M   |\\n'\n",
      " '|    4.m.0.cv1          |    18.496K             |    29.594M |\\n'\n",
      " '|    4.m.0.cv2          |    18.56K              |    29.696M |\\n'\n",
      " '|  5                    |  0.59M                 |  0.236G    |\\n'\n",
      " '|   5.conv              |   0.59M                |   0.236G   |\\n'\n",
      " '|    5.conv.weight      |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.512K               |   0.205M   |\\n'\n",
      " '|    5.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  6                    |  0.346M                |  0.138G    |\\n'\n",
      " '|   6.cv1               |   66.048K              |   26.419M  |\\n'\n",
      " '|    6.cv1.conv         |    65.536K             |    26.214M |\\n'\n",
      " '|    6.cv1.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.cv2               |   98.816K              |   39.526M  |\\n'\n",
      " '|    6.cv2.conv         |    98.304K             |    39.322M |\\n'\n",
      " '|    6.cv2.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.m.0               |   0.181M               |   72.499M  |\\n'\n",
      " '|    6.m.0.cv1          |    8.32K               |    3.328M  |\\n'\n",
      " '|    6.m.0.cv2          |    8.32K               |    3.328M  |\\n'\n",
      " '|    6.m.0.cv3          |    16.64K              |    6.656M  |\\n'\n",
      " '|    6.m.0.m            |    0.148M              |    59.187M |\\n'\n",
      " '|  7                    |  1.181M                |  0.118G    |\\n'\n",
      " '|   7.conv              |   1.18M                |   0.118G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  1.38M                 |  0.138G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.394M               |   39.424M  |\\n'\n",
      " '|    8.cv2.conv         |    0.393M              |    39.322M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m.0               |   0.723M               |   72.294M  |\\n'\n",
      " '|    8.m.0.cv1          |    33.024K             |    3.302M  |\\n'\n",
      " '|    8.m.0.cv2          |    33.024K             |    3.302M  |\\n'\n",
      " '|    8.m.0.cv3          |    66.048K             |    6.605M  |\\n'\n",
      " '|    8.m.0.m            |    0.591M              |    59.085M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  10                   |  0.991M                |  0.103G    |\\n'\n",
      " '|   10.cv1              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv1.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.cv2              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv2.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.m.0              |   0.465M               |   50.304M  |\\n'\n",
      " '|    10.m.0.attn        |    0.201M              |    23.936M |\\n'\n",
      " '|    10.m.0.ffn         |    0.264M              |    26.368M |\\n'\n",
      " '|  13                   |  0.444M                |  0.178G    |\\n'\n",
      " '|   13.cv1              |   0.197M               |   78.848M  |\\n'\n",
      " '|    13.cv1.conv        |    0.197M              |    78.643M |\\n'\n",
      " '|    13.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   13.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    13.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    13.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   13.m.0              |   0.148M               |   59.136M  |\\n'\n",
      " '|    13.m.0.cv1         |    73.856K             |    29.542M |\\n'\n",
      " '|    13.m.0.cv2         |    73.984K             |    29.594M |\\n'\n",
      " '|  16                   |  0.128M                |  0.204G    |\\n'\n",
      " '|   16.cv1              |   65.792K              |   0.105G   |\\n'\n",
      " '|    16.cv1.conv        |    65.536K             |    0.105G  |\\n'\n",
      " '|    16.cv1.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   16.cv2              |   24.832K              |   39.731M  |\\n'\n",
      " '|    16.cv2.conv        |    24.576K             |    39.322M |\\n'\n",
      " '|    16.cv2.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   16.m.0              |   37.056K              |   59.29M   |\\n'\n",
      " '|    16.m.0.cv1         |    18.496K             |    29.594M |\\n'\n",
      " '|    16.m.0.cv2         |    18.56K              |    29.696M |\\n'\n",
      " '|  17                   |  0.148M                |  59.085M   |\\n'\n",
      " '|   17.conv             |   0.147M               |   58.982M  |\\n'\n",
      " '|    17.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   17.bn               |   0.256K               |   0.102M   |\\n'\n",
      " '|    17.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    17.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  19                   |  0.345M                |  0.138G    |\\n'\n",
      " '|   19.cv1              |   98.816K              |   39.526M  |\\n'\n",
      " '|    19.cv1.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    19.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   19.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    19.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    19.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   19.m.0              |   0.148M               |   59.136M  |\\n'\n",
      " '|    19.m.0.cv1         |    73.856K             |    29.542M |\\n'\n",
      " '|    19.m.0.cv2         |    73.984K             |    29.594M |\\n'\n",
      " '|  20                   |  0.59M                 |  59.034M   |\\n'\n",
      " '|   20.conv             |   0.59M                |   58.982M  |\\n'\n",
      " '|    20.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   20.bn               |   0.512K               |   51.2K    |\\n'\n",
      " '|    20.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    20.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  22                   |  1.511M                |  0.151G    |\\n'\n",
      " '|   22.cv1              |   0.394M               |   39.424M  |\\n'\n",
      " '|    22.cv1.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    22.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.cv2              |   0.394M               |   39.424M  |\\n'\n",
      " '|    22.cv2.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    22.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.m.0              |   0.723M               |   72.294M  |\\n'\n",
      " '|    22.m.0.cv1         |    33.024K             |    3.302M  |\\n'\n",
      " '|    22.m.0.cv2         |    33.024K             |    3.302M  |\\n'\n",
      " '|    22.m.0.cv3         |    66.048K             |    6.605M  |\\n'\n",
      " '|    22.m.0.m           |    0.591M              |    59.085M |\\n'\n",
      " '|  23                   |  0.85M                 |  0.403G    |\\n'\n",
      " '|   23.cv2              |   0.64M                |   0.293G   |\\n'\n",
      " '|    23.cv2.0           |    0.115M              |    0.184G  |\\n'\n",
      " '|    23.cv2.1           |    0.189M              |    75.469M |\\n'\n",
      " '|    23.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   23.cv3              |   0.21M                |   0.11G    |\\n'\n",
      " '|    23.cv3.0           |    46.416K             |    74.138M |\\n'\n",
      " '|    23.cv3.1           |    64.208K             |    25.651M |\\n'\n",
      " '|    23.cv3.2           |    99.792K             |    9.971M  |\\n'\n",
      " '|   23.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    23.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  11                   |                        |  0.205M    |\\n'\n",
      " '|  14                   |                        |  0.41M     |')\n",
      "--------------------\n",
      "Model: yolo11m\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 20.115M                | 8.536G     |\\n'\n",
      " '|  0                    |  1.856K                |  47.514M   |\\n'\n",
      " '|   0.conv              |   1.728K               |   44.237M  |\\n'\n",
      " '|    0.conv.weight      |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   0.128K               |   3.277M   |\\n'\n",
      " '|    0.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  1                    |  73.984K               |  0.473G    |\\n'\n",
      " '|   1.conv              |   73.728K              |   0.472G   |\\n'\n",
      " '|    1.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   1.bn                |   0.256K               |   1.638M   |\\n'\n",
      " '|    1.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    1.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  2                    |  0.112M                |  0.716G    |\\n'\n",
      " '|   2.cv1               |   16.64K               |   0.106G   |\\n'\n",
      " '|    2.cv1.conv         |    16.384K             |    0.105G  |\\n'\n",
      " '|    2.cv1.bn           |    0.256K              |    1.638M  |\\n'\n",
      " '|   2.cv2               |   49.664K              |   0.318G   |\\n'\n",
      " '|    2.cv2.conv         |    49.152K             |    0.315G  |\\n'\n",
      " '|    2.cv2.bn           |    0.512K              |    3.277M  |\\n'\n",
      " '|   2.m.0               |   45.568K              |   0.292G   |\\n'\n",
      " '|    2.m.0.cv1          |    2.112K              |    13.517M |\\n'\n",
      " '|    2.m.0.cv2          |    2.112K              |    13.517M |\\n'\n",
      " '|    2.m.0.cv3          |    4.224K              |    27.034M |\\n'\n",
      " '|    2.m.0.m            |    37.12K              |    0.238G  |\\n'\n",
      " '|  3                    |  0.59M                 |  0.945G    |\\n'\n",
      " '|   3.conv              |   0.59M                |   0.944G   |\\n'\n",
      " '|    3.conv.weight      |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.512K               |   0.819M   |\\n'\n",
      " '|    3.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  4                    |  0.445M                |  0.712G    |\\n'\n",
      " '|   4.cv1               |   66.048K              |   0.106G   |\\n'\n",
      " '|    4.cv1.conv         |    65.536K             |    0.105G  |\\n'\n",
      " '|    4.cv1.bn           |    0.512K              |    0.819M  |\\n'\n",
      " '|   4.cv2               |   0.198M               |   0.316G   |\\n'\n",
      " '|    4.cv2.conv         |    0.197M              |    0.315G  |\\n'\n",
      " '|    4.cv2.bn           |    1.024K              |    1.638M  |\\n'\n",
      " '|   4.m.0               |   0.181M               |   0.29G    |\\n'\n",
      " '|    4.m.0.cv1          |    8.32K               |    13.312M |\\n'\n",
      " '|    4.m.0.cv2          |    8.32K               |    13.312M |\\n'\n",
      " '|    4.m.0.cv3          |    16.64K              |    26.624M |\\n'\n",
      " '|    4.m.0.m            |    0.148M              |    0.237G  |\\n'\n",
      " '|  5                    |  2.36M                 |  0.944G    |\\n'\n",
      " '|   5.conv              |   2.359M               |   0.944G   |\\n'\n",
      " '|    5.conv.weight      |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   1.024K               |   0.41M    |\\n'\n",
      " '|    5.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  6                    |  1.38M                 |  0.552G    |\\n'\n",
      " '|   6.cv1               |   0.263M               |   0.105G   |\\n'\n",
      " '|    6.cv1.conv         |    0.262M              |    0.105G  |\\n'\n",
      " '|    6.cv1.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.cv2               |   0.394M               |   0.158G   |\\n'\n",
      " '|    6.cv2.conv         |    0.393M              |    0.157G  |\\n'\n",
      " '|    6.cv2.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.m.0               |   0.723M               |   0.289G   |\\n'\n",
      " '|    6.m.0.cv1          |    33.024K             |    13.21M  |\\n'\n",
      " '|    6.m.0.cv2          |    33.024K             |    13.21M  |\\n'\n",
      " '|    6.m.0.cv3          |    66.048K             |    26.419M |\\n'\n",
      " '|    6.m.0.m            |    0.591M              |    0.236G  |\\n'\n",
      " '|  7                    |  2.36M                 |  0.236G    |\\n'\n",
      " '|   7.conv              |   2.359M               |   0.236G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  1.38M                 |  0.138G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.394M               |   39.424M  |\\n'\n",
      " '|    8.cv2.conv         |    0.393M              |    39.322M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m.0               |   0.723M               |   72.294M  |\\n'\n",
      " '|    8.m.0.cv1          |    33.024K             |    3.302M  |\\n'\n",
      " '|    8.m.0.cv2          |    33.024K             |    3.302M  |\\n'\n",
      " '|    8.m.0.cv3          |    66.048K             |    6.605M  |\\n'\n",
      " '|    8.m.0.m            |    0.591M              |    59.085M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  10                   |  0.991M                |  0.103G    |\\n'\n",
      " '|   10.cv1              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv1.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.cv2              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv2.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.m.0              |   0.465M               |   50.304M  |\\n'\n",
      " '|    10.m.0.attn        |    0.201M              |    23.936M |\\n'\n",
      " '|    10.m.0.ffn         |    0.264M              |    26.368M |\\n'\n",
      " '|  13                   |  1.642M                |  0.657G    |\\n'\n",
      " '|   13.cv1              |   0.525M               |   0.21G    |\\n'\n",
      " '|    13.cv1.conv        |    0.524M              |    0.21G   |\\n'\n",
      " '|    13.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   13.cv2              |   0.394M               |   0.158G   |\\n'\n",
      " '|    13.cv2.conv        |    0.393M              |    0.157G  |\\n'\n",
      " '|    13.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   13.m.0              |   0.723M               |   0.289G   |\\n'\n",
      " '|    13.m.0.cv1         |    33.024K             |    13.21M  |\\n'\n",
      " '|    13.m.0.cv2         |    33.024K             |    13.21M  |\\n'\n",
      " '|    13.m.0.cv3         |    66.048K             |    26.419M |\\n'\n",
      " '|    13.m.0.m           |    0.591M              |    0.236G  |\\n'\n",
      " '|  16                   |  0.543M                |  0.868G    |\\n'\n",
      " '|   16.cv1              |   0.263M               |   0.42G    |\\n'\n",
      " '|    16.cv1.conv        |    0.262M              |    0.419G  |\\n'\n",
      " '|    16.cv1.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   16.cv2              |   98.816K              |   0.158G   |\\n'\n",
      " '|    16.cv2.conv        |    98.304K             |    0.157G  |\\n'\n",
      " '|    16.cv2.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   16.m.0              |   0.181M               |   0.29G    |\\n'\n",
      " '|    16.m.0.cv1         |    8.32K               |    13.312M |\\n'\n",
      " '|    16.m.0.cv2         |    8.32K               |    13.312M |\\n'\n",
      " '|    16.m.0.cv3         |    16.64K              |    26.624M |\\n'\n",
      " '|    16.m.0.m           |    0.148M              |    0.237G  |\\n'\n",
      " '|  17                   |  0.59M                 |  0.236G    |\\n'\n",
      " '|   17.conv             |   0.59M                |   0.236G   |\\n'\n",
      " '|    17.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   17.bn               |   0.512K               |   0.205M   |\\n'\n",
      " '|    17.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    17.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  19                   |  1.511M                |  0.605G    |\\n'\n",
      " '|   19.cv1              |   0.394M               |   0.158G   |\\n'\n",
      " '|    19.cv1.conv        |    0.393M              |    0.157G  |\\n'\n",
      " '|    19.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   19.cv2              |   0.394M               |   0.158G   |\\n'\n",
      " '|    19.cv2.conv        |    0.393M              |    0.157G  |\\n'\n",
      " '|    19.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   19.m.0              |   0.723M               |   0.289G   |\\n'\n",
      " '|    19.m.0.cv1         |    33.024K             |    13.21M  |\\n'\n",
      " '|    19.m.0.cv2         |    33.024K             |    13.21M  |\\n'\n",
      " '|    19.m.0.cv3         |    66.048K             |    26.419M |\\n'\n",
      " '|    19.m.0.m           |    0.591M              |    0.236G  |\\n'\n",
      " '|  20                   |  2.36M                 |  0.236G    |\\n'\n",
      " '|   20.conv             |   2.359M               |   0.236G   |\\n'\n",
      " '|    20.conv.weight     |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   20.bn               |   1.024K               |   0.102M   |\\n'\n",
      " '|    20.bn.weight       |    (512,)              |            |\\n'\n",
      " '|    20.bn.bias         |    (512,)              |            |\\n'\n",
      " '|  22                   |  1.642M                |  0.164G    |\\n'\n",
      " '|   22.cv1              |   0.525M               |   52.531M  |\\n'\n",
      " '|    22.cv1.conv        |    0.524M              |    52.429M |\\n'\n",
      " '|    22.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.cv2              |   0.394M               |   39.424M  |\\n'\n",
      " '|    22.cv2.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    22.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.m.0              |   0.723M               |   72.294M  |\\n'\n",
      " '|    22.m.0.cv1         |    33.024K             |    3.302M  |\\n'\n",
      " '|    22.m.0.cv2         |    33.024K             |    3.302M  |\\n'\n",
      " '|    22.m.0.cv3         |    66.048K             |    6.605M  |\\n'\n",
      " '|    22.m.0.m           |    0.591M              |    59.085M |\\n'\n",
      " '|  23                   |  1.473M                |  0.836G    |\\n'\n",
      " '|   23.cv2              |   0.861M               |   0.47G    |\\n'\n",
      " '|    23.cv2.0           |    0.189M              |    0.302G  |\\n'\n",
      " '|    23.cv2.1           |    0.336M              |    0.134G  |\\n'\n",
      " '|    23.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   23.cv3              |   0.612M               |   0.366G   |\\n'\n",
      " '|    23.cv3.0           |    0.158M              |    0.253G  |\\n'\n",
      " '|    23.cv3.1           |    0.227M              |    90.624M |\\n'\n",
      " '|    23.cv3.2           |    0.227M              |    22.656M |\\n'\n",
      " '|   23.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    23.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  11                   |                        |  0.205M    |\\n'\n",
      " '|  14                   |                        |  0.819M    |')\n",
      "--------------------\n",
      "Model: yolo11l\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 25.372M                | 10.916G    |\\n'\n",
      " '|  0                    |  1.856K                |  47.514M   |\\n'\n",
      " '|   0.conv              |   1.728K               |   44.237M  |\\n'\n",
      " '|    0.conv.weight      |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   0.128K               |   3.277M   |\\n'\n",
      " '|    0.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  1                    |  73.984K               |  0.473G    |\\n'\n",
      " '|   1.conv              |   73.728K              |   0.472G   |\\n'\n",
      " '|    1.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   1.bn                |   0.256K               |   1.638M   |\\n'\n",
      " '|    1.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    1.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  2                    |  0.174M                |  1.112G    |\\n'\n",
      " '|   2.cv1               |   16.64K               |   0.106G   |\\n'\n",
      " '|    2.cv1.conv         |    16.384K             |    0.105G  |\\n'\n",
      " '|    2.cv1.bn           |    0.256K              |    1.638M  |\\n'\n",
      " '|   2.cv2               |   66.048K              |   0.423G   |\\n'\n",
      " '|    2.cv2.conv         |    65.536K             |    0.419G  |\\n'\n",
      " '|    2.cv2.bn           |    0.512K              |    3.277M  |\\n'\n",
      " '|   2.m                 |   91.136K              |   0.583G   |\\n'\n",
      " '|    2.m.0              |    45.568K             |    0.292G  |\\n'\n",
      " '|    2.m.1              |    45.568K             |    0.292G  |\\n'\n",
      " '|  3                    |  0.59M                 |  0.945G    |\\n'\n",
      " '|   3.conv              |   0.59M                |   0.944G   |\\n'\n",
      " '|    3.conv.weight      |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.512K               |   0.819M   |\\n'\n",
      " '|    3.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  4                    |  0.692M                |  1.107G    |\\n'\n",
      " '|   4.cv1               |   66.048K              |   0.106G   |\\n'\n",
      " '|    4.cv1.conv         |    65.536K             |    0.105G  |\\n'\n",
      " '|    4.cv1.bn           |    0.512K              |    0.819M  |\\n'\n",
      " '|   4.cv2               |   0.263M               |   0.421G   |\\n'\n",
      " '|    4.cv2.conv         |    0.262M              |    0.419G  |\\n'\n",
      " '|    4.cv2.bn           |    1.024K              |    1.638M  |\\n'\n",
      " '|   4.m                 |   0.362M               |   0.58G    |\\n'\n",
      " '|    4.m.0              |    0.181M              |    0.29G   |\\n'\n",
      " '|    4.m.1              |    0.181M              |    0.29G   |\\n'\n",
      " '|  5                    |  2.36M                 |  0.944G    |\\n'\n",
      " '|   5.conv              |   2.359M               |   0.944G   |\\n'\n",
      " '|    5.conv.weight      |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   1.024K               |   0.41M    |\\n'\n",
      " '|    5.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  6                    |  2.234M                |  0.894G    |\\n'\n",
      " '|   6.cv1               |   0.263M               |   0.105G   |\\n'\n",
      " '|    6.cv1.conv         |    0.262M              |    0.105G  |\\n'\n",
      " '|    6.cv1.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.cv2               |   0.525M               |   0.21G    |\\n'\n",
      " '|    6.cv2.conv         |    0.524M              |    0.21G   |\\n'\n",
      " '|    6.cv2.bn           |    1.024K              |    0.41M   |\\n'\n",
      " '|   6.m                 |   1.446M               |   0.578G   |\\n'\n",
      " '|    6.m.0              |    0.723M              |    0.289G  |\\n'\n",
      " '|    6.m.1              |    0.723M              |    0.289G  |\\n'\n",
      " '|  7                    |  2.36M                 |  0.236G    |\\n'\n",
      " '|   7.conv              |   2.359M               |   0.236G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  2.234M                |  0.223G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    8.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m                 |   1.446M               |   0.145G   |\\n'\n",
      " '|    8.m.0              |    0.723M              |    72.294M |\\n'\n",
      " '|    8.m.1              |    0.723M              |    72.294M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  10                   |  1.456M                |  0.153G    |\\n'\n",
      " '|   10.cv1              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv1.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.cv2              |   0.263M               |   26.317M  |\\n'\n",
      " '|    10.cv2.conv        |    0.262M              |    26.214M |\\n'\n",
      " '|    10.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   10.m                |   0.929M               |   0.101G   |\\n'\n",
      " '|    10.m.0             |    0.465M              |    50.304M |\\n'\n",
      " '|    10.m.1             |    0.465M              |    50.304M |\\n'\n",
      " '|  13                   |  2.497M                |  0.999G    |\\n'\n",
      " '|   13.cv1              |   0.525M               |   0.21G    |\\n'\n",
      " '|    13.cv1.conv        |    0.524M              |    0.21G   |\\n'\n",
      " '|    13.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   13.cv2              |   0.525M               |   0.21G    |\\n'\n",
      " '|    13.cv2.conv        |    0.524M              |    0.21G   |\\n'\n",
      " '|    13.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   13.m                |   1.446M               |   0.578G   |\\n'\n",
      " '|    13.m.0             |    0.723M              |    0.289G  |\\n'\n",
      " '|    13.m.1             |    0.723M              |    0.289G  |\\n'\n",
      " '|  16                   |  0.757M                |  1.211G    |\\n'\n",
      " '|   16.cv1              |   0.263M               |   0.42G    |\\n'\n",
      " '|    16.cv1.conv        |    0.262M              |    0.419G  |\\n'\n",
      " '|    16.cv1.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   16.cv2              |   0.132M               |   0.211G   |\\n'\n",
      " '|    16.cv2.conv        |    0.131M              |    0.21G   |\\n'\n",
      " '|    16.cv2.bn          |    0.512K              |    0.819M  |\\n'\n",
      " '|   16.m                |   0.362M               |   0.58G    |\\n'\n",
      " '|    16.m.0             |    0.181M              |    0.29G   |\\n'\n",
      " '|    16.m.1             |    0.181M              |    0.29G   |\\n'\n",
      " '|  17                   |  0.59M                 |  0.236G    |\\n'\n",
      " '|   17.conv             |   0.59M                |   0.236G   |\\n'\n",
      " '|    17.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   17.bn               |   0.512K               |   0.205M   |\\n'\n",
      " '|    17.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    17.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  19                   |  2.365M                |  0.946G    |\\n'\n",
      " '|   19.cv1              |   0.394M               |   0.158G   |\\n'\n",
      " '|    19.cv1.conv        |    0.393M              |    0.157G  |\\n'\n",
      " '|    19.cv1.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   19.cv2              |   0.525M               |   0.21G    |\\n'\n",
      " '|    19.cv2.conv        |    0.524M              |    0.21G   |\\n'\n",
      " '|    19.cv2.bn          |    1.024K              |    0.41M   |\\n'\n",
      " '|   19.m                |   1.446M               |   0.578G   |\\n'\n",
      " '|    19.m.0             |    0.723M              |    0.289G  |\\n'\n",
      " '|    19.m.1             |    0.723M              |    0.289G  |\\n'\n",
      " '|  20                   |  2.36M                 |  0.236G    |\\n'\n",
      " '|   20.conv             |   2.359M               |   0.236G   |\\n'\n",
      " '|    20.conv.weight     |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   20.bn               |   1.024K               |   0.102M   |\\n'\n",
      " '|    20.bn.weight       |    (512,)              |            |\\n'\n",
      " '|    20.bn.bias         |    (512,)              |            |\\n'\n",
      " '|  22                   |  2.497M                |  0.25G     |\\n'\n",
      " '|   22.cv1              |   0.525M               |   52.531M  |\\n'\n",
      " '|    22.cv1.conv        |    0.524M              |    52.429M |\\n'\n",
      " '|    22.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.cv2              |   0.525M               |   52.531M  |\\n'\n",
      " '|    22.cv2.conv        |    0.524M              |    52.429M |\\n'\n",
      " '|    22.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   22.m                |   1.446M               |   0.145G   |\\n'\n",
      " '|    22.m.0             |    0.723M              |    72.294M |\\n'\n",
      " '|    22.m.1             |    0.723M              |    72.294M |\\n'\n",
      " '|  23                   |  1.473M                |  0.836G    |\\n'\n",
      " '|   23.cv2              |   0.861M               |   0.47G    |\\n'\n",
      " '|    23.cv2.0           |    0.189M              |    0.302G  |\\n'\n",
      " '|    23.cv2.1           |    0.336M              |    0.134G  |\\n'\n",
      " '|    23.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   23.cv3              |   0.612M               |   0.366G   |\\n'\n",
      " '|    23.cv3.0           |    0.158M              |    0.253G  |\\n'\n",
      " '|    23.cv3.1           |    0.227M              |    90.624M |\\n'\n",
      " '|    23.cv3.2           |    0.227M              |    22.656M |\\n'\n",
      " '|   23.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    23.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  11                   |                        |  0.205M    |\\n'\n",
      " '|  14                   |                        |  0.819M    |')\n",
      "--------------------\n",
      "Model: yolo11x\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 56.966M                | 24.441G    |\\n'\n",
      " '|  0                    |  2.784K                |  71.27M    |\\n'\n",
      " '|   0.conv              |   2.592K               |   66.355M  |\\n'\n",
      " '|    0.conv.weight      |    (96, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   0.192K               |   4.915M   |\\n'\n",
      " '|    0.bn.weight        |    (96,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (96,)               |            |\\n'\n",
      " '|  1                    |  0.166M                |  1.064G    |\\n'\n",
      " '|   1.conv              |   0.166M               |   1.062G   |\\n'\n",
      " '|    1.conv.weight      |    (192, 96, 3, 3)     |            |\\n'\n",
      " '|   1.bn                |   0.384K               |   2.458M   |\\n'\n",
      " '|    1.bn.weight        |    (192,)              |            |\\n'\n",
      " '|    1.bn.bias          |    (192,)              |            |\\n'\n",
      " '|  2                    |  0.39M                 |  2.494G    |\\n'\n",
      " '|   2.cv1               |   37.248K              |   0.238G   |\\n'\n",
      " '|    2.cv1.conv         |    36.864K             |    0.236G  |\\n'\n",
      " '|    2.cv1.bn           |    0.384K              |    2.458M  |\\n'\n",
      " '|   2.cv2               |   0.148M               |   0.949G   |\\n'\n",
      " '|    2.cv2.conv         |    0.147M              |    0.944G  |\\n'\n",
      " '|    2.cv2.bn           |    0.768K              |    4.915M  |\\n'\n",
      " '|   2.m                 |   0.204M               |   1.307G   |\\n'\n",
      " '|    2.m.0              |    0.102M              |    0.654G  |\\n'\n",
      " '|    2.m.1              |    0.102M              |    0.654G  |\\n'\n",
      " '|  3                    |  1.328M                |  2.125G    |\\n'\n",
      " '|   3.conv              |   1.327M               |   2.123G   |\\n'\n",
      " '|    3.conv.weight      |    (384, 384, 3, 3)    |            |\\n'\n",
      " '|   3.bn                |   0.768K               |   1.229M   |\\n'\n",
      " '|    3.bn.weight        |    (384,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (384,)              |            |\\n'\n",
      " '|  4                    |  1.554M                |  2.486G    |\\n'\n",
      " '|   4.cv1               |   0.148M               |   0.237G   |\\n'\n",
      " '|    4.cv1.conv         |    0.147M              |    0.236G  |\\n'\n",
      " '|    4.cv1.bn           |    0.768K              |    1.229M  |\\n'\n",
      " '|   4.cv2               |   0.591M               |   0.946G   |\\n'\n",
      " '|    4.cv2.conv         |    0.59M               |    0.944G  |\\n'\n",
      " '|    4.cv2.bn           |    1.536K              |    2.458M  |\\n'\n",
      " '|   4.m                 |   0.814M               |   1.303G   |\\n'\n",
      " '|    4.m.0              |    0.407M              |    0.651G  |\\n'\n",
      " '|    4.m.1              |    0.407M              |    0.651G  |\\n'\n",
      " '|  5                    |  5.31M                 |  2.124G    |\\n'\n",
      " '|   5.conv              |   5.308M               |   2.123G   |\\n'\n",
      " '|    5.conv.weight      |    (768, 768, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   1.536K               |   0.614M   |\\n'\n",
      " '|    5.bn.weight        |    (768,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (768,)              |            |\\n'\n",
      " '|  6                    |  5.023M                |  2.009G    |\\n'\n",
      " '|   6.cv1               |   0.591M               |   0.237G   |\\n'\n",
      " '|    6.cv1.conv         |    0.59M               |    0.236G  |\\n'\n",
      " '|    6.cv1.bn           |    1.536K              |    0.614M  |\\n'\n",
      " '|   6.cv2               |   1.181M               |   0.472G   |\\n'\n",
      " '|    6.cv2.conv         |    1.18M               |    0.472G  |\\n'\n",
      " '|    6.cv2.bn           |    1.536K              |    0.614M  |\\n'\n",
      " '|   6.m                 |   3.25M                |   1.3G     |\\n'\n",
      " '|    6.m.0              |    1.625M              |    0.65G   |\\n'\n",
      " '|    6.m.1              |    1.625M              |    0.65G   |\\n'\n",
      " '|  7                    |  5.31M                 |  0.531G    |\\n'\n",
      " '|   7.conv              |   5.308M               |   0.531G   |\\n'\n",
      " '|    7.conv.weight      |    (768, 768, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.536K               |   0.154M   |\\n'\n",
      " '|    7.bn.weight        |    (768,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (768,)              |            |\\n'\n",
      " '|  8                    |  5.023M                |  0.502G    |\\n'\n",
      " '|   8.cv1               |   0.591M               |   59.136M  |\\n'\n",
      " '|    8.cv1.conv         |    0.59M               |    58.982M |\\n'\n",
      " '|    8.cv1.bn           |    1.536K              |    0.154M  |\\n'\n",
      " '|   8.cv2               |   1.181M               |   0.118G   |\\n'\n",
      " '|    8.cv2.conv         |    1.18M               |    0.118G  |\\n'\n",
      " '|    8.cv2.bn           |    1.536K              |    0.154M  |\\n'\n",
      " '|   8.m                 |   3.25M                |   0.325G   |\\n'\n",
      " '|    8.m.0              |    1.625M              |    0.163G  |\\n'\n",
      " '|    8.m.1              |    1.625M              |    0.163G  |\\n'\n",
      " '|  9                    |  1.477M                |  0.148G    |\\n'\n",
      " '|   9.cv1               |   0.296M               |   29.568M  |\\n'\n",
      " '|    9.cv1.conv         |    0.295M              |    29.491M |\\n'\n",
      " '|    9.cv1.bn           |    0.768K              |    76.8K   |\\n'\n",
      " '|   9.cv2               |   1.181M               |   0.118G   |\\n'\n",
      " '|    9.cv2.conv         |    1.18M               |    0.118G  |\\n'\n",
      " '|    9.cv2.bn           |    1.536K              |    0.154M  |\\n'\n",
      " '|  10                   |  3.265M                |  0.338G    |\\n'\n",
      " '|   10.cv1              |   0.591M               |   59.136M  |\\n'\n",
      " '|    10.cv1.conv        |    0.59M               |    58.982M |\\n'\n",
      " '|    10.cv1.bn          |    1.536K              |    0.154M  |\\n'\n",
      " '|   10.cv2              |   0.591M               |   59.136M  |\\n'\n",
      " '|    10.cv2.conv        |    0.59M               |    58.982M |\\n'\n",
      " '|    10.cv2.bn          |    1.536K              |    0.154M  |\\n'\n",
      " '|   10.m                |   2.082M               |   0.22G    |\\n'\n",
      " '|    10.m.0             |    1.041M              |    0.11G   |\\n'\n",
      " '|    10.m.1             |    1.041M              |    0.11G   |\\n'\n",
      " '|  13                   |  5.613M                |  2.245G    |\\n'\n",
      " '|   13.cv1              |   1.181M               |   0.472G   |\\n'\n",
      " '|    13.cv1.conv        |    1.18M               |    0.472G  |\\n'\n",
      " '|    13.cv1.bn          |    1.536K              |    0.614M  |\\n'\n",
      " '|   13.cv2              |   1.181M               |   0.472G   |\\n'\n",
      " '|    13.cv2.conv        |    1.18M               |    0.472G  |\\n'\n",
      " '|    13.cv2.bn          |    1.536K              |    0.614M  |\\n'\n",
      " '|   13.m                |   3.25M                |   1.3G     |\\n'\n",
      " '|    13.m.0             |    1.625M              |    0.65G   |\\n'\n",
      " '|    13.m.1             |    1.625M              |    0.65G   |\\n'\n",
      " '|  16                   |  1.7M                  |  2.721G    |\\n'\n",
      " '|   16.cv1              |   0.591M               |   0.945G   |\\n'\n",
      " '|    16.cv1.conv        |    0.59M               |    0.944G  |\\n'\n",
      " '|    16.cv1.bn          |    0.768K              |    1.229M  |\\n'\n",
      " '|   16.cv2              |   0.296M               |   0.473G   |\\n'\n",
      " '|    16.cv2.conv        |    0.295M              |    0.472G  |\\n'\n",
      " '|    16.cv2.bn          |    0.768K              |    1.229M  |\\n'\n",
      " '|   16.m                |   0.814M               |   1.303G   |\\n'\n",
      " '|    16.m.0             |    0.407M              |    0.651G  |\\n'\n",
      " '|    16.m.1             |    0.407M              |    0.651G  |\\n'\n",
      " '|  17                   |  1.328M                |  0.531G    |\\n'\n",
      " '|   17.conv             |   1.327M               |   0.531G   |\\n'\n",
      " '|    17.conv.weight     |    (384, 384, 3, 3)    |            |\\n'\n",
      " '|   17.bn               |   0.768K               |   0.307M   |\\n'\n",
      " '|    17.bn.weight       |    (384,)              |            |\\n'\n",
      " '|    17.bn.bias         |    (384,)              |            |\\n'\n",
      " '|  19                   |  5.318M                |  2.127G    |\\n'\n",
      " '|   19.cv1              |   0.886M               |   0.355G   |\\n'\n",
      " '|    19.cv1.conv        |    0.885M              |    0.354G  |\\n'\n",
      " '|    19.cv1.bn          |    1.536K              |    0.614M  |\\n'\n",
      " '|   19.cv2              |   1.181M               |   0.472G   |\\n'\n",
      " '|    19.cv2.conv        |    1.18M               |    0.472G  |\\n'\n",
      " '|    19.cv2.bn          |    1.536K              |    0.614M  |\\n'\n",
      " '|   19.m                |   3.25M                |   1.3G     |\\n'\n",
      " '|    19.m.0             |    1.625M              |    0.65G   |\\n'\n",
      " '|    19.m.1             |    1.625M              |    0.65G   |\\n'\n",
      " '|  20                   |  5.31M                 |  0.531G    |\\n'\n",
      " '|   20.conv             |   5.308M               |   0.531G   |\\n'\n",
      " '|    20.conv.weight     |    (768, 768, 3, 3)    |            |\\n'\n",
      " '|   20.bn               |   1.536K               |   0.154M   |\\n'\n",
      " '|    20.bn.weight       |    (768,)              |            |\\n'\n",
      " '|    20.bn.bias         |    (768,)              |            |\\n'\n",
      " '|  22                   |  5.613M                |  0.561G    |\\n'\n",
      " '|   22.cv1              |   1.181M               |   0.118G   |\\n'\n",
      " '|    22.cv1.conv        |    1.18M               |    0.118G  |\\n'\n",
      " '|    22.cv1.bn          |    1.536K              |    0.154M  |\\n'\n",
      " '|   22.cv2              |   1.181M               |   0.118G   |\\n'\n",
      " '|    22.cv2.conv        |    1.18M               |    0.118G  |\\n'\n",
      " '|    22.cv2.bn          |    1.536K              |    0.154M  |\\n'\n",
      " '|   22.m                |   3.25M                |   0.325G   |\\n'\n",
      " '|    22.m.0             |    1.625M              |    0.163G  |\\n'\n",
      " '|    22.m.1             |    1.625M              |    0.163G  |\\n'\n",
      " '|  23                   |  3.238M                |  1.831G    |\\n'\n",
      " '|   23.cv2              |   1.927M               |   1.051G   |\\n'\n",
      " '|    23.cv2.0           |    0.421M              |    0.674G  |\\n'\n",
      " '|    23.cv2.1           |    0.753M              |    0.301G  |\\n'\n",
      " '|    23.cv2.2           |    0.753M              |    75.302M |\\n'\n",
      " '|   23.cv3              |   1.31M                |   0.781G   |\\n'\n",
      " '|    23.cv3.0           |    0.336M              |    0.537G  |\\n'\n",
      " '|    23.cv3.1           |    0.487M              |    0.195G  |\\n'\n",
      " '|    23.cv3.2           |    0.487M              |    48.73M  |\\n'\n",
      " '|   23.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    23.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  11                   |                        |  0.307M    |\\n'\n",
      " '|  14                   |                        |  1.229M    |')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"yolo11n\",\n",
    "    \"yolo11s\",\n",
    "    \"yolo11m\",\n",
    "    \"yolo11l\",\n",
    "    \"yolo11x\",\n",
    "]\n",
    "MODEL_FOLDER = \"/mnt/ssd2/xxx/repo/ultralytics/customization\"\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    model_path = os.path.join(MODEL_FOLDER, model_name)\n",
    "    model = YOLO(model_path).model\n",
    "\n",
    "    input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "    flops = FlopCountAnalysis(model, input)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    pp.pprint(flop_count_table(flops))\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21.5M/21.5M [00:00<00:00, 64.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 11.167M                | 3.589G     |\\n'\n",
      " '|  0                    |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.conv              |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.conv.weight      |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   64                   |   1.638M   |\\n'\n",
      " '|    0.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  1                    |  18.56K                |  0.119G    |\\n'\n",
      " '|   1.conv              |   18.432K              |   0.118G   |\\n'\n",
      " '|    1.conv.weight      |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.128K               |   0.819M   |\\n'\n",
      " '|    1.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  2                    |  29.056K               |  0.186G    |\\n'\n",
      " '|   2.cv1               |   4.224K               |   27.034M  |\\n'\n",
      " '|    2.cv1.conv         |    4.096K              |    26.214M |\\n'\n",
      " '|    2.cv1.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.cv2               |   6.272K               |   40.141M  |\\n'\n",
      " '|    2.cv2.conv         |    6.144K              |    39.322M |\\n'\n",
      " '|    2.cv2.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.m.0               |   18.56K               |   0.119G   |\\n'\n",
      " '|    2.m.0.cv1          |    9.28K               |    59.392M |\\n'\n",
      " '|    2.m.0.cv2          |    9.28K               |    59.392M |\\n'\n",
      " '|  3                    |  73.984K               |  0.118G    |\\n'\n",
      " '|   3.conv              |   73.728K              |   0.118G   |\\n'\n",
      " '|    3.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.256K               |   0.41M    |\\n'\n",
      " '|    3.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  4                    |  0.198M                |  0.316G    |\\n'\n",
      " '|   4.cv1               |   16.64K               |   26.624M  |\\n'\n",
      " '|    4.cv1.conv         |    16.384K             |    26.214M |\\n'\n",
      " '|    4.cv1.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.cv2               |   33.024K              |   52.838M  |\\n'\n",
      " '|    4.cv2.conv         |    32.768K             |    52.429M |\\n'\n",
      " '|    4.cv2.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.m                 |   0.148M               |   0.237G   |\\n'\n",
      " '|    4.m.0              |    73.984K             |    0.118G  |\\n'\n",
      " '|    4.m.1              |    73.984K             |    0.118G  |\\n'\n",
      " '|  5                    |  0.295M                |  0.118G    |\\n'\n",
      " '|   5.conv              |   0.295M               |   0.118G   |\\n'\n",
      " '|    5.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.512K               |   0.205M   |\\n'\n",
      " '|    5.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  6                    |  0.788M                |  0.315G    |\\n'\n",
      " '|   6.cv1               |   66.048K              |   26.419M  |\\n'\n",
      " '|    6.cv1.conv         |    65.536K             |    26.214M |\\n'\n",
      " '|    6.cv1.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.cv2               |   0.132M               |   52.634M  |\\n'\n",
      " '|    6.cv2.conv         |    0.131M              |    52.429M |\\n'\n",
      " '|    6.cv2.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.m                 |   0.591M               |   0.236G   |\\n'\n",
      " '|    6.m.0              |    0.295M              |    0.118G  |\\n'\n",
      " '|    6.m.1              |    0.295M              |    0.118G  |\\n'\n",
      " '|  7                    |  1.181M                |  0.118G    |\\n'\n",
      " '|   7.conv              |   1.18M                |   0.118G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  1.838M                |  0.184G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.394M               |   39.424M  |\\n'\n",
      " '|    8.cv2.conv         |    0.393M              |    39.322M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m.0               |   1.181M               |   0.118G   |\\n'\n",
      " '|    8.m.0.cv1          |    0.59M               |    59.034M |\\n'\n",
      " '|    8.m.0.cv2          |    0.59M               |    59.034M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  12                   |  0.591M                |  0.237G    |\\n'\n",
      " '|   12.cv1              |   0.197M               |   78.848M  |\\n'\n",
      " '|    12.cv1.conv        |    0.197M              |    78.643M |\\n'\n",
      " '|    12.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    12.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    12.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    12.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    12.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  15                   |  0.148M                |  0.237G    |\\n'\n",
      " '|   15.cv1              |   49.408K              |   79.053M  |\\n'\n",
      " '|    15.cv1.conv        |    49.152K             |    78.643M |\\n'\n",
      " '|    15.cv1.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.cv2              |   24.832K              |   39.731M  |\\n'\n",
      " '|    15.cv2.conv        |    24.576K             |    39.322M |\\n'\n",
      " '|    15.cv2.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.m.0              |   73.984K              |   0.118G   |\\n'\n",
      " '|    15.m.0.cv1         |    36.992K             |    59.187M |\\n'\n",
      " '|    15.m.0.cv2         |    36.992K             |    59.187M |\\n'\n",
      " '|  16                   |  0.148M                |  59.085M   |\\n'\n",
      " '|   16.conv             |   0.147M               |   58.982M  |\\n'\n",
      " '|    16.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.256K               |   0.102M   |\\n'\n",
      " '|    16.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  18                   |  0.493M                |  0.197G    |\\n'\n",
      " '|   18.cv1              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv1.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    18.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    18.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  19                   |  0.59M                 |  59.034M   |\\n'\n",
      " '|   19.conv             |   0.59M                |   58.982M  |\\n'\n",
      " '|    19.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.512K               |   51.2K    |\\n'\n",
      " '|    19.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  21                   |  1.969M                |  0.197G    |\\n'\n",
      " '|   21.cv1              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv1.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.cv2              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv2.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.m.0              |   1.181M               |   0.118G   |\\n'\n",
      " '|    21.m.0.cv1         |    0.59M               |    59.034M |\\n'\n",
      " '|    21.m.0.cv2         |    0.59M               |    59.034M |\\n'\n",
      " '|  22                   |  2.147M                |  1.038G    |\\n'\n",
      " '|   22.cv2              |   0.64M                |   0.293G   |\\n'\n",
      " '|    22.cv2.0           |    0.115M              |    0.184G  |\\n'\n",
      " '|    22.cv2.1           |    0.189M              |    75.469M |\\n'\n",
      " '|    22.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   22.cv3              |   1.507M               |   0.745G   |\\n'\n",
      " '|    22.cv3.0           |    0.306M              |    0.489G  |\\n'\n",
      " '|    22.cv3.1           |    0.453M              |    0.181G  |\\n'\n",
      " '|    22.cv3.2           |    0.748M              |    74.803M |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.205M    |\\n'\n",
      " '|  13                   |                        |  0.41M     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\").model\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 49.7M/49.7M [00:00<00:00, 85.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 25.903M                | 9.891G     |\\n'\n",
      " '|  0                    |  1.392K                |  35.635M   |\\n'\n",
      " '|   0.conv              |   1.296K               |   33.178M  |\\n'\n",
      " '|    0.conv.weight      |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   96                   |   2.458M   |\\n'\n",
      " '|    0.bn.weight        |    (48,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (48,)               |            |\\n'\n",
      " '|  1                    |  41.664K               |  0.267G    |\\n'\n",
      " '|   1.conv              |   41.472K              |   0.265G   |\\n'\n",
      " '|    1.conv.weight      |    (96, 48, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.192K               |   1.229M   |\\n'\n",
      " '|    1.bn.weight        |    (96,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (96,)               |            |\\n'\n",
      " '|  2                    |  0.111M                |  0.713G    |\\n'\n",
      " '|   2.cv1               |   9.408K               |   60.211M  |\\n'\n",
      " '|    2.cv1.conv         |    9.216K              |    58.982M |\\n'\n",
      " '|    2.cv1.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.cv2               |   18.624K              |   0.119G   |\\n'\n",
      " '|    2.cv2.conv         |    18.432K             |    0.118G  |\\n'\n",
      " '|    2.cv2.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.m                 |   83.328K              |   0.533G   |\\n'\n",
      " '|    2.m.0              |    41.664K             |    0.267G  |\\n'\n",
      " '|    2.m.1              |    41.664K             |    0.267G  |\\n'\n",
      " '|  3                    |  0.166M                |  0.266G    |\\n'\n",
      " '|   3.conv              |   0.166M               |   0.265G   |\\n'\n",
      " '|    3.conv.weight      |    (192, 96, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.384K               |   0.614M   |\\n'\n",
      " '|    3.bn.weight        |    (192,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (192,)              |            |\\n'\n",
      " '|  4                    |  0.813M                |  1.301G    |\\n'\n",
      " '|   4.cv1               |   37.248K              |   59.597M  |\\n'\n",
      " '|    4.cv1.conv         |    36.864K             |    58.982M |\\n'\n",
      " '|    4.cv1.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.cv2               |   0.111M               |   0.178G   |\\n'\n",
      " '|    4.cv2.conv         |    0.111M              |    0.177G  |\\n'\n",
      " '|    4.cv2.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.m                 |   0.665M               |   1.064G   |\\n'\n",
      " '|    4.m.0              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.1              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.2              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.3              |    0.166M              |    0.266G  |\\n'\n",
      " '|  5                    |  0.664M                |  0.266G    |\\n'\n",
      " '|   5.conv              |   0.664M               |   0.265G   |\\n'\n",
      " '|    5.conv.weight      |    (384, 192, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.768K               |   0.307M   |\\n'\n",
      " '|    5.bn.weight        |    (384,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (384,)              |            |\\n'\n",
      " '|  6                    |  3.249M                |  1.299G    |\\n'\n",
      " '|   6.cv1               |   0.148M               |   59.29M   |\\n'\n",
      " '|    6.cv1.conv         |    0.147M              |    58.982M |\\n'\n",
      " '|    6.cv1.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.cv2               |   0.443M               |   0.177G   |\\n'\n",
      " '|    6.cv2.conv         |    0.442M              |    0.177G  |\\n'\n",
      " '|    6.cv2.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.m                 |   2.657M               |   1.063G   |\\n'\n",
      " '|    6.m.0              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.1              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.2              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.3              |    0.664M              |    0.266G  |\\n'\n",
      " '|  7                    |  1.992M                |  0.199G    |\\n'\n",
      " '|   7.conv              |   1.991M               |   0.199G   |\\n'\n",
      " '|    7.conv.weight      |    (576, 384, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.152K               |   0.115M   |\\n'\n",
      " '|    7.bn.weight        |    (576,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (576,)              |            |\\n'\n",
      " '|  8                    |  3.986M                |  0.399G    |\\n'\n",
      " '|   8.cv1               |   0.333M               |   33.293M  |\\n'\n",
      " '|    8.cv1.conv         |    0.332M              |    33.178M |\\n'\n",
      " '|    8.cv1.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    8.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    8.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.m                 |   2.988M               |   0.299G   |\\n'\n",
      " '|    8.m.0              |    1.494M              |    0.149G  |\\n'\n",
      " '|    8.m.1              |    1.494M              |    0.149G  |\\n'\n",
      " '|  9                    |  0.831M                |  83.117M   |\\n'\n",
      " '|   9.cv1               |   0.166M               |   16.646M  |\\n'\n",
      " '|    9.cv1.conv         |    0.166M              |    16.589M |\\n'\n",
      " '|    9.cv1.bn           |    0.576K              |    57.6K   |\\n'\n",
      " '|   9.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    9.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    9.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|  12                   |  1.994M                |  0.797G    |\\n'\n",
      " '|   12.cv1              |   0.369M               |   0.148G   |\\n'\n",
      " '|    12.cv1.conv        |    0.369M              |    0.147G  |\\n'\n",
      " '|    12.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    12.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    12.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    12.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    12.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  15                   |  0.518M                |  0.828G    |\\n'\n",
      " '|   15.cv1              |   0.111M               |   0.178G   |\\n'\n",
      " '|    15.cv1.conv        |    0.111M              |    0.177G  |\\n'\n",
      " '|    15.cv1.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.cv2              |   74.112K              |   0.119G   |\\n'\n",
      " '|    15.cv2.conv        |    73.728K             |    0.118G  |\\n'\n",
      " '|    15.cv2.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.m                |   0.333M               |   0.532G   |\\n'\n",
      " '|    15.m.0             |    0.166M              |    0.266G  |\\n'\n",
      " '|    15.m.1             |    0.166M              |    0.266G  |\\n'\n",
      " '|  16                   |  0.332M                |  0.133G    |\\n'\n",
      " '|   16.conv             |   0.332M               |   0.133G   |\\n'\n",
      " '|    16.conv.weight     |    (192, 192, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.384K               |   0.154M   |\\n'\n",
      " '|    16.bn.weight       |    (192,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (192,)              |            |\\n'\n",
      " '|  18                   |  1.846M                |  0.739G    |\\n'\n",
      " '|   18.cv1              |   0.222M               |   88.781M  |\\n'\n",
      " '|    18.cv1.conv        |    0.221M              |    88.474M |\\n'\n",
      " '|    18.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    18.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    18.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    18.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    18.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  19                   |  1.328M                |  0.133G    |\\n'\n",
      " '|   19.conv             |   1.327M               |   0.133G   |\\n'\n",
      " '|    19.conv.weight     |    (384, 384, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.768K               |   76.8K    |\\n'\n",
      " '|    19.bn.weight       |    (384,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (384,)              |            |\\n'\n",
      " '|  21                   |  4.207M                |  0.421G    |\\n'\n",
      " '|   21.cv1              |   0.554M               |   55.411M  |\\n'\n",
      " '|    21.cv1.conv        |    0.553M              |    55.296M |\\n'\n",
      " '|    21.cv1.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.cv2              |   0.665M               |   66.47M   |\\n'\n",
      " '|    21.cv2.conv        |    0.664M              |    66.355M |\\n'\n",
      " '|    21.cv2.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.m                |   2.988M               |   0.299G   |\\n'\n",
      " '|    21.m.0             |    1.494M              |    0.149G  |\\n'\n",
      " '|    21.m.1             |    1.494M              |    0.149G  |\\n'\n",
      " '|  22                   |  3.822M                |  2.012G    |\\n'\n",
      " '|   22.cv2              |   0.787M               |   0.385G   |\\n'\n",
      " '|    22.cv2.0           |    0.152M              |    0.243G  |\\n'\n",
      " '|    22.cv2.1           |    0.262M              |    0.105G  |\\n'\n",
      " '|    22.cv2.2           |    0.373M              |    37.299M |\\n'\n",
      " '|   22.cv3              |   3.035M               |   1.626G   |\\n'\n",
      " '|    22.cv3.0           |    0.68M               |    1.087G  |\\n'\n",
      " '|    22.cv3.1           |    1.012M              |    0.405G  |\\n'\n",
      " '|    22.cv3.2           |    1.343M              |    0.134G  |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.23M     |\\n'\n",
      " '|  13                   |                        |  0.614M    |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\").model\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21.5M/21.5M [00:00<00:00, 64.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 11.167M                | 3.589G     |\\n'\n",
      " '|  0                    |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.conv              |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.conv.weight      |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   64                   |   1.638M   |\\n'\n",
      " '|    0.bn.weight        |    (32,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (32,)               |            |\\n'\n",
      " '|  1                    |  18.56K                |  0.119G    |\\n'\n",
      " '|   1.conv              |   18.432K              |   0.118G   |\\n'\n",
      " '|    1.conv.weight      |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.128K               |   0.819M   |\\n'\n",
      " '|    1.bn.weight        |    (64,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (64,)               |            |\\n'\n",
      " '|  2                    |  29.056K               |  0.186G    |\\n'\n",
      " '|   2.cv1               |   4.224K               |   27.034M  |\\n'\n",
      " '|    2.cv1.conv         |    4.096K              |    26.214M |\\n'\n",
      " '|    2.cv1.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.cv2               |   6.272K               |   40.141M  |\\n'\n",
      " '|    2.cv2.conv         |    6.144K              |    39.322M |\\n'\n",
      " '|    2.cv2.bn           |    0.128K              |    0.819M  |\\n'\n",
      " '|   2.m.0               |   18.56K               |   0.119G   |\\n'\n",
      " '|    2.m.0.cv1          |    9.28K               |    59.392M |\\n'\n",
      " '|    2.m.0.cv2          |    9.28K               |    59.392M |\\n'\n",
      " '|  3                    |  73.984K               |  0.118G    |\\n'\n",
      " '|   3.conv              |   73.728K              |   0.118G   |\\n'\n",
      " '|    3.conv.weight      |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.256K               |   0.41M    |\\n'\n",
      " '|    3.bn.weight        |    (128,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (128,)              |            |\\n'\n",
      " '|  4                    |  0.198M                |  0.316G    |\\n'\n",
      " '|   4.cv1               |   16.64K               |   26.624M  |\\n'\n",
      " '|    4.cv1.conv         |    16.384K             |    26.214M |\\n'\n",
      " '|    4.cv1.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.cv2               |   33.024K              |   52.838M  |\\n'\n",
      " '|    4.cv2.conv         |    32.768K             |    52.429M |\\n'\n",
      " '|    4.cv2.bn           |    0.256K              |    0.41M   |\\n'\n",
      " '|   4.m                 |   0.148M               |   0.237G   |\\n'\n",
      " '|    4.m.0              |    73.984K             |    0.118G  |\\n'\n",
      " '|    4.m.1              |    73.984K             |    0.118G  |\\n'\n",
      " '|  5                    |  0.295M                |  0.118G    |\\n'\n",
      " '|   5.conv              |   0.295M               |   0.118G   |\\n'\n",
      " '|    5.conv.weight      |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.512K               |   0.205M   |\\n'\n",
      " '|    5.bn.weight        |    (256,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (256,)              |            |\\n'\n",
      " '|  6                    |  0.788M                |  0.315G    |\\n'\n",
      " '|   6.cv1               |   66.048K              |   26.419M  |\\n'\n",
      " '|    6.cv1.conv         |    65.536K             |    26.214M |\\n'\n",
      " '|    6.cv1.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.cv2               |   0.132M               |   52.634M  |\\n'\n",
      " '|    6.cv2.conv         |    0.131M              |    52.429M |\\n'\n",
      " '|    6.cv2.bn           |    0.512K              |    0.205M  |\\n'\n",
      " '|   6.m                 |   0.591M               |   0.236G   |\\n'\n",
      " '|    6.m.0              |    0.295M              |    0.118G  |\\n'\n",
      " '|    6.m.1              |    0.295M              |    0.118G  |\\n'\n",
      " '|  7                    |  1.181M                |  0.118G    |\\n'\n",
      " '|   7.conv              |   1.18M                |   0.118G   |\\n'\n",
      " '|    7.conv.weight      |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.024K               |   0.102M   |\\n'\n",
      " '|    7.bn.weight        |    (512,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (512,)              |            |\\n'\n",
      " '|  8                    |  1.838M                |  0.184G    |\\n'\n",
      " '|   8.cv1               |   0.263M               |   26.317M  |\\n'\n",
      " '|    8.cv1.conv         |    0.262M              |    26.214M |\\n'\n",
      " '|    8.cv1.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.cv2               |   0.394M               |   39.424M  |\\n'\n",
      " '|    8.cv2.conv         |    0.393M              |    39.322M |\\n'\n",
      " '|    8.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|   8.m.0               |   1.181M               |   0.118G   |\\n'\n",
      " '|    8.m.0.cv1          |    0.59M               |    59.034M |\\n'\n",
      " '|    8.m.0.cv2          |    0.59M               |    59.034M |\\n'\n",
      " '|  9                    |  0.657M                |  65.69M    |\\n'\n",
      " '|   9.cv1               |   0.132M               |   13.158M  |\\n'\n",
      " '|    9.cv1.conv         |    0.131M              |    13.107M |\\n'\n",
      " '|    9.cv1.bn           |    0.512K              |    51.2K   |\\n'\n",
      " '|   9.cv2               |   0.525M               |   52.531M  |\\n'\n",
      " '|    9.cv2.conv         |    0.524M              |    52.429M |\\n'\n",
      " '|    9.cv2.bn           |    1.024K              |    0.102M  |\\n'\n",
      " '|  12                   |  0.591M                |  0.237G    |\\n'\n",
      " '|   12.cv1              |   0.197M               |   78.848M  |\\n'\n",
      " '|    12.cv1.conv        |    0.197M              |    78.643M |\\n'\n",
      " '|    12.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    12.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    12.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   12.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    12.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    12.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  15                   |  0.148M                |  0.237G    |\\n'\n",
      " '|   15.cv1              |   49.408K              |   79.053M  |\\n'\n",
      " '|    15.cv1.conv        |    49.152K             |    78.643M |\\n'\n",
      " '|    15.cv1.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.cv2              |   24.832K              |   39.731M  |\\n'\n",
      " '|    15.cv2.conv        |    24.576K             |    39.322M |\\n'\n",
      " '|    15.cv2.bn          |    0.256K              |    0.41M   |\\n'\n",
      " '|   15.m.0              |   73.984K              |   0.118G   |\\n'\n",
      " '|    15.m.0.cv1         |    36.992K             |    59.187M |\\n'\n",
      " '|    15.m.0.cv2         |    36.992K             |    59.187M |\\n'\n",
      " '|  16                   |  0.148M                |  59.085M   |\\n'\n",
      " '|   16.conv             |   0.147M               |   58.982M  |\\n'\n",
      " '|    16.conv.weight     |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.256K               |   0.102M   |\\n'\n",
      " '|    16.bn.weight       |    (128,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (128,)              |            |\\n'\n",
      " '|  18                   |  0.493M                |  0.197G    |\\n'\n",
      " '|   18.cv1              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv1.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv1.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.cv2              |   98.816K              |   39.526M  |\\n'\n",
      " '|    18.cv2.conv        |    98.304K             |    39.322M |\\n'\n",
      " '|    18.cv2.bn          |    0.512K              |    0.205M  |\\n'\n",
      " '|   18.m.0              |   0.295M               |   0.118G   |\\n'\n",
      " '|    18.m.0.cv1         |    0.148M              |    59.085M |\\n'\n",
      " '|    18.m.0.cv2         |    0.148M              |    59.085M |\\n'\n",
      " '|  19                   |  0.59M                 |  59.034M   |\\n'\n",
      " '|   19.conv             |   0.59M                |   58.982M  |\\n'\n",
      " '|    19.conv.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.512K               |   51.2K    |\\n'\n",
      " '|    19.bn.weight       |    (256,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (256,)              |            |\\n'\n",
      " '|  21                   |  1.969M                |  0.197G    |\\n'\n",
      " '|   21.cv1              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv1.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv1.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.cv2              |   0.394M               |   39.424M  |\\n'\n",
      " '|    21.cv2.conv        |    0.393M              |    39.322M |\\n'\n",
      " '|    21.cv2.bn          |    1.024K              |    0.102M  |\\n'\n",
      " '|   21.m.0              |   1.181M               |   0.118G   |\\n'\n",
      " '|    21.m.0.cv1         |    0.59M               |    59.034M |\\n'\n",
      " '|    21.m.0.cv2         |    0.59M               |    59.034M |\\n'\n",
      " '|  22                   |  2.147M                |  1.038G    |\\n'\n",
      " '|   22.cv2              |   0.64M                |   0.293G   |\\n'\n",
      " '|    22.cv2.0           |    0.115M              |    0.184G  |\\n'\n",
      " '|    22.cv2.1           |    0.189M              |    75.469M |\\n'\n",
      " '|    22.cv2.2           |    0.336M              |    33.613M |\\n'\n",
      " '|   22.cv3              |   1.507M               |   0.745G   |\\n'\n",
      " '|    22.cv3.0           |    0.306M              |    0.489G  |\\n'\n",
      " '|    22.cv3.1           |    0.453M              |    0.181G  |\\n'\n",
      " '|    22.cv3.2           |    0.748M              |    74.803M |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.205M    |\\n'\n",
      " '|  13                   |                        |  0.41M     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\").model\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 49.7M/49.7M [00:00<00:00, 85.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 25.903M                | 9.891G     |\\n'\n",
      " '|  0                    |  1.392K                |  35.635M   |\\n'\n",
      " '|   0.conv              |   1.296K               |   33.178M  |\\n'\n",
      " '|    0.conv.weight      |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   0.bn                |   96                   |   2.458M   |\\n'\n",
      " '|    0.bn.weight        |    (48,)               |            |\\n'\n",
      " '|    0.bn.bias          |    (48,)               |            |\\n'\n",
      " '|  1                    |  41.664K               |  0.267G    |\\n'\n",
      " '|   1.conv              |   41.472K              |   0.265G   |\\n'\n",
      " '|    1.conv.weight      |    (96, 48, 3, 3)      |            |\\n'\n",
      " '|   1.bn                |   0.192K               |   1.229M   |\\n'\n",
      " '|    1.bn.weight        |    (96,)               |            |\\n'\n",
      " '|    1.bn.bias          |    (96,)               |            |\\n'\n",
      " '|  2                    |  0.111M                |  0.713G    |\\n'\n",
      " '|   2.cv1               |   9.408K               |   60.211M  |\\n'\n",
      " '|    2.cv1.conv         |    9.216K              |    58.982M |\\n'\n",
      " '|    2.cv1.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.cv2               |   18.624K              |   0.119G   |\\n'\n",
      " '|    2.cv2.conv         |    18.432K             |    0.118G  |\\n'\n",
      " '|    2.cv2.bn           |    0.192K              |    1.229M  |\\n'\n",
      " '|   2.m                 |   83.328K              |   0.533G   |\\n'\n",
      " '|    2.m.0              |    41.664K             |    0.267G  |\\n'\n",
      " '|    2.m.1              |    41.664K             |    0.267G  |\\n'\n",
      " '|  3                    |  0.166M                |  0.266G    |\\n'\n",
      " '|   3.conv              |   0.166M               |   0.265G   |\\n'\n",
      " '|    3.conv.weight      |    (192, 96, 3, 3)     |            |\\n'\n",
      " '|   3.bn                |   0.384K               |   0.614M   |\\n'\n",
      " '|    3.bn.weight        |    (192,)              |            |\\n'\n",
      " '|    3.bn.bias          |    (192,)              |            |\\n'\n",
      " '|  4                    |  0.813M                |  1.301G    |\\n'\n",
      " '|   4.cv1               |   37.248K              |   59.597M  |\\n'\n",
      " '|    4.cv1.conv         |    36.864K             |    58.982M |\\n'\n",
      " '|    4.cv1.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.cv2               |   0.111M               |   0.178G   |\\n'\n",
      " '|    4.cv2.conv         |    0.111M              |    0.177G  |\\n'\n",
      " '|    4.cv2.bn           |    0.384K              |    0.614M  |\\n'\n",
      " '|   4.m                 |   0.665M               |   1.064G   |\\n'\n",
      " '|    4.m.0              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.1              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.2              |    0.166M              |    0.266G  |\\n'\n",
      " '|    4.m.3              |    0.166M              |    0.266G  |\\n'\n",
      " '|  5                    |  0.664M                |  0.266G    |\\n'\n",
      " '|   5.conv              |   0.664M               |   0.265G   |\\n'\n",
      " '|    5.conv.weight      |    (384, 192, 3, 3)    |            |\\n'\n",
      " '|   5.bn                |   0.768K               |   0.307M   |\\n'\n",
      " '|    5.bn.weight        |    (384,)              |            |\\n'\n",
      " '|    5.bn.bias          |    (384,)              |            |\\n'\n",
      " '|  6                    |  3.249M                |  1.299G    |\\n'\n",
      " '|   6.cv1               |   0.148M               |   59.29M   |\\n'\n",
      " '|    6.cv1.conv         |    0.147M              |    58.982M |\\n'\n",
      " '|    6.cv1.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.cv2               |   0.443M               |   0.177G   |\\n'\n",
      " '|    6.cv2.conv         |    0.442M              |    0.177G  |\\n'\n",
      " '|    6.cv2.bn           |    0.768K              |    0.307M  |\\n'\n",
      " '|   6.m                 |   2.657M               |   1.063G   |\\n'\n",
      " '|    6.m.0              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.1              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.2              |    0.664M              |    0.266G  |\\n'\n",
      " '|    6.m.3              |    0.664M              |    0.266G  |\\n'\n",
      " '|  7                    |  1.992M                |  0.199G    |\\n'\n",
      " '|   7.conv              |   1.991M               |   0.199G   |\\n'\n",
      " '|    7.conv.weight      |    (576, 384, 3, 3)    |            |\\n'\n",
      " '|   7.bn                |   1.152K               |   0.115M   |\\n'\n",
      " '|    7.bn.weight        |    (576,)              |            |\\n'\n",
      " '|    7.bn.bias          |    (576,)              |            |\\n'\n",
      " '|  8                    |  3.986M                |  0.399G    |\\n'\n",
      " '|   8.cv1               |   0.333M               |   33.293M  |\\n'\n",
      " '|    8.cv1.conv         |    0.332M              |    33.178M |\\n'\n",
      " '|    8.cv1.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    8.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    8.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|   8.m                 |   2.988M               |   0.299G   |\\n'\n",
      " '|    8.m.0              |    1.494M              |    0.149G  |\\n'\n",
      " '|    8.m.1              |    1.494M              |    0.149G  |\\n'\n",
      " '|  9                    |  0.831M                |  83.117M   |\\n'\n",
      " '|   9.cv1               |   0.166M               |   16.646M  |\\n'\n",
      " '|    9.cv1.conv         |    0.166M              |    16.589M |\\n'\n",
      " '|    9.cv1.bn           |    0.576K              |    57.6K   |\\n'\n",
      " '|   9.cv2               |   0.665M               |   66.47M   |\\n'\n",
      " '|    9.cv2.conv         |    0.664M              |    66.355M |\\n'\n",
      " '|    9.cv2.bn           |    1.152K              |    0.115M  |\\n'\n",
      " '|  12                   |  1.994M                |  0.797G    |\\n'\n",
      " '|   12.cv1              |   0.369M               |   0.148G   |\\n'\n",
      " '|    12.cv1.conv        |    0.369M              |    0.147G  |\\n'\n",
      " '|    12.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    12.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    12.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   12.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    12.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    12.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  15                   |  0.518M                |  0.828G    |\\n'\n",
      " '|   15.cv1              |   0.111M               |   0.178G   |\\n'\n",
      " '|    15.cv1.conv        |    0.111M              |    0.177G  |\\n'\n",
      " '|    15.cv1.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.cv2              |   74.112K              |   0.119G   |\\n'\n",
      " '|    15.cv2.conv        |    73.728K             |    0.118G  |\\n'\n",
      " '|    15.cv2.bn          |    0.384K              |    0.614M  |\\n'\n",
      " '|   15.m                |   0.333M               |   0.532G   |\\n'\n",
      " '|    15.m.0             |    0.166M              |    0.266G  |\\n'\n",
      " '|    15.m.1             |    0.166M              |    0.266G  |\\n'\n",
      " '|  16                   |  0.332M                |  0.133G    |\\n'\n",
      " '|   16.conv             |   0.332M               |   0.133G   |\\n'\n",
      " '|    16.conv.weight     |    (192, 192, 3, 3)    |            |\\n'\n",
      " '|   16.bn               |   0.384K               |   0.154M   |\\n'\n",
      " '|    16.bn.weight       |    (192,)              |            |\\n'\n",
      " '|    16.bn.bias         |    (192,)              |            |\\n'\n",
      " '|  18                   |  1.846M                |  0.739G    |\\n'\n",
      " '|   18.cv1              |   0.222M               |   88.781M  |\\n'\n",
      " '|    18.cv1.conv        |    0.221M              |    88.474M |\\n'\n",
      " '|    18.cv1.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.cv2              |   0.296M               |   0.118G   |\\n'\n",
      " '|    18.cv2.conv        |    0.295M              |    0.118G  |\\n'\n",
      " '|    18.cv2.bn          |    0.768K              |    0.307M  |\\n'\n",
      " '|   18.m                |   1.329M               |   0.531G   |\\n'\n",
      " '|    18.m.0             |    0.664M              |    0.266G  |\\n'\n",
      " '|    18.m.1             |    0.664M              |    0.266G  |\\n'\n",
      " '|  19                   |  1.328M                |  0.133G    |\\n'\n",
      " '|   19.conv             |   1.327M               |   0.133G   |\\n'\n",
      " '|    19.conv.weight     |    (384, 384, 3, 3)    |            |\\n'\n",
      " '|   19.bn               |   0.768K               |   76.8K    |\\n'\n",
      " '|    19.bn.weight       |    (384,)              |            |\\n'\n",
      " '|    19.bn.bias         |    (384,)              |            |\\n'\n",
      " '|  21                   |  4.207M                |  0.421G    |\\n'\n",
      " '|   21.cv1              |   0.554M               |   55.411M  |\\n'\n",
      " '|    21.cv1.conv        |    0.553M              |    55.296M |\\n'\n",
      " '|    21.cv1.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.cv2              |   0.665M               |   66.47M   |\\n'\n",
      " '|    21.cv2.conv        |    0.664M              |    66.355M |\\n'\n",
      " '|    21.cv2.bn          |    1.152K              |    0.115M  |\\n'\n",
      " '|   21.m                |   2.988M               |   0.299G   |\\n'\n",
      " '|    21.m.0             |    1.494M              |    0.149G  |\\n'\n",
      " '|    21.m.1             |    1.494M              |    0.149G  |\\n'\n",
      " '|  22                   |  3.822M                |  2.012G    |\\n'\n",
      " '|   22.cv2              |   0.787M               |   0.385G   |\\n'\n",
      " '|    22.cv2.0           |    0.152M              |    0.243G  |\\n'\n",
      " '|    22.cv2.1           |    0.262M              |    0.105G  |\\n'\n",
      " '|    22.cv2.2           |    0.373M              |    37.299M |\\n'\n",
      " '|   22.cv3              |   3.035M               |   1.626G   |\\n'\n",
      " '|    22.cv3.0           |    0.68M               |    1.087G  |\\n'\n",
      " '|    22.cv3.1           |    1.012M              |    0.405G  |\\n'\n",
      " '|    22.cv3.2           |    1.343M              |    0.134G  |\\n'\n",
      " '|   22.dfl.conv         |   16                   |   0.134M   |\\n'\n",
      " '|    22.dfl.conv.weight |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|  10                   |                        |  0.23M     |\\n'\n",
      " '|  13                   |                        |  0.614M    |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "from ultralytics import YOLO\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\").model\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(weights=\"MobileNet_V2_Weights.IMAGENET1K_V2\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "Sequential: 1-1                                  [-1, 1280, 7, 7]          --\n",
      "|    Conv2dNormActivation: 2-1                   [-1, 32, 112, 112]        --\n",
      "|    |    Conv2d: 3-1                            [-1, 32, 112, 112]        864\n",
      "|    |    BatchNorm2d: 3-2                       [-1, 32, 112, 112]        64\n",
      "|    |    ReLU6: 3-3                             [-1, 32, 112, 112]        --\n",
      "|    InvertedResidual: 2-2                       [-1, 16, 112, 112]        --\n",
      "|    |    Sequential: 3-4                        [-1, 16, 112, 112]        896\n",
      "|    InvertedResidual: 2-3                       [-1, 24, 56, 56]          --\n",
      "|    |    Sequential: 3-5                        [-1, 24, 56, 56]          5,136\n",
      "|    InvertedResidual: 2-4                       [-1, 24, 56, 56]          --\n",
      "|    |    Sequential: 3-6                        [-1, 24, 56, 56]          8,832\n",
      "|    InvertedResidual: 2-5                       [-1, 32, 28, 28]          --\n",
      "|    |    Sequential: 3-7                        [-1, 32, 28, 28]          10,000\n",
      "|    InvertedResidual: 2-6                       [-1, 32, 28, 28]          --\n",
      "|    |    Sequential: 3-8                        [-1, 32, 28, 28]          14,848\n",
      "|    InvertedResidual: 2-7                       [-1, 32, 28, 28]          --\n",
      "|    |    Sequential: 3-9                        [-1, 32, 28, 28]          14,848\n",
      "|    InvertedResidual: 2-8                       [-1, 64, 14, 14]          --\n",
      "|    |    Sequential: 3-10                       [-1, 64, 14, 14]          21,056\n",
      "|    InvertedResidual: 2-9                       [-1, 64, 14, 14]          --\n",
      "|    |    Sequential: 3-11                       [-1, 64, 14, 14]          54,272\n",
      "|    InvertedResidual: 2-10                      [-1, 64, 14, 14]          --\n",
      "|    |    Sequential: 3-12                       [-1, 64, 14, 14]          54,272\n",
      "|    InvertedResidual: 2-11                      [-1, 64, 14, 14]          --\n",
      "|    |    Sequential: 3-13                       [-1, 64, 14, 14]          54,272\n",
      "|    InvertedResidual: 2-12                      [-1, 96, 14, 14]          --\n",
      "|    |    Sequential: 3-14                       [-1, 96, 14, 14]          66,624\n",
      "|    InvertedResidual: 2-13                      [-1, 96, 14, 14]          --\n",
      "|    |    Sequential: 3-15                       [-1, 96, 14, 14]          118,272\n",
      "|    InvertedResidual: 2-14                      [-1, 96, 14, 14]          --\n",
      "|    |    Sequential: 3-16                       [-1, 96, 14, 14]          118,272\n",
      "|    InvertedResidual: 2-15                      [-1, 160, 7, 7]           --\n",
      "|    |    Sequential: 3-17                       [-1, 160, 7, 7]           155,264\n",
      "|    InvertedResidual: 2-16                      [-1, 160, 7, 7]           --\n",
      "|    |    Sequential: 3-18                       [-1, 160, 7, 7]           320,000\n",
      "|    InvertedResidual: 2-17                      [-1, 160, 7, 7]           --\n",
      "|    |    Sequential: 3-19                       [-1, 160, 7, 7]           320,000\n",
      "|    InvertedResidual: 2-18                      [-1, 320, 7, 7]           --\n",
      "|    |    Sequential: 3-20                       [-1, 320, 7, 7]           473,920\n",
      "|    Conv2dNormActivation: 2-19                  [-1, 1280, 7, 7]          --\n",
      "|    |    Conv2d: 3-21                           [-1, 1280, 7, 7]          409,600\n",
      "|    |    BatchNorm2d: 3-22                      [-1, 1280, 7, 7]          2,560\n",
      "|    |    ReLU6: 3-23                            [-1, 1280, 7, 7]          --\n",
      "Sequential: 1-2                                  [-1, 1000]                --\n",
      "|    Dropout: 2-20                               [-1, 1280]                --\n",
      "|    Linear: 2-21                                [-1, 1000]                1,281,000\n",
      "====================================================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 158.62\n",
      "====================================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 15.82\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 29.77\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "features\n",
      "features.0\n",
      "features.0.0\n",
      "features.0.1\n",
      "features.0.2\n",
      "features.1\n",
      "features.1.conv\n",
      "features.1.conv.0\n",
      "features.1.conv.0.0\n",
      "features.1.conv.0.1\n",
      "features.1.conv.0.2\n",
      "features.1.conv.1\n",
      "features.1.conv.2\n",
      "features.2\n",
      "features.2.conv\n",
      "features.2.conv.0\n",
      "features.2.conv.0.0\n",
      "features.2.conv.0.1\n",
      "features.2.conv.0.2\n",
      "features.2.conv.1\n",
      "features.2.conv.1.0\n",
      "features.2.conv.1.1\n",
      "features.2.conv.1.2\n",
      "features.2.conv.2\n",
      "features.2.conv.3\n",
      "features.3\n",
      "features.3.conv\n",
      "features.3.conv.0\n",
      "features.3.conv.0.0\n",
      "features.3.conv.0.1\n",
      "features.3.conv.0.2\n",
      "features.3.conv.1\n",
      "features.3.conv.1.0\n",
      "features.3.conv.1.1\n",
      "features.3.conv.1.2\n",
      "features.3.conv.2\n",
      "features.3.conv.3\n",
      "features.4\n",
      "features.4.conv\n",
      "features.4.conv.0\n",
      "features.4.conv.0.0\n",
      "features.4.conv.0.1\n",
      "features.4.conv.0.2\n",
      "features.4.conv.1\n",
      "features.4.conv.1.0\n",
      "features.4.conv.1.1\n",
      "features.4.conv.1.2\n",
      "features.4.conv.2\n",
      "features.4.conv.3\n",
      "features.5\n",
      "features.5.conv\n",
      "features.5.conv.0\n",
      "features.5.conv.0.0\n",
      "features.5.conv.0.1\n",
      "features.5.conv.0.2\n",
      "features.5.conv.1\n",
      "features.5.conv.1.0\n",
      "features.5.conv.1.1\n",
      "features.5.conv.1.2\n",
      "features.5.conv.2\n",
      "features.5.conv.3\n",
      "features.6\n",
      "features.6.conv\n",
      "features.6.conv.0\n",
      "features.6.conv.0.0\n",
      "features.6.conv.0.1\n",
      "features.6.conv.0.2\n",
      "features.6.conv.1\n",
      "features.6.conv.1.0\n",
      "features.6.conv.1.1\n",
      "features.6.conv.1.2\n",
      "features.6.conv.2\n",
      "features.6.conv.3\n",
      "features.7\n",
      "features.7.conv\n",
      "features.7.conv.0\n",
      "features.7.conv.0.0\n",
      "features.7.conv.0.1\n",
      "features.7.conv.0.2\n",
      "features.7.conv.1\n",
      "features.7.conv.1.0\n",
      "features.7.conv.1.1\n",
      "features.7.conv.1.2\n",
      "features.7.conv.2\n",
      "features.7.conv.3\n",
      "features.8\n",
      "features.8.conv\n",
      "features.8.conv.0\n",
      "features.8.conv.0.0\n",
      "features.8.conv.0.1\n",
      "features.8.conv.0.2\n",
      "features.8.conv.1\n",
      "features.8.conv.1.0\n",
      "features.8.conv.1.1\n",
      "features.8.conv.1.2\n",
      "features.8.conv.2\n",
      "features.8.conv.3\n",
      "features.9\n",
      "features.9.conv\n",
      "features.9.conv.0\n",
      "features.9.conv.0.0\n",
      "features.9.conv.0.1\n",
      "features.9.conv.0.2\n",
      "features.9.conv.1\n",
      "features.9.conv.1.0\n",
      "features.9.conv.1.1\n",
      "features.9.conv.1.2\n",
      "features.9.conv.2\n",
      "features.9.conv.3\n",
      "features.10\n",
      "features.10.conv\n",
      "features.10.conv.0\n",
      "features.10.conv.0.0\n",
      "features.10.conv.0.1\n",
      "features.10.conv.0.2\n",
      "features.10.conv.1\n",
      "features.10.conv.1.0\n",
      "features.10.conv.1.1\n",
      "features.10.conv.1.2\n",
      "features.10.conv.2\n",
      "features.10.conv.3\n",
      "features.11\n",
      "features.11.conv\n",
      "features.11.conv.0\n",
      "features.11.conv.0.0\n",
      "features.11.conv.0.1\n",
      "features.11.conv.0.2\n",
      "features.11.conv.1\n",
      "features.11.conv.1.0\n",
      "features.11.conv.1.1\n",
      "features.11.conv.1.2\n",
      "features.11.conv.2\n",
      "features.11.conv.3\n",
      "features.12\n",
      "features.12.conv\n",
      "features.12.conv.0\n",
      "features.12.conv.0.0\n",
      "features.12.conv.0.1\n",
      "features.12.conv.0.2\n",
      "features.12.conv.1\n",
      "features.12.conv.1.0\n",
      "features.12.conv.1.1\n",
      "features.12.conv.1.2\n",
      "features.12.conv.2\n",
      "features.12.conv.3\n",
      "features.13\n",
      "features.13.conv\n",
      "features.13.conv.0\n",
      "features.13.conv.0.0\n",
      "features.13.conv.0.1\n",
      "features.13.conv.0.2\n",
      "features.13.conv.1\n",
      "features.13.conv.1.0\n",
      "features.13.conv.1.1\n",
      "features.13.conv.1.2\n",
      "features.13.conv.2\n",
      "features.13.conv.3\n",
      "features.14\n",
      "features.14.conv\n",
      "features.14.conv.0\n",
      "features.14.conv.0.0\n",
      "features.14.conv.0.1\n",
      "features.14.conv.0.2\n",
      "features.14.conv.1\n",
      "features.14.conv.1.0\n",
      "features.14.conv.1.1\n",
      "features.14.conv.1.2\n",
      "features.14.conv.2\n",
      "features.14.conv.3\n",
      "features.15\n",
      "features.15.conv\n",
      "features.15.conv.0\n",
      "features.15.conv.0.0\n",
      "features.15.conv.0.1\n",
      "features.15.conv.0.2\n",
      "features.15.conv.1\n",
      "features.15.conv.1.0\n",
      "features.15.conv.1.1\n",
      "features.15.conv.1.2\n",
      "features.15.conv.2\n",
      "features.15.conv.3\n",
      "features.16\n",
      "features.16.conv\n",
      "features.16.conv.0\n",
      "features.16.conv.0.0\n",
      "features.16.conv.0.1\n",
      "features.16.conv.0.2\n",
      "features.16.conv.1\n",
      "features.16.conv.1.0\n",
      "features.16.conv.1.1\n",
      "features.16.conv.1.2\n",
      "features.16.conv.2\n",
      "features.16.conv.3\n",
      "features.17\n",
      "features.17.conv\n",
      "features.17.conv.0\n",
      "features.17.conv.0.0\n",
      "features.17.conv.0.1\n",
      "features.17.conv.0.2\n",
      "features.17.conv.1\n",
      "features.17.conv.1.0\n",
      "features.17.conv.1.1\n",
      "features.17.conv.1.2\n",
      "features.17.conv.2\n",
      "features.17.conv.3\n",
      "features.18\n",
      "features.18.0\n",
      "features.18.1\n",
      "features.18.2\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.1\n"
     ]
    }
   ],
   "source": [
    "# name of each layer\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape of layer 0 : torch.Size([1, 32, 112, 112])\n",
      "output shape of layer 1 : torch.Size([1, 16, 112, 112])\n",
      "output shape of layer 2 : torch.Size([1, 24, 56, 56])\n",
      "output shape of layer 3 : torch.Size([1, 24, 56, 56])\n",
      "output shape of layer 4 : torch.Size([1, 32, 28, 28])\n",
      "output shape of layer 5 : torch.Size([1, 32, 28, 28])\n",
      "output shape of layer 6 : torch.Size([1, 32, 28, 28])\n",
      "output shape of layer 7 : torch.Size([1, 64, 14, 14])\n",
      "output shape of layer 8 : torch.Size([1, 64, 14, 14])\n",
      "output shape of layer 9 : torch.Size([1, 64, 14, 14])\n",
      "output shape of layer 10 : torch.Size([1, 64, 14, 14])\n",
      "output shape of layer 11 : torch.Size([1, 96, 14, 14])\n",
      "output shape of layer 12 : torch.Size([1, 96, 14, 14])\n",
      "output shape of layer 13 : torch.Size([1, 96, 14, 14])\n",
      "output shape of layer 14 : torch.Size([1, 160, 7, 7])\n",
      "output shape of layer 15 : torch.Size([1, 160, 7, 7])\n",
      "output shape of layer 16 : torch.Size([1, 160, 7, 7])\n",
      "output shape of layer 17 : torch.Size([1, 320, 7, 7])\n",
      "output shape of layer 18 : torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(list(model.features))):\n",
    "    new_model = torch.nn.Sequential(*list(model.features.children())[: n + 1]).to(\"cpu\")\n",
    "    # new_model = (model.features[:N+1]).to(\"cpu\")\n",
    "    input_data = torch.randn(1, 3, 224, 224).to(\"cpu\")\n",
    "    output = new_model(input_data)\n",
    "    print(f\"output shape of layer {n} : {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timm MobileNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv1_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 64, 112, 112])\n",
    "    #  torch.Size([1, 128, 56, 56])\n",
    "    #  torch.Size([1, 256, 28, 28])\n",
    "    #  torch.Size([1, 512, 14, 14])\n",
    "    #  torch.Size([1, 1024, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 3.207M                 | 1.179G     |\\n'\n",
      " '|  conv_stem            |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight    |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight          |   (32,)                |            |\\n'\n",
      " '|   bn1.bias            |   (32,)                |            |\\n'\n",
      " '|  blocks               |  3.206M                |  1.155G    |\\n'\n",
      " '|   blocks.0.0          |   2.528K               |   64.717M  |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.288K              |    7.373M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    64                  |    1.638M  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    2.048K              |    52.429M |\\n'\n",
      " '|    blocks.0.0.bn2     |    0.128K              |    3.277M  |\\n'\n",
      " '|   blocks.1            |   27.2K                |   0.174G   |\\n'\n",
      " '|    blocks.1.0         |    9.152K              |    58.573M |\\n'\n",
      " '|    blocks.1.1         |    18.048K             |    0.116G  |\\n'\n",
      " '|   blocks.2            |   0.104M               |   0.166G   |\\n'\n",
      " '|    blocks.2.0         |    34.688K             |    55.501M |\\n'\n",
      " '|    blocks.2.1         |    68.864K             |    0.11G   |\\n'\n",
      " '|   blocks.3            |   1.479M               |   0.592G   |\\n'\n",
      " '|    blocks.3.0         |    0.135M              |    53.965M |\\n'\n",
      " '|    blocks.3.1         |    0.269M              |    0.108G  |\\n'\n",
      " '|    blocks.3.2         |    0.269M              |    0.108G  |\\n'\n",
      " '|    blocks.3.3         |    0.269M              |    0.108G  |\\n'\n",
      " '|    blocks.3.4         |    0.269M              |    0.108G  |\\n'\n",
      " '|    blocks.3.5         |    0.269M              |    0.108G  |\\n'\n",
      " '|   blocks.4            |   1.594M               |   0.159G   |\\n'\n",
      " '|    blocks.4.0         |    0.532M              |    53.197M |\\n'\n",
      " '|    blocks.4.1         |    1.062M              |    0.106G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv1_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timm mobilenetv2_050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 112, 112])\n",
      "torch.Size([1, 16, 56, 56])\n",
      "torch.Size([1, 16, 28, 28])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 160, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_050\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 8, 112, 112])\n",
    "    #  torch.Size([1, 16, 56, 56])\n",
    "    #  torch.Size([1, 16, 28, 28])\n",
    "    #  torch.Size([1, 48, 14, 14])\n",
    "    #  torch.Size([1, 160, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 0.48M                  | 0.19G      |\\n'\n",
      " '|  conv_stem             |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight     |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight           |   (16,)                |            |\\n'\n",
      " '|   bn1.bias             |   (16,)                |            |\\n'\n",
      " '|  blocks                |  0.48M                 |  0.178G    |\\n'\n",
      " '|   blocks.0.0           |   0.32K                |   8.192M   |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1      |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    0.128K              |    3.277M  |\\n'\n",
      " '|    blocks.0.0.bn2      |    16                  |    0.41M   |\\n'\n",
      " '|   blocks.1             |   6.16K                |   48.64M   |\\n'\n",
      " '|    blocks.1.0          |    1.808K              |    20.787M |\\n'\n",
      " '|    blocks.1.1          |    4.352K              |    27.853M |\\n'\n",
      " '|   blocks.2             |   13.056K              |   29.184M  |\\n'\n",
      " '|    blocks.2.0          |    4.352K              |    15.258M |\\n'\n",
      " '|    blocks.2.1          |    4.352K              |    6.963M  |\\n'\n",
      " '|    blocks.2.2          |    4.352K              |    6.963M  |\\n'\n",
      " '|   blocks.3             |   50.464K              |   22.259M  |\\n'\n",
      " '|    blocks.3.0          |    5.92K               |    4.442M  |\\n'\n",
      " '|    blocks.3.1          |    14.848K             |    5.939M  |\\n'\n",
      " '|    blocks.3.2          |    14.848K             |    5.939M  |\\n'\n",
      " '|    blocks.3.3          |    14.848K             |    5.939M  |\\n'\n",
      " '|   blocks.4             |   80.928K              |   32.371M  |\\n'\n",
      " '|    blocks.4.0          |    17.952K             |    7.181M  |\\n'\n",
      " '|    blocks.4.1          |    31.488K             |    12.595M |\\n'\n",
      " '|    blocks.4.2          |    31.488K             |    12.595M |\\n'\n",
      " '|   blocks.5             |   0.207M               |   25.037M  |\\n'\n",
      " '|    blocks.5.0          |    40.768K             |    8.397M  |\\n'\n",
      " '|    blocks.5.1          |    83.2K               |    8.32M   |\\n'\n",
      " '|    blocks.5.2          |    83.2K               |    8.32M   |\\n'\n",
      " '|   blocks.6.0           |   0.122M               |   12.176M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    38.4K               |    3.84M   |\\n'\n",
      " '|    blocks.6.0.bn1      |    0.96K               |    96K     |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    4.32K               |    0.432M  |\\n'\n",
      " '|    blocks.6.0.bn2      |    0.96K               |    96K     |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    76.8K               |    7.68M   |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.32K               |    32K     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_050\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv2_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 112, 112])\n",
      "torch.Size([1, 16, 56, 56])\n",
      "torch.Size([1, 16, 28, 28])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 160, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_050\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 8, 112, 112])\n",
    "    #  torch.Size([1, 16, 56, 56])\n",
    "    #  torch.Size([1, 16, 28, 28])\n",
    "    #  torch.Size([1, 48, 14, 14])\n",
    "    #  torch.Size([1, 160, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 0.48M                  | 0.19G      |\\n'\n",
      " '|  conv_stem             |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight     |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight           |   (16,)                |            |\\n'\n",
      " '|   bn1.bias             |   (16,)                |            |\\n'\n",
      " '|  blocks                |  0.48M                 |  0.178G    |\\n'\n",
      " '|   blocks.0.0           |   0.32K                |   8.192M   |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1      |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    0.128K              |    3.277M  |\\n'\n",
      " '|    blocks.0.0.bn2      |    16                  |    0.41M   |\\n'\n",
      " '|   blocks.1             |   6.16K                |   48.64M   |\\n'\n",
      " '|    blocks.1.0          |    1.808K              |    20.787M |\\n'\n",
      " '|    blocks.1.1          |    4.352K              |    27.853M |\\n'\n",
      " '|   blocks.2             |   13.056K              |   29.184M  |\\n'\n",
      " '|    blocks.2.0          |    4.352K              |    15.258M |\\n'\n",
      " '|    blocks.2.1          |    4.352K              |    6.963M  |\\n'\n",
      " '|    blocks.2.2          |    4.352K              |    6.963M  |\\n'\n",
      " '|   blocks.3             |   50.464K              |   22.259M  |\\n'\n",
      " '|    blocks.3.0          |    5.92K               |    4.442M  |\\n'\n",
      " '|    blocks.3.1          |    14.848K             |    5.939M  |\\n'\n",
      " '|    blocks.3.2          |    14.848K             |    5.939M  |\\n'\n",
      " '|    blocks.3.3          |    14.848K             |    5.939M  |\\n'\n",
      " '|   blocks.4             |   80.928K              |   32.371M  |\\n'\n",
      " '|    blocks.4.0          |    17.952K             |    7.181M  |\\n'\n",
      " '|    blocks.4.1          |    31.488K             |    12.595M |\\n'\n",
      " '|    blocks.4.2          |    31.488K             |    12.595M |\\n'\n",
      " '|   blocks.5             |   0.207M               |   25.037M  |\\n'\n",
      " '|    blocks.5.0          |    40.768K             |    8.397M  |\\n'\n",
      " '|    blocks.5.1          |    83.2K               |    8.32M   |\\n'\n",
      " '|    blocks.5.2          |    83.2K               |    8.32M   |\\n'\n",
      " '|   blocks.6.0           |   0.122M               |   12.176M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    38.4K               |    3.84M   |\\n'\n",
      " '|    blocks.6.0.bn1      |    0.96K               |    96K     |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    4.32K               |    0.432M  |\\n'\n",
      " '|    blocks.6.0.bn2      |    0.96K               |    96K     |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    76.8K               |    7.68M   |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.32K               |    32K     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_050\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## moblienetv2_075\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timm api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 72, 14, 14])\n",
      "torch.Size([1, 240, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_075\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 1.046M                 | 0.417G     |\\n'\n",
      " '|  conv_stem             |  0.648K                |  16.589M   |\\n'\n",
      " '|   conv_stem.weight     |   (24, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  48                    |  1.229M    |\\n'\n",
      " '|   bn1.weight           |   (24,)                |            |\\n'\n",
      " '|   bn1.bias             |   (24,)                |            |\\n'\n",
      " '|  blocks                |  1.045M                |  0.399G    |\\n'\n",
      " '|   blocks.0.0           |   0.68K                |   17.408M  |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.216K              |    5.53M   |\\n'\n",
      " '|    blocks.0.0.bn1      |    48                  |    1.229M  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    0.384K              |    9.83M   |\\n'\n",
      " '|    blocks.0.0.bn2      |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1             |   13.968K              |   0.123G   |\\n'\n",
      " '|    blocks.1.0          |    5.136K              |    66.048M |\\n'\n",
      " '|    blocks.1.1          |    8.832K              |    56.525M |\\n'\n",
      " '|   blocks.2             |   26.496K              |   60.365M  |\\n'\n",
      " '|    blocks.2.0          |    8.832K              |    32.102M |\\n'\n",
      " '|    blocks.2.1          |    8.832K              |    14.131M |\\n'\n",
      " '|    blocks.2.2          |    8.832K              |    14.131M |\\n'\n",
      " '|   blocks.3             |   0.107M               |   47.213M  |\\n'\n",
      " '|    blocks.3.0          |    12.336K             |    9.427M  |\\n'\n",
      " '|    blocks.3.1          |    31.488K             |    12.595M |\\n'\n",
      " '|    blocks.3.2          |    31.488K             |    12.595M |\\n'\n",
      " '|    blocks.3.3          |    31.488K             |    12.595M |\\n'\n",
      " '|   blocks.4             |   0.174M               |   69.754M  |\\n'\n",
      " '|    blocks.4.0          |    38.448K             |    15.379M |\\n'\n",
      " '|    blocks.4.1          |    67.968K             |    27.187M |\\n'\n",
      " '|    blocks.4.2          |    67.968K             |    27.187M |\\n'\n",
      " '|   blocks.5             |   0.454M               |   54.95M   |\\n'\n",
      " '|    blocks.5.0          |    88.8K               |    18.47M  |\\n'\n",
      " '|    blocks.5.1          |    0.182M              |    18.24M  |\\n'\n",
      " '|    blocks.5.2          |    0.182M              |    18.24M  |\\n'\n",
      " '|   blocks.6.0           |   0.269M               |   26.904M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    86.4K               |    8.64M   |\\n'\n",
      " '|    blocks.6.0.bn1      |    1.44K               |    0.144M  |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    6.48K               |    0.648M  |\\n'\n",
      " '|    blocks.6.0.bn2      |    1.44K               |    0.144M  |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    0.173M              |    17.28M  |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.48K               |    48K     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_075\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformers api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 72, 14, 14])\n",
      "torch.Size([1, 72, 14, 14])\n",
      "torch.Size([1, 72, 14, 14])\n",
      "torch.Size([1, 120, 7, 7])\n",
      "torch.Size([1, 120, 7, 7])\n",
      "torch.Size([1, 120, 7, 7])\n",
      "torch.Size([1, 240, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import MobileNetV2Config, MobileNetV2Model, AutoImageProcessor\n",
    "\n",
    "configuration = MobileNetV2Config(depth_multiplier=0.75)\n",
    "model = MobileNetV2Model(configuration)\n",
    "model = model.eval()\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/mobilenet_v2_1.0_224\")\n",
    "inputs = image_processor(img, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # outputs = model(**inputs, output_hidden_states=True)\n",
    "    outputs = model(inputs[\"pixel_values\"], output_hidden_states=True)\n",
    "\n",
    "for o in outputs[\"hidden_states\"]:\n",
    "    # print shape of each feature map in output\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 72, 14, 14])\n",
      "torch.Size([1, 240, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(outputs[\"hidden_states\"][1].shape)\n",
    "print(outputs[\"hidden_states\"][4].shape)\n",
    "print(outputs[\"hidden_states\"][11].shape)\n",
    "print(outputs[\"hidden_states\"][-1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv2_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 96, 14, 14])\n",
      "torch.Size([1, 320, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 1.812M                 | 0.597G     |\\n'\n",
      " '|  conv_stem             |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight     |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight           |   (32,)                |            |\\n'\n",
      " '|   bn1.bias             |   (32,)                |            |\\n'\n",
      " '|  blocks                |  1.811M                |  0.573G    |\\n'\n",
      " '|   blocks.0.0           |   0.896K               |   22.938M  |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.288K              |    7.373M  |\\n'\n",
      " '|    blocks.0.0.bn1      |    64                  |    1.638M  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    0.512K              |    13.107M |\\n'\n",
      " '|    blocks.0.0.bn2      |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1             |   13.968K              |   0.123G   |\\n'\n",
      " '|    blocks.1.0          |    5.136K              |    66.048M |\\n'\n",
      " '|    blocks.1.1          |    8.832K              |    56.525M |\\n'\n",
      " '|   blocks.2             |   39.696K              |   81.485M  |\\n'\n",
      " '|    blocks.2.0          |    10K                 |    33.971M |\\n'\n",
      " '|    blocks.2.1          |    14.848K             |    23.757M |\\n'\n",
      " '|    blocks.2.2          |    14.848K             |    23.757M |\\n'\n",
      " '|   blocks.3             |   0.184M               |   81.382M  |\\n'\n",
      " '|    blocks.3.0          |    21.056K             |    16.256M |\\n'\n",
      " '|    blocks.3.1          |    54.272K             |    21.709M |\\n'\n",
      " '|    blocks.3.2          |    54.272K             |    21.709M |\\n'\n",
      " '|    blocks.3.3          |    54.272K             |    21.709M |\\n'\n",
      " '|   blocks.4             |   0.303M               |   0.121G   |\\n'\n",
      " '|    blocks.4.0          |    66.624K             |    26.65M  |\\n'\n",
      " '|    blocks.4.1          |    0.118M              |    47.309M |\\n'\n",
      " '|    blocks.4.2          |    0.118M              |    47.309M |\\n'\n",
      " '|   blocks.5             |   0.795M               |   96.461M  |\\n'\n",
      " '|    blocks.5.0          |    0.155M              |    32.461M |\\n'\n",
      " '|    blocks.5.1          |    0.32M               |    32M     |\\n'\n",
      " '|    blocks.5.2          |    0.32M               |    32M     |\\n'\n",
      " '|   blocks.6.0           |   0.474M               |   47.392M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    0.154M              |    15.36M  |\\n'\n",
      " '|    blocks.6.0.bn1      |    1.92K               |    0.192M  |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    8.64K               |    0.864M  |\\n'\n",
      " '|    blocks.6.0.bn2      |    1.92K               |    0.192M  |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    0.307M              |    30.72M  |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.64K               |    64K     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_100.ra_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting layers up to stride 8 from mobilenetv2_100...\n",
      "extracting layers up to stride 8 from mobilenetv2_100...\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "from models.model import ObjectCentroidDetection\n",
    "\n",
    "model_map = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv2_100\", half=False\n",
    ")\n",
    "model_half = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv2_100\", half=True\n",
    ")\n",
    "print(model_map(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(model_half(torch.randn(1, 3, 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 32, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 32, 112, 112]        864\n",
      "|    BatchNormAct2d: 2-2                    [-1, 32, 112, 112]        --\n",
      "|    |    Identity: 3-1                     [-1, 32, 112, 112]        --\n",
      "|    |    ReLU6: 3-2                        [-1, 32, 112, 112]        --\n",
      "|    Sequential: 2-3                        [-1, 16, 112, 112]        --\n",
      "|    |    DepthwiseSeparableConv: 3-3       [-1, 16, 112, 112]        896\n",
      "|    Sequential: 2-4                        [-1, 24, 56, 56]          --\n",
      "|    |    InvertedResidual: 3-4             [-1, 24, 56, 56]          5,136\n",
      "|    |    InvertedResidual: 3-5             [-1, 24, 56, 56]          8,832\n",
      "|    Sequential: 2-5                        [-1, 32, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-6             [-1, 32, 28, 28]          10,000\n",
      "|    |    InvertedResidual: 3-7             [-1, 32, 28, 28]          14,848\n",
      "|    |    InvertedResidual: 3-8             [-1, 32, 28, 28]          14,848\n",
      "Conv2d: 1-2                                 [-1, 1, 28, 28]           33\n",
      "===============================================================================================\n",
      "Total params: 55,457\n",
      "Trainable params: 55,457\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 113.45\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 36.66\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 37.45\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_map, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 32, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 32, 112, 112]        864\n",
      "|    BatchNormAct2d: 2-2                    [-1, 32, 112, 112]        --\n",
      "|    |    Identity: 3-1                     [-1, 32, 112, 112]        --\n",
      "|    |    ReLU6: 3-2                        [-1, 32, 112, 112]        --\n",
      "|    Sequential: 2-3                        [-1, 16, 112, 112]        --\n",
      "|    |    DepthwiseSeparableConv: 3-3       [-1, 16, 112, 112]        896\n",
      "|    Sequential: 2-4                        [-1, 24, 56, 56]          --\n",
      "|    |    InvertedResidual: 3-4             [-1, 24, 56, 56]          5,136\n",
      "|    |    InvertedResidual: 3-5             [-1, 24, 56, 56]          8,832\n",
      "|    Sequential: 2-5                        [-1, 32, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-6             [-1, 32, 28, 28]          10,000\n",
      "|    |    InvertedResidual: 3-7             [-1, 32, 28, 28]          14,848\n",
      "|    |    InvertedResidual: 3-8             [-1, 32, 28, 28]          14,848\n",
      "Sequential: 1-2                             [-1, 2]                   --\n",
      "|    AdaptiveAvgPool2d: 2-6                 [-1, 32, 1, 1]            --\n",
      "|    Flatten: 2-7                           [-1, 32]                  --\n",
      "|    Linear: 2-8                            [-1, 2]                   66\n",
      "===============================================================================================\n",
      "Total params: 55,490\n",
      "Trainable params: 55,490\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 113.42\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 36.65\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 37.44\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model_half, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv2_140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e476860709894691a19c664f6b62e641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/24.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 112, 112])\n",
      "torch.Size([1, 32, 56, 56])\n",
      "torch.Size([1, 48, 28, 28])\n",
      "torch.Size([1, 136, 14, 14])\n",
      "torch.Size([1, 448, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_140.ra_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 24, 112, 112])\n",
    "    #  torch.Size([1, 32, 56, 56])\n",
    "    #  torch.Size([1, 48, 28, 28])\n",
    "    #  torch.Size([1, 136, 14, 14])\n",
    "    #  torch.Size([1, 448, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 3.509M                 | 1.143G     |\\n'\n",
      " '|  conv_stem             |  1.296K                |  33.178M   |\\n'\n",
      " '|   conv_stem.weight     |   (48, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  96                    |  2.458M    |\\n'\n",
      " '|   bn1.weight           |   (48,)                |            |\\n'\n",
      " '|   bn1.bias             |   (48,)                |            |\\n'\n",
      " '|  blocks                |  3.508M                |  1.107G    |\\n'\n",
      " '|   blocks.0.0           |   1.728K               |   44.237M  |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.432K              |    11.059M |\\n'\n",
      " '|    blocks.0.0.bn1      |    96                  |    2.458M  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    1.152K              |    29.491M |\\n'\n",
      " '|    blocks.0.0.bn2      |    48                  |    1.229M  |\\n'\n",
      " '|   blocks.1             |   24.848K              |   0.231G   |\\n'\n",
      " '|    blocks.1.0          |    10K                 |    0.136G  |\\n'\n",
      " '|    blocks.1.1          |    14.848K             |    95.027M |\\n'\n",
      " '|   blocks.2             |   80.928K              |   0.161G   |\\n'\n",
      " '|    blocks.2.0          |    17.952K             |    60.058M |\\n'\n",
      " '|    blocks.2.1          |    31.488K             |    50.381M |\\n'\n",
      " '|    blocks.2.2          |    31.488K             |    50.381M |\\n'\n",
      " '|   blocks.3             |   0.343M               |   0.154G   |\\n'\n",
      " '|    blocks.3.0          |    43.088K             |    34.515M |\\n'\n",
      " '|    blocks.3.1          |    99.968K             |    39.987M |\\n'\n",
      " '|    blocks.3.2          |    99.968K             |    39.987M |\\n'\n",
      " '|    blocks.3.3          |    99.968K             |    39.987M |\\n'\n",
      " '|   blocks.4             |   0.591M               |   0.236G   |\\n'\n",
      " '|    blocks.4.0          |    0.125M              |    50.163M |\\n'\n",
      " '|    blocks.4.1          |    0.233M              |    93.133M |\\n'\n",
      " '|    blocks.4.2          |    0.233M              |    93.133M |\\n'\n",
      " '|   blocks.5             |   1.545M               |   0.188G   |\\n'\n",
      " '|    blocks.5.0          |    0.305M              |    64.264M |\\n'\n",
      " '|    blocks.5.1          |    0.62M               |    62.003M |\\n'\n",
      " '|    blocks.5.2          |    0.62M               |    62.003M |\\n'\n",
      " '|   blocks.6.0           |   0.922M               |   92.154M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    0.301M              |    30.106M |\\n'\n",
      " '|    blocks.6.0.bn1      |    2.688K              |    0.269M  |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    12.096K             |    1.21M   |\\n'\n",
      " '|    blocks.6.0.bn2      |    2.688K              |    0.269M  |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    0.602M              |    60.211M |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.896K              |    89.6K   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv2_140\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv3_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### mobilenetv3_large_075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 88, 14, 14])\n",
      "torch.Size([1, 720, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_075\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 1.79M                  | 0.326G     |\\n'\n",
      " '|  conv_stem            |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight    |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight          |   (16,)                |            |\\n'\n",
      " '|   bn1.bias            |   (16,)                |            |\\n'\n",
      " '|  blocks               |  1.789M                |  0.314G    |\\n'\n",
      " '|   blocks.0.0          |   0.464K               |   11.878M  |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    0.256K              |    6.554M  |\\n'\n",
      " '|    blocks.0.0.bn2     |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1            |   7.88K                |   72.55M   |\\n'\n",
      " '|    blocks.1.0         |    3.44K               |    44.134M |\\n'\n",
      " '|    blocks.1.1         |    4.44K               |    28.416M |\\n'\n",
      " '|   blocks.2            |   37.176K              |   47.667M  |\\n'\n",
      " '|    blocks.2.0         |    9.736K              |    18.883M |\\n'\n",
      " '|    blocks.2.1         |    13.72K              |    14.392M |\\n'\n",
      " '|    blocks.2.2         |    13.72K              |    14.392M |\\n'\n",
      " '|   blocks.3            |   84.608K              |   41.677M  |\\n'\n",
      " '|    blocks.3.0         |    21.056K             |    16.256M |\\n'\n",
      " '|    blocks.3.1         |    22.688K             |    9.075M  |\\n'\n",
      " '|    blocks.3.2         |    20.432K             |    8.173M  |\\n'\n",
      " '|    blocks.3.3         |    20.432K             |    8.173M  |\\n'\n",
      " '|   blocks.4            |   0.382M               |   65.619M  |\\n'\n",
      " '|    blocks.4.0         |    0.138M              |    25.488M |\\n'\n",
      " '|    blocks.4.1         |    0.244M              |    40.131M |\\n'\n",
      " '|   blocks.5            |   1.189M               |   66.251M  |\\n'\n",
      " '|    blocks.5.0         |    0.27M               |    26.937M |\\n'\n",
      " '|    blocks.5.1         |    0.46M               |    19.657M |\\n'\n",
      " '|    blocks.5.2         |    0.46M               |    19.657M |\\n'\n",
      " '|   blocks.6.0          |   87.84K               |   8.784M   |\\n'\n",
      " '|    blocks.6.0.conv    |    86.4K               |    8.64M   |\\n'\n",
      " '|    blocks.6.0.bn1     |    1.44K               |    0.144M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_075\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### mobilenetv3_large_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 40, 28, 28])\n",
      "torch.Size([1, 112, 14, 14])\n",
      "torch.Size([1, 960, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 2.972M                 | 0.453G     |\\n'\n",
      " '|  conv_stem            |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight    |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight          |   (16,)                |            |\\n'\n",
      " '|   bn1.bias            |   (16,)                |            |\\n'\n",
      " '|  blocks               |  2.971M                |  0.441G    |\\n'\n",
      " '|   blocks.0.0          |   0.464K               |   11.878M  |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    0.256K              |    6.554M  |\\n'\n",
      " '|    blocks.0.0.bn2     |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1            |   7.88K                |   72.55M   |\\n'\n",
      " '|    blocks.1.0         |    3.44K               |    44.134M |\\n'\n",
      " '|    blocks.1.1         |    4.44K               |    28.416M |\\n'\n",
      " '|   blocks.2            |   52.312K              |   61.958M  |\\n'\n",
      " '|    blocks.2.0         |    10.328K             |    19.831M |\\n'\n",
      " '|    blocks.2.1         |    20.992K             |    21.064M |\\n'\n",
      " '|    blocks.2.2         |    20.992K             |    21.064M |\\n'\n",
      " '|   blocks.3            |   0.131M               |   64.426M  |\\n'\n",
      " '|    blocks.3.0         |    32.08K              |    24.928M |\\n'\n",
      " '|    blocks.3.1         |    34.76K              |    13.904M |\\n'\n",
      " '|    blocks.3.2         |    31.992K             |    12.797M |\\n'\n",
      " '|    blocks.3.3         |    31.992K             |    12.797M |\\n'\n",
      " '|   blocks.4            |   0.601M               |   0.104G   |\\n'\n",
      " '|    blocks.4.0         |    0.214M              |    39.565M |\\n'\n",
      " '|    blocks.4.1         |    0.386M              |    64.021M |\\n'\n",
      " '|   blocks.5            |   2.024M               |   0.111G   |\\n'\n",
      " '|    blocks.5.0         |    0.429M              |    43.467M |\\n'\n",
      " '|    blocks.5.1         |    0.797M              |    33.997M |\\n'\n",
      " '|    blocks.5.2         |    0.797M              |    33.997M |\\n'\n",
      " '|   blocks.6.0          |   0.156M               |   15.552M  |\\n'\n",
      " '|    blocks.6.0.conv    |    0.154M              |    15.36M  |\\n'\n",
      " '|    blocks.6.0.bn1     |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf_mobilenetv3_large_075\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5394440ccf49ab96c8781a403459c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/16.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 88, 14, 14])\n",
      "torch.Size([1, 720, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"tf_mobilenetv3_large_075.in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 16, 112, 112])\n",
    "    #  torch.Size([1, 24, 56, 56])\n",
    "    #  torch.Size([1, 32, 28, 28])\n",
    "    #  torch.Size([1, 88, 14, 14])\n",
    "    #  torch.Size([1, 720, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 1.79M                  | 0.326G     |\\n'\n",
      " '|  conv_stem            |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight    |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight          |   (16,)                |            |\\n'\n",
      " '|   bn1.bias            |   (16,)                |            |\\n'\n",
      " '|  blocks               |  1.789M                |  0.314G    |\\n'\n",
      " '|   blocks.0.0          |   0.464K               |   11.878M  |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    0.256K              |    6.554M  |\\n'\n",
      " '|    blocks.0.0.bn2     |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1            |   7.88K                |   72.55M   |\\n'\n",
      " '|    blocks.1.0         |    3.44K               |    44.134M |\\n'\n",
      " '|    blocks.1.1         |    4.44K               |    28.416M |\\n'\n",
      " '|   blocks.2            |   37.176K              |   47.667M  |\\n'\n",
      " '|    blocks.2.0         |    9.736K              |    18.883M |\\n'\n",
      " '|    blocks.2.1         |    13.72K              |    14.392M |\\n'\n",
      " '|    blocks.2.2         |    13.72K              |    14.392M |\\n'\n",
      " '|   blocks.3            |   84.608K              |   41.677M  |\\n'\n",
      " '|    blocks.3.0         |    21.056K             |    16.256M |\\n'\n",
      " '|    blocks.3.1         |    22.688K             |    9.075M  |\\n'\n",
      " '|    blocks.3.2         |    20.432K             |    8.173M  |\\n'\n",
      " '|    blocks.3.3         |    20.432K             |    8.173M  |\\n'\n",
      " '|   blocks.4            |   0.382M               |   65.619M  |\\n'\n",
      " '|    blocks.4.0         |    0.138M              |    25.488M |\\n'\n",
      " '|    blocks.4.1         |    0.244M              |    40.131M |\\n'\n",
      " '|   blocks.5            |   1.189M               |   66.251M  |\\n'\n",
      " '|    blocks.5.0         |    0.27M               |    26.937M |\\n'\n",
      " '|    blocks.5.1         |    0.46M               |    19.657M |\\n'\n",
      " '|    blocks.5.2         |    0.46M               |    19.657M |\\n'\n",
      " '|   blocks.6.0          |   87.84K               |   8.784M   |\\n'\n",
      " '|    blocks.6.0.conv    |    86.4K               |    8.64M   |\\n'\n",
      " '|    blocks.6.0.bn1     |    1.44K               |    0.144M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"tf_mobilenetv3_large_075\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timm mobilenetv3_large_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 40, 28, 28])\n",
      "torch.Size([1, 112, 14, 14])\n",
      "torch.Size([1, 960, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_100.ra_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 16, 112, 112])\n",
    "    #  torch.Size([1, 24, 56, 56])\n",
    "    #  torch.Size([1, 40, 28, 28])\n",
    "    #  torch.Size([1, 112, 14, 14])\n",
    "    #  torch.Size([1, 960, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 2.972M                 | 0.453G     |\\n'\n",
      " '|  conv_stem            |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight    |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight          |   (16,)                |            |\\n'\n",
      " '|   bn1.bias            |   (16,)                |            |\\n'\n",
      " '|  blocks               |  2.971M                |  0.441G    |\\n'\n",
      " '|   blocks.0.0          |   0.464K               |   11.878M  |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.144K              |    3.686M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    32                  |    0.819M  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    0.256K              |    6.554M  |\\n'\n",
      " '|    blocks.0.0.bn2     |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1            |   7.88K                |   72.55M   |\\n'\n",
      " '|    blocks.1.0         |    3.44K               |    44.134M |\\n'\n",
      " '|    blocks.1.1         |    4.44K               |    28.416M |\\n'\n",
      " '|   blocks.2            |   52.312K              |   61.958M  |\\n'\n",
      " '|    blocks.2.0         |    10.328K             |    19.831M |\\n'\n",
      " '|    blocks.2.1         |    20.992K             |    21.064M |\\n'\n",
      " '|    blocks.2.2         |    20.992K             |    21.064M |\\n'\n",
      " '|   blocks.3            |   0.131M               |   64.426M  |\\n'\n",
      " '|    blocks.3.0         |    32.08K              |    24.928M |\\n'\n",
      " '|    blocks.3.1         |    34.76K              |    13.904M |\\n'\n",
      " '|    blocks.3.2         |    31.992K             |    12.797M |\\n'\n",
      " '|    blocks.3.3         |    31.992K             |    12.797M |\\n'\n",
      " '|   blocks.4            |   0.601M               |   0.104G   |\\n'\n",
      " '|    blocks.4.0         |    0.214M              |    39.565M |\\n'\n",
      " '|    blocks.4.1         |    0.386M              |    64.021M |\\n'\n",
      " '|   blocks.5            |   2.024M               |   0.111G   |\\n'\n",
      " '|    blocks.5.0         |    0.429M              |    43.467M |\\n'\n",
      " '|    blocks.5.1         |    0.797M              |    33.997M |\\n'\n",
      " '|    blocks.5.2         |    0.797M              |    33.997M |\\n'\n",
      " '|   blocks.6.0          |   0.156M               |   15.552M  |\\n'\n",
      " '|    blocks.6.0.conv    |    0.154M              |    15.36M  |\\n'\n",
      " '|    blocks.6.0.bn1     |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_100.ra_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3Features(\n",
       "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): Hardswish()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(\n",
    "    \"mobilenetv3_large_100\", pretrained=True, features_only=True\n",
    ")  # note that model structure is different from with or without features_only\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv_stem\n",
      "bn1\n",
      "act1\n",
      "blocks\n",
      "blocks.0\n",
      "blocks.0.0\n",
      "blocks.0.0.conv_dw\n",
      "blocks.0.0.bn1\n",
      "blocks.0.0.bn1.drop\n",
      "blocks.0.0.bn1.act\n",
      "blocks.0.0.se\n",
      "blocks.0.0.conv_pw\n",
      "blocks.0.0.bn2\n",
      "blocks.0.0.bn2.drop\n",
      "blocks.0.0.bn2.act\n",
      "blocks.0.0.drop_path\n",
      "blocks.1\n",
      "blocks.1.0\n",
      "blocks.1.0.conv_pw\n",
      "blocks.1.0.bn1\n",
      "blocks.1.0.bn1.drop\n",
      "blocks.1.0.bn1.act\n",
      "blocks.1.0.conv_dw\n",
      "blocks.1.0.bn2\n",
      "blocks.1.0.bn2.drop\n",
      "blocks.1.0.bn2.act\n",
      "blocks.1.0.se\n",
      "blocks.1.0.conv_pwl\n",
      "blocks.1.0.bn3\n",
      "blocks.1.0.bn3.drop\n",
      "blocks.1.0.bn3.act\n",
      "blocks.1.0.drop_path\n",
      "blocks.1.1\n",
      "blocks.1.1.conv_pw\n",
      "blocks.1.1.bn1\n",
      "blocks.1.1.bn1.drop\n",
      "blocks.1.1.bn1.act\n",
      "blocks.1.1.conv_dw\n",
      "blocks.1.1.bn2\n",
      "blocks.1.1.bn2.drop\n",
      "blocks.1.1.bn2.act\n",
      "blocks.1.1.se\n",
      "blocks.1.1.conv_pwl\n",
      "blocks.1.1.bn3\n",
      "blocks.1.1.bn3.drop\n",
      "blocks.1.1.bn3.act\n",
      "blocks.1.1.drop_path\n",
      "blocks.2\n",
      "blocks.2.0\n",
      "blocks.2.0.conv_pw\n",
      "blocks.2.0.bn1\n",
      "blocks.2.0.bn1.drop\n",
      "blocks.2.0.bn1.act\n",
      "blocks.2.0.conv_dw\n",
      "blocks.2.0.bn2\n",
      "blocks.2.0.bn2.drop\n",
      "blocks.2.0.bn2.act\n",
      "blocks.2.0.se\n",
      "blocks.2.0.se.conv_reduce\n",
      "blocks.2.0.se.act1\n",
      "blocks.2.0.se.conv_expand\n",
      "blocks.2.0.se.gate\n",
      "blocks.2.0.conv_pwl\n",
      "blocks.2.0.bn3\n",
      "blocks.2.0.bn3.drop\n",
      "blocks.2.0.bn3.act\n",
      "blocks.2.0.drop_path\n",
      "blocks.2.1\n",
      "blocks.2.1.conv_pw\n",
      "blocks.2.1.bn1\n",
      "blocks.2.1.bn1.drop\n",
      "blocks.2.1.bn1.act\n",
      "blocks.2.1.conv_dw\n",
      "blocks.2.1.bn2\n",
      "blocks.2.1.bn2.drop\n",
      "blocks.2.1.bn2.act\n",
      "blocks.2.1.se\n",
      "blocks.2.1.se.conv_reduce\n",
      "blocks.2.1.se.act1\n",
      "blocks.2.1.se.conv_expand\n",
      "blocks.2.1.se.gate\n",
      "blocks.2.1.conv_pwl\n",
      "blocks.2.1.bn3\n",
      "blocks.2.1.bn3.drop\n",
      "blocks.2.1.bn3.act\n",
      "blocks.2.1.drop_path\n",
      "blocks.2.2\n",
      "blocks.2.2.conv_pw\n",
      "blocks.2.2.bn1\n",
      "blocks.2.2.bn1.drop\n",
      "blocks.2.2.bn1.act\n",
      "blocks.2.2.conv_dw\n",
      "blocks.2.2.bn2\n",
      "blocks.2.2.bn2.drop\n",
      "blocks.2.2.bn2.act\n",
      "blocks.2.2.se\n",
      "blocks.2.2.se.conv_reduce\n",
      "blocks.2.2.se.act1\n",
      "blocks.2.2.se.conv_expand\n",
      "blocks.2.2.se.gate\n",
      "blocks.2.2.conv_pwl\n",
      "blocks.2.2.bn3\n",
      "blocks.2.2.bn3.drop\n",
      "blocks.2.2.bn3.act\n",
      "blocks.2.2.drop_path\n",
      "blocks.3\n",
      "blocks.3.0\n",
      "blocks.3.0.conv_pw\n",
      "blocks.3.0.bn1\n",
      "blocks.3.0.bn1.drop\n",
      "blocks.3.0.bn1.act\n",
      "blocks.3.0.conv_dw\n",
      "blocks.3.0.bn2\n",
      "blocks.3.0.bn2.drop\n",
      "blocks.3.0.bn2.act\n",
      "blocks.3.0.se\n",
      "blocks.3.0.conv_pwl\n",
      "blocks.3.0.bn3\n",
      "blocks.3.0.bn3.drop\n",
      "blocks.3.0.bn3.act\n",
      "blocks.3.0.drop_path\n",
      "blocks.3.1\n",
      "blocks.3.1.conv_pw\n",
      "blocks.3.1.bn1\n",
      "blocks.3.1.bn1.drop\n",
      "blocks.3.1.bn1.act\n",
      "blocks.3.1.conv_dw\n",
      "blocks.3.1.bn2\n",
      "blocks.3.1.bn2.drop\n",
      "blocks.3.1.bn2.act\n",
      "blocks.3.1.se\n",
      "blocks.3.1.conv_pwl\n",
      "blocks.3.1.bn3\n",
      "blocks.3.1.bn3.drop\n",
      "blocks.3.1.bn3.act\n",
      "blocks.3.1.drop_path\n",
      "blocks.3.2\n",
      "blocks.3.2.conv_pw\n",
      "blocks.3.2.bn1\n",
      "blocks.3.2.bn1.drop\n",
      "blocks.3.2.bn1.act\n",
      "blocks.3.2.conv_dw\n",
      "blocks.3.2.bn2\n",
      "blocks.3.2.bn2.drop\n",
      "blocks.3.2.bn2.act\n",
      "blocks.3.2.se\n",
      "blocks.3.2.conv_pwl\n",
      "blocks.3.2.bn3\n",
      "blocks.3.2.bn3.drop\n",
      "blocks.3.2.bn3.act\n",
      "blocks.3.2.drop_path\n",
      "blocks.3.3\n",
      "blocks.3.3.conv_pw\n",
      "blocks.3.3.bn1\n",
      "blocks.3.3.bn1.drop\n",
      "blocks.3.3.bn1.act\n",
      "blocks.3.3.conv_dw\n",
      "blocks.3.3.bn2\n",
      "blocks.3.3.bn2.drop\n",
      "blocks.3.3.bn2.act\n",
      "blocks.3.3.se\n",
      "blocks.3.3.conv_pwl\n",
      "blocks.3.3.bn3\n",
      "blocks.3.3.bn3.drop\n",
      "blocks.3.3.bn3.act\n",
      "blocks.3.3.drop_path\n",
      "blocks.4\n",
      "blocks.4.0\n",
      "blocks.4.0.conv_pw\n",
      "blocks.4.0.bn1\n",
      "blocks.4.0.bn1.drop\n",
      "blocks.4.0.bn1.act\n",
      "blocks.4.0.conv_dw\n",
      "blocks.4.0.bn2\n",
      "blocks.4.0.bn2.drop\n",
      "blocks.4.0.bn2.act\n",
      "blocks.4.0.se\n",
      "blocks.4.0.se.conv_reduce\n",
      "blocks.4.0.se.act1\n",
      "blocks.4.0.se.conv_expand\n",
      "blocks.4.0.se.gate\n",
      "blocks.4.0.conv_pwl\n",
      "blocks.4.0.bn3\n",
      "blocks.4.0.bn3.drop\n",
      "blocks.4.0.bn3.act\n",
      "blocks.4.0.drop_path\n",
      "blocks.4.1\n",
      "blocks.4.1.conv_pw\n",
      "blocks.4.1.bn1\n",
      "blocks.4.1.bn1.drop\n",
      "blocks.4.1.bn1.act\n",
      "blocks.4.1.conv_dw\n",
      "blocks.4.1.bn2\n",
      "blocks.4.1.bn2.drop\n",
      "blocks.4.1.bn2.act\n",
      "blocks.4.1.se\n",
      "blocks.4.1.se.conv_reduce\n",
      "blocks.4.1.se.act1\n",
      "blocks.4.1.se.conv_expand\n",
      "blocks.4.1.se.gate\n",
      "blocks.4.1.conv_pwl\n",
      "blocks.4.1.bn3\n",
      "blocks.4.1.bn3.drop\n",
      "blocks.4.1.bn3.act\n",
      "blocks.4.1.drop_path\n",
      "blocks.5\n",
      "blocks.5.0\n",
      "blocks.5.0.conv_pw\n",
      "blocks.5.0.bn1\n",
      "blocks.5.0.bn1.drop\n",
      "blocks.5.0.bn1.act\n",
      "blocks.5.0.conv_dw\n",
      "blocks.5.0.bn2\n",
      "blocks.5.0.bn2.drop\n",
      "blocks.5.0.bn2.act\n",
      "blocks.5.0.se\n",
      "blocks.5.0.se.conv_reduce\n",
      "blocks.5.0.se.act1\n",
      "blocks.5.0.se.conv_expand\n",
      "blocks.5.0.se.gate\n",
      "blocks.5.0.conv_pwl\n",
      "blocks.5.0.bn3\n",
      "blocks.5.0.bn3.drop\n",
      "blocks.5.0.bn3.act\n",
      "blocks.5.0.drop_path\n",
      "blocks.5.1\n",
      "blocks.5.1.conv_pw\n",
      "blocks.5.1.bn1\n",
      "blocks.5.1.bn1.drop\n",
      "blocks.5.1.bn1.act\n",
      "blocks.5.1.conv_dw\n",
      "blocks.5.1.bn2\n",
      "blocks.5.1.bn2.drop\n",
      "blocks.5.1.bn2.act\n",
      "blocks.5.1.se\n",
      "blocks.5.1.se.conv_reduce\n",
      "blocks.5.1.se.act1\n",
      "blocks.5.1.se.conv_expand\n",
      "blocks.5.1.se.gate\n",
      "blocks.5.1.conv_pwl\n",
      "blocks.5.1.bn3\n",
      "blocks.5.1.bn3.drop\n",
      "blocks.5.1.bn3.act\n",
      "blocks.5.1.drop_path\n",
      "blocks.5.2\n",
      "blocks.5.2.conv_pw\n",
      "blocks.5.2.bn1\n",
      "blocks.5.2.bn1.drop\n",
      "blocks.5.2.bn1.act\n",
      "blocks.5.2.conv_dw\n",
      "blocks.5.2.bn2\n",
      "blocks.5.2.bn2.drop\n",
      "blocks.5.2.bn2.act\n",
      "blocks.5.2.se\n",
      "blocks.5.2.se.conv_reduce\n",
      "blocks.5.2.se.act1\n",
      "blocks.5.2.se.conv_expand\n",
      "blocks.5.2.se.gate\n",
      "blocks.5.2.conv_pwl\n",
      "blocks.5.2.bn3\n",
      "blocks.5.2.bn3.drop\n",
      "blocks.5.2.bn3.act\n",
      "blocks.5.2.drop_path\n",
      "blocks.6\n",
      "blocks.6.0\n",
      "blocks.6.0.conv\n",
      "blocks.6.0.bn1\n",
      "blocks.6.0.bn1.drop\n",
      "blocks.6.0.bn1.act\n",
      "blocks.6.0.drop_path\n"
     ]
    }
   ],
   "source": [
    "# name of each layer\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Hardswish(),\n",
       " Sequential(\n",
       "   (0): Sequential(\n",
       "     (0): DepthwiseSeparableConv(\n",
       "       (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (1): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (2): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (2): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (3): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (2): InvertedResidual(\n",
       "       (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (3): InvertedResidual(\n",
       "       (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (4): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (2): InvertedResidual(\n",
       "       (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (6): Sequential(\n",
       "     (0): ConvBnAct(\n",
       "       (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = list(model.children())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(c[-1])):\n",
    "    print(len(c[-1][n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape of layer 0 : torch.Size([1, 16, 112, 112])\n",
      "output shape of layer 1 : torch.Size([1, 24, 56, 56])\n",
      "output shape of layer 2 : torch.Size([1, 40, 28, 28])\n",
      "output shape of layer 3 : torch.Size([1, 80, 14, 14])\n",
      "output shape of layer 4 : torch.Size([1, 112, 14, 14])\n",
      "output shape of layer 5 : torch.Size([1, 160, 7, 7])\n",
      "output shape of layer 6 : torch.Size([1, 960, 7, 7])\n",
      "{2: 0, 4: 1, 8: 2, 16: 4, 32: 6}\n"
     ]
    }
   ],
   "source": [
    "stride_to_layer = {}\n",
    "for n in range(len(c[-1])):\n",
    "    new_model = torch.nn.Sequential(*(c[:3] + list(c[3][: (n + 1)]))).to(\"cpu\")\n",
    "    input_data = torch.randn(1, 3, 224, 224).to(\"cpu\")\n",
    "    output = new_model(input_data)\n",
    "    print(f\"output shape of layer {n} : {output.shape}\")\n",
    "    stride = 224 // output.shape[-1]\n",
    "    stride_to_layer[stride] = n\n",
    "pprint.pprint(stride_to_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 16, 4: 24, 8: 40, 16: 112, 32: 960}\n"
     ]
    }
   ],
   "source": [
    "stride_to_dim = dict(zip(model.feature_info.reduction(), model.feature_info.channels()))\n",
    "pprint.pprint(stride_to_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting layers up to stride 8 from mobilenetv3_large_100...\n",
      "extracting layers up to stride 8 from mobilenetv3_large_100...\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "from models.model import ObjectCentroidDetection\n",
    "\n",
    "model_map = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv3_large_100\", half=False\n",
    ")\n",
    "model_half = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv3_large_100\", half=True\n",
    ")\n",
    "print(model_map(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(model_half(torch.randn(1, 3, 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 40, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 16, 112, 112]        432\n",
      "|    BatchNorm2d: 2-2                       [-1, 16, 112, 112]        32\n",
      "|    Hardswish: 2-3                         [-1, 16, 112, 112]        --\n",
      "|    Sequential: 2-4                        [-1, 16, 112, 112]        --\n",
      "|    |    DepthwiseSeparableConv: 3-1       [-1, 16, 112, 112]        464\n",
      "|    Sequential: 2-5                        [-1, 24, 56, 56]          --\n",
      "|    |    InvertedResidual: 3-2             [-1, 24, 56, 56]          3,440\n",
      "|    |    InvertedResidual: 3-3             [-1, 24, 56, 56]          4,440\n",
      "|    Sequential: 2-6                        [-1, 40, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-4             [-1, 40, 28, 28]          10,328\n",
      "|    |    InvertedResidual: 3-5             [-1, 40, 28, 28]          20,992\n",
      "|    |    InvertedResidual: 3-6             [-1, 40, 28, 28]          20,992\n",
      "Conv2d: 1-2                                 [-1, 1, 28, 28]           41\n",
      "===============================================================================================\n",
      "Total params: 61,161\n",
      "Trainable params: 61,161\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 71.85\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 24.12\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 24.93\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_map, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 40, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 16, 112, 112]        432\n",
      "|    BatchNorm2d: 2-2                       [-1, 16, 112, 112]        32\n",
      "|    Hardswish: 2-3                         [-1, 16, 112, 112]        --\n",
      "|    Sequential: 2-4                        [-1, 16, 112, 112]        --\n",
      "|    |    DepthwiseSeparableConv: 3-1       [-1, 16, 112, 112]        464\n",
      "|    Sequential: 2-5                        [-1, 24, 56, 56]          --\n",
      "|    |    InvertedResidual: 3-2             [-1, 24, 56, 56]          3,440\n",
      "|    |    InvertedResidual: 3-3             [-1, 24, 56, 56]          4,440\n",
      "|    Sequential: 2-6                        [-1, 40, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-4             [-1, 40, 28, 28]          10,328\n",
      "|    |    InvertedResidual: 3-5             [-1, 40, 28, 28]          20,992\n",
      "|    |    InvertedResidual: 3-6             [-1, 40, 28, 28]          20,992\n",
      "Sequential: 1-2                             [-1, 2]                   --\n",
      "|    AdaptiveAvgPool2d: 2-7                 [-1, 40, 1, 1]            --\n",
      "|    Flatten: 2-8                           [-1, 40]                  --\n",
      "|    Linear: 2-9                            [-1, 2]                   82\n",
      "===============================================================================================\n",
      "Total params: 61,202\n",
      "Trainable params: 61,202\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 71.82\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 24.12\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 24.92\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model_half, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timm mobilenetv3_small_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88e9dbc8ccf4da48675976028504e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/10.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 16, 56, 56])\n",
      "torch.Size([1, 24, 28, 28])\n",
      "torch.Size([1, 48, 14, 14])\n",
      "torch.Size([1, 576, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_small_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 16, 112, 112])\n",
    "    #  torch.Size([1, 24, 56, 56])\n",
    "    #  torch.Size([1, 40, 28, 28])\n",
    "    #  torch.Size([1, 112, 14, 14])\n",
    "    #  torch.Size([1, 960, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                 | 0.927M                 | 0.117G     |\\n'\n",
      " '|  conv_stem            |  0.432K                |  11.059M   |\\n'\n",
      " '|   conv_stem.weight    |   (16, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                  |  32                    |  0.819M    |\\n'\n",
      " '|   bn1.weight          |   (16,)                |            |\\n'\n",
      " '|   bn1.bias            |   (16,)                |            |\\n'\n",
      " '|  blocks               |  0.927M                |  0.105G    |\\n'\n",
      " '|   blocks.0.0          |   0.744K               |   2.97M    |\\n'\n",
      " '|    blocks.0.0.conv_dw |    0.144K              |    0.922M  |\\n'\n",
      " '|    blocks.0.0.bn1     |    32                  |    0.205M  |\\n'\n",
      " '|    blocks.0.0.se      |    0.28K               |    0.256K  |\\n'\n",
      " '|    blocks.0.0.conv_pw |    0.256K              |    1.638M  |\\n'\n",
      " '|    blocks.0.0.bn2     |    32                  |    0.205M  |\\n'\n",
      " '|   blocks.1            |   9.28K                |   21.069M  |\\n'\n",
      " '|    blocks.1.0         |    3.864K              |    12.403M |\\n'\n",
      " '|    blocks.1.1         |    5.416K              |    8.666M  |\\n'\n",
      " '|   blocks.2            |   0.128M               |   27.656M  |\\n'\n",
      " '|    blocks.2.0         |    13.736K             |    6.603M  |\\n'\n",
      " '|    blocks.2.1         |    57.264K             |    10.527M |\\n'\n",
      " '|    blocks.2.2         |    57.264K             |    10.527M |\\n'\n",
      " '|   blocks.3            |   51.768K              |   12.912M  |\\n'\n",
      " '|    blocks.3.0         |    21.968K             |    5.662M  |\\n'\n",
      " '|    blocks.3.1         |    29.8K               |    7.25M   |\\n'\n",
      " '|   blocks.4            |   0.68M                |   35.192M  |\\n'\n",
      " '|    blocks.4.0         |    91.848K             |    9.363M  |\\n'\n",
      " '|    blocks.4.1         |    0.294M              |    12.915M |\\n'\n",
      " '|    blocks.4.2         |    0.294M              |    12.915M |\\n'\n",
      " '|   blocks.5.0          |   56.448K              |   5.645M   |\\n'\n",
      " '|    blocks.5.0.conv    |    55.296K             |    5.53M   |\\n'\n",
      " '|    blocks.5.0.bn1     |    1.152K              |    0.115M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_small_100\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3Features(\n",
       "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): Hardswish()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv3_small_100\", pretrained=True, features_only=True\n",
    ")  # note that model structure is different from with or without features_only\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Conv2d: 1-1                                 [-1, 16, 112, 112]        432\n",
      "BatchNorm2d: 1-2                            [-1, 16, 112, 112]        32\n",
      "Hardswish: 1-3                              [-1, 16, 112, 112]        --\n",
      "Sequential: 1                               []                        --\n",
      "|    Sequential: 2-1                        [-1, 16, 56, 56]          --\n",
      "|    |    DepthwiseSeparableConv: 3-1       [-1, 16, 56, 56]          744\n",
      "|    Sequential: 2-2                        [-1, 24, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-2             [-1, 24, 28, 28]          3,864\n",
      "|    |    InvertedResidual: 3-3             [-1, 24, 28, 28]          5,416\n",
      "|    Sequential: 2-3                        [-1, 40, 14, 14]          --\n",
      "|    |    InvertedResidual: 3-4             [-1, 40, 14, 14]          13,736\n",
      "|    |    InvertedResidual: 3-5             [-1, 40, 14, 14]          57,264\n",
      "|    |    InvertedResidual: 3-6             [-1, 40, 14, 14]          57,264\n",
      "|    Sequential: 2-4                        [-1, 48, 14, 14]          --\n",
      "|    |    InvertedResidual: 3-7             [-1, 48, 14, 14]          21,968\n",
      "|    |    InvertedResidual: 3-8             [-1, 48, 14, 14]          29,800\n",
      "|    Sequential: 2-5                        [-1, 96, 7, 7]            --\n",
      "|    |    InvertedResidual: 3-9             [-1, 96, 7, 7]            91,848\n",
      "|    |    InvertedResidual: 3-10            [-1, 96, 7, 7]            294,096\n",
      "|    |    InvertedResidual: 3-11            [-1, 96, 7, 7]            294,096\n",
      "|    Sequential: 2-6                        [-1, 576, 7, 7]           --\n",
      "|    |    ConvBnAct: 3-12                   [-1, 576, 7, 7]           56,448\n",
      "===============================================================================================\n",
      "Total params: 927,008\n",
      "Trainable params: 927,008\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 56.74\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 12.31\n",
      "Params size (MB): 3.54\n",
      "Estimated Total Size (MB): 16.42\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv_stem\n",
      "bn1\n",
      "act1\n",
      "blocks\n",
      "blocks.0\n",
      "blocks.0.0\n",
      "blocks.0.0.conv_dw\n",
      "blocks.0.0.bn1\n",
      "blocks.0.0.bn1.drop\n",
      "blocks.0.0.bn1.act\n",
      "blocks.0.0.se\n",
      "blocks.0.0.se.conv_reduce\n",
      "blocks.0.0.se.act1\n",
      "blocks.0.0.se.conv_expand\n",
      "blocks.0.0.se.gate\n",
      "blocks.0.0.conv_pw\n",
      "blocks.0.0.bn2\n",
      "blocks.0.0.bn2.drop\n",
      "blocks.0.0.bn2.act\n",
      "blocks.0.0.drop_path\n",
      "blocks.1\n",
      "blocks.1.0\n",
      "blocks.1.0.conv_pw\n",
      "blocks.1.0.bn1\n",
      "blocks.1.0.bn1.drop\n",
      "blocks.1.0.bn1.act\n",
      "blocks.1.0.conv_dw\n",
      "blocks.1.0.bn2\n",
      "blocks.1.0.bn2.drop\n",
      "blocks.1.0.bn2.act\n",
      "blocks.1.0.se\n",
      "blocks.1.0.conv_pwl\n",
      "blocks.1.0.bn3\n",
      "blocks.1.0.bn3.drop\n",
      "blocks.1.0.bn3.act\n",
      "blocks.1.0.drop_path\n",
      "blocks.1.1\n",
      "blocks.1.1.conv_pw\n",
      "blocks.1.1.bn1\n",
      "blocks.1.1.bn1.drop\n",
      "blocks.1.1.bn1.act\n",
      "blocks.1.1.conv_dw\n",
      "blocks.1.1.bn2\n",
      "blocks.1.1.bn2.drop\n",
      "blocks.1.1.bn2.act\n",
      "blocks.1.1.se\n",
      "blocks.1.1.conv_pwl\n",
      "blocks.1.1.bn3\n",
      "blocks.1.1.bn3.drop\n",
      "blocks.1.1.bn3.act\n",
      "blocks.1.1.drop_path\n",
      "blocks.2\n",
      "blocks.2.0\n",
      "blocks.2.0.conv_pw\n",
      "blocks.2.0.bn1\n",
      "blocks.2.0.bn1.drop\n",
      "blocks.2.0.bn1.act\n",
      "blocks.2.0.conv_dw\n",
      "blocks.2.0.bn2\n",
      "blocks.2.0.bn2.drop\n",
      "blocks.2.0.bn2.act\n",
      "blocks.2.0.se\n",
      "blocks.2.0.se.conv_reduce\n",
      "blocks.2.0.se.act1\n",
      "blocks.2.0.se.conv_expand\n",
      "blocks.2.0.se.gate\n",
      "blocks.2.0.conv_pwl\n",
      "blocks.2.0.bn3\n",
      "blocks.2.0.bn3.drop\n",
      "blocks.2.0.bn3.act\n",
      "blocks.2.0.drop_path\n",
      "blocks.2.1\n",
      "blocks.2.1.conv_pw\n",
      "blocks.2.1.bn1\n",
      "blocks.2.1.bn1.drop\n",
      "blocks.2.1.bn1.act\n",
      "blocks.2.1.conv_dw\n",
      "blocks.2.1.bn2\n",
      "blocks.2.1.bn2.drop\n",
      "blocks.2.1.bn2.act\n",
      "blocks.2.1.se\n",
      "blocks.2.1.se.conv_reduce\n",
      "blocks.2.1.se.act1\n",
      "blocks.2.1.se.conv_expand\n",
      "blocks.2.1.se.gate\n",
      "blocks.2.1.conv_pwl\n",
      "blocks.2.1.bn3\n",
      "blocks.2.1.bn3.drop\n",
      "blocks.2.1.bn3.act\n",
      "blocks.2.1.drop_path\n",
      "blocks.2.2\n",
      "blocks.2.2.conv_pw\n",
      "blocks.2.2.bn1\n",
      "blocks.2.2.bn1.drop\n",
      "blocks.2.2.bn1.act\n",
      "blocks.2.2.conv_dw\n",
      "blocks.2.2.bn2\n",
      "blocks.2.2.bn2.drop\n",
      "blocks.2.2.bn2.act\n",
      "blocks.2.2.se\n",
      "blocks.2.2.se.conv_reduce\n",
      "blocks.2.2.se.act1\n",
      "blocks.2.2.se.conv_expand\n",
      "blocks.2.2.se.gate\n",
      "blocks.2.2.conv_pwl\n",
      "blocks.2.2.bn3\n",
      "blocks.2.2.bn3.drop\n",
      "blocks.2.2.bn3.act\n",
      "blocks.2.2.drop_path\n",
      "blocks.3\n",
      "blocks.3.0\n",
      "blocks.3.0.conv_pw\n",
      "blocks.3.0.bn1\n",
      "blocks.3.0.bn1.drop\n",
      "blocks.3.0.bn1.act\n",
      "blocks.3.0.conv_dw\n",
      "blocks.3.0.bn2\n",
      "blocks.3.0.bn2.drop\n",
      "blocks.3.0.bn2.act\n",
      "blocks.3.0.se\n",
      "blocks.3.0.se.conv_reduce\n",
      "blocks.3.0.se.act1\n",
      "blocks.3.0.se.conv_expand\n",
      "blocks.3.0.se.gate\n",
      "blocks.3.0.conv_pwl\n",
      "blocks.3.0.bn3\n",
      "blocks.3.0.bn3.drop\n",
      "blocks.3.0.bn3.act\n",
      "blocks.3.0.drop_path\n",
      "blocks.3.1\n",
      "blocks.3.1.conv_pw\n",
      "blocks.3.1.bn1\n",
      "blocks.3.1.bn1.drop\n",
      "blocks.3.1.bn1.act\n",
      "blocks.3.1.conv_dw\n",
      "blocks.3.1.bn2\n",
      "blocks.3.1.bn2.drop\n",
      "blocks.3.1.bn2.act\n",
      "blocks.3.1.se\n",
      "blocks.3.1.se.conv_reduce\n",
      "blocks.3.1.se.act1\n",
      "blocks.3.1.se.conv_expand\n",
      "blocks.3.1.se.gate\n",
      "blocks.3.1.conv_pwl\n",
      "blocks.3.1.bn3\n",
      "blocks.3.1.bn3.drop\n",
      "blocks.3.1.bn3.act\n",
      "blocks.3.1.drop_path\n",
      "blocks.4\n",
      "blocks.4.0\n",
      "blocks.4.0.conv_pw\n",
      "blocks.4.0.bn1\n",
      "blocks.4.0.bn1.drop\n",
      "blocks.4.0.bn1.act\n",
      "blocks.4.0.conv_dw\n",
      "blocks.4.0.bn2\n",
      "blocks.4.0.bn2.drop\n",
      "blocks.4.0.bn2.act\n",
      "blocks.4.0.se\n",
      "blocks.4.0.se.conv_reduce\n",
      "blocks.4.0.se.act1\n",
      "blocks.4.0.se.conv_expand\n",
      "blocks.4.0.se.gate\n",
      "blocks.4.0.conv_pwl\n",
      "blocks.4.0.bn3\n",
      "blocks.4.0.bn3.drop\n",
      "blocks.4.0.bn3.act\n",
      "blocks.4.0.drop_path\n",
      "blocks.4.1\n",
      "blocks.4.1.conv_pw\n",
      "blocks.4.1.bn1\n",
      "blocks.4.1.bn1.drop\n",
      "blocks.4.1.bn1.act\n",
      "blocks.4.1.conv_dw\n",
      "blocks.4.1.bn2\n",
      "blocks.4.1.bn2.drop\n",
      "blocks.4.1.bn2.act\n",
      "blocks.4.1.se\n",
      "blocks.4.1.se.conv_reduce\n",
      "blocks.4.1.se.act1\n",
      "blocks.4.1.se.conv_expand\n",
      "blocks.4.1.se.gate\n",
      "blocks.4.1.conv_pwl\n",
      "blocks.4.1.bn3\n",
      "blocks.4.1.bn3.drop\n",
      "blocks.4.1.bn3.act\n",
      "blocks.4.1.drop_path\n",
      "blocks.4.2\n",
      "blocks.4.2.conv_pw\n",
      "blocks.4.2.bn1\n",
      "blocks.4.2.bn1.drop\n",
      "blocks.4.2.bn1.act\n",
      "blocks.4.2.conv_dw\n",
      "blocks.4.2.bn2\n",
      "blocks.4.2.bn2.drop\n",
      "blocks.4.2.bn2.act\n",
      "blocks.4.2.se\n",
      "blocks.4.2.se.conv_reduce\n",
      "blocks.4.2.se.act1\n",
      "blocks.4.2.se.conv_expand\n",
      "blocks.4.2.se.gate\n",
      "blocks.4.2.conv_pwl\n",
      "blocks.4.2.bn3\n",
      "blocks.4.2.bn3.drop\n",
      "blocks.4.2.bn3.act\n",
      "blocks.4.2.drop_path\n",
      "blocks.5\n",
      "blocks.5.0\n",
      "blocks.5.0.conv\n",
      "blocks.5.0.bn1\n",
      "blocks.5.0.bn1.drop\n",
      "blocks.5.0.bn1.act\n",
      "blocks.5.0.drop_path\n"
     ]
    }
   ],
   "source": [
    "# name of each layer\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Hardswish(),\n",
       " Sequential(\n",
       "   (0): Sequential(\n",
       "     (0): DepthwiseSeparableConv(\n",
       "       (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (1): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv_dw): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): ReLU(inplace=True)\n",
       "       )\n",
       "       (se): Identity()\n",
       "       (conv_pwl): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (2): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (2): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (3): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (4): Sequential(\n",
       "     (0): InvertedResidual(\n",
       "       (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (1): InvertedResidual(\n",
       "       (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "     (2): InvertedResidual(\n",
       "       (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "       (bn2): BatchNormAct2d(\n",
       "         576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (se): SqueezeExcite(\n",
       "         (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (gate): Hardsigmoid()\n",
       "       )\n",
       "       (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNormAct2d(\n",
       "         96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Identity()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): ConvBnAct(\n",
       "       (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNormAct2d(\n",
       "         576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "         (drop): Identity()\n",
       "         (act): Hardswish()\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = list(model.children())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(c[-1])):\n",
    "    print(len(c[-1][n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape of layer 0 : torch.Size([1, 16, 56, 56])\n",
      "output shape of layer 1 : torch.Size([1, 24, 28, 28])\n",
      "output shape of layer 2 : torch.Size([1, 40, 14, 14])\n",
      "output shape of layer 3 : torch.Size([1, 48, 14, 14])\n",
      "output shape of layer 4 : torch.Size([1, 96, 7, 7])\n",
      "output shape of layer 5 : torch.Size([1, 576, 7, 7])\n",
      "{4: 0, 8: 1, 16: 3, 32: 5}\n"
     ]
    }
   ],
   "source": [
    "stride_to_layer = {}\n",
    "for n in range(len(c[-1])):\n",
    "    new_model = torch.nn.Sequential(*(c[:3] + list(c[3][: (n + 1)]))).to(\"cpu\")\n",
    "    input_data = torch.randn(1, 3, 224, 224).to(\"cpu\")\n",
    "    output = new_model(input_data)\n",
    "    print(f\"output shape of layer {n} : {output.shape}\")\n",
    "    stride = 224 // output.shape[-1]\n",
    "    stride_to_layer[stride] = n\n",
    "pprint.pprint(stride_to_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 16, 4: 16, 8: 24, 16: 48, 32: 576}\n"
     ]
    }
   ],
   "source": [
    "stride_to_dim = dict(zip(model.feature_info.reduction(), model.feature_info.channels()))\n",
    "pprint.pprint(stride_to_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting layers up to stride 8 from mobilenetv3_small_100...\n",
      "extracting layers up to stride 8 from mobilenetv3_small_100...\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "from models.model import ObjectCentroidDetection\n",
    "\n",
    "\n",
    "model_map = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv3_small_100\", half=False\n",
    ")\n",
    "model_half = ObjectCentroidDetection(\n",
    "    n_classes=1, stride=8, architecture=\"mobilenetv3_small_100\", half=True\n",
    ")\n",
    "print(model_map(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(model_half(torch.randn(1, 3, 224, 224)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 24, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 16, 112, 112]        432\n",
      "|    BatchNorm2d: 2-2                       [-1, 16, 112, 112]        32\n",
      "|    Hardswish: 2-3                         [-1, 16, 112, 112]        --\n",
      "|    Sequential: 2-4                        [-1, 16, 56, 56]          --\n",
      "|    |    DepthwiseSeparableConv: 3-1       [-1, 16, 56, 56]          744\n",
      "|    Sequential: 2-5                        [-1, 24, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-2             [-1, 24, 28, 28]          3,864\n",
      "|    |    InvertedResidual: 3-3             [-1, 24, 28, 28]          5,416\n",
      "Conv2d: 1-2                                 [-1, 1, 28, 28]           25\n",
      "===============================================================================================\n",
      "Total params: 10,513\n",
      "Trainable params: 10,513\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 16.13\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 7.33\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 7.94\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_map, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Sequential: 1-1                             [-1, 24, 28, 28]          --\n",
      "|    Conv2d: 2-1                            [-1, 16, 112, 112]        432\n",
      "|    BatchNorm2d: 2-2                       [-1, 16, 112, 112]        32\n",
      "|    Hardswish: 2-3                         [-1, 16, 112, 112]        --\n",
      "|    Sequential: 2-4                        [-1, 16, 56, 56]          --\n",
      "|    |    DepthwiseSeparableConv: 3-1       [-1, 16, 56, 56]          744\n",
      "|    Sequential: 2-5                        [-1, 24, 28, 28]          --\n",
      "|    |    InvertedResidual: 3-2             [-1, 24, 28, 28]          3,864\n",
      "|    |    InvertedResidual: 3-3             [-1, 24, 28, 28]          5,416\n",
      "Sequential: 1-2                             [-1, 2]                   --\n",
      "|    AdaptiveAvgPool2d: 2-6                 [-1, 24, 1, 1]            --\n",
      "|    Flatten: 2-7                           [-1, 24]                  --\n",
      "|    Linear: 2-8                            [-1, 2]                   50\n",
      "===============================================================================================\n",
      "Total params: 10,538\n",
      "Trainable params: 10,538\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 16.11\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 7.32\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 7.94\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model_half, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed Comparison between differnet model implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 16 16:10:33 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              66W / 300W |  11985MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              68W / 300W |   1352MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              74W / 300W |   4525MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              71W / 300W |   2494MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1549943      C   ...iconda3/envs/transformer/bin/python      722MiB |\n",
      "|    0   N/A  N/A   3040624      C   ...enxin/anaconda3/envs/ocd/bin/python      664MiB |\n",
      "|    0   N/A  N/A   3780832      C   ...iconda3/envs/transformer/bin/python      722MiB |\n",
      "|    0   N/A  N/A   3844304      C   ...iconda3/envs/transformer/bin/python     4176MiB |\n",
      "|    0   N/A  N/A   4054160      C   ...naconda3/envs/hyde_conda/bin/python     4516MiB |\n",
      "|    0   N/A  N/A   4162912      C   ...iconda3/envs/transformer/bin/python     1112MiB |\n",
      "|    1   N/A  N/A     37453      C   ...iconda3/envs/transformer/bin/python      664MiB |\n",
      "|    1   N/A  N/A   3780833      C   ...iconda3/envs/transformer/bin/python      664MiB |\n",
      "|    2   N/A  N/A    492946      C   ...iconda3/envs/transformer/bin/python     1142MiB |\n",
      "|    2   N/A  N/A   1549943      C   ...iconda3/envs/transformer/bin/python     1040MiB |\n",
      "|    2   N/A  N/A   3780832      C   ...iconda3/envs/transformer/bin/python      724MiB |\n",
      "|    2   N/A  N/A   3780833      C   ...iconda3/envs/transformer/bin/python      664MiB |\n",
      "|    2   N/A  N/A   4162912      C   ...iconda3/envs/transformer/bin/python      898MiB |\n",
      "|    3   N/A  N/A   3780833      C   ...iconda3/envs/transformer/bin/python      664MiB |\n",
      "|    3   N/A  N/A   4162912      C   ...iconda3/envs/transformer/bin/python     1804MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2CentroidMapTV(nn.Module):\n",
    "    \"\"\"modified from torchvision\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, n_classes=1, stride=8, weights=\"MobileNet_V2_Weights.IMAGENET1K_V2\"\n",
    "    ):\n",
    "        super(MobileNetV2CentroidMapTV, self).__init__()\n",
    "        self.nc = n_classes\n",
    "        self.weights = weights\n",
    "\n",
    "        # last layer number (0-indexed) of each stride\n",
    "        self.stride_to_layer = {2: 1, 4: 3, 8: 6, 16: 13, 32: 18}\n",
    "        self.stride = stride\n",
    "        n = self.stride_to_layer[self.stride]\n",
    "\n",
    "        # number of channels of each layer\n",
    "        self.layer_to_dim = {\n",
    "            0: 32,\n",
    "            1: 16,\n",
    "            2: 24,\n",
    "            3: 24,\n",
    "            4: 32,\n",
    "            5: 32,\n",
    "            6: 32,\n",
    "            7: 64,\n",
    "            8: 64,\n",
    "            9: 64,\n",
    "            10: 64,\n",
    "            11: 96,\n",
    "            12: 96,\n",
    "            13: 96,\n",
    "            14: 160,\n",
    "            15: 160,\n",
    "            16: 160,\n",
    "            17: 320,\n",
    "            18: 1280,\n",
    "        }\n",
    "\n",
    "        # load the first n layers of the pretrained mobilenet\n",
    "        feature_layers = models.mobilenet_v2(self.weights).features\n",
    "        self.features = torch.nn.Sequential(*list(feature_layers.children())[: n + 1])\n",
    "\n",
    "        self.classifier = nn.Conv2d(\n",
    "            in_channels=self.layer_to_dim[n],\n",
    "            out_channels=self.nc,\n",
    "            kernel_size=1,  # 1x1 conv as fc\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self._initialize_classifier()\n",
    "\n",
    "    def _initialize_classifier(self):\n",
    "        # weight initialization for the classifier layers\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2CentroidMap(nn.Module):\n",
    "    \"\"\"modified from timm\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes=1,\n",
    "        stride=8,\n",
    "        model_name=\"mobilenetv2_100\",\n",
    "    ):\n",
    "        super(MobileNetV2CentroidMap, self).__init__()\n",
    "        self.nc = n_classes\n",
    "\n",
    "        # last timm blocks layer number (0-indexed) of each stride\n",
    "        self.stride_to_layer = {2: 0, 4: 1, 8: 2, 16: 4, 32: 6}\n",
    "        self.stride = stride\n",
    "        n = self.stride_to_layer[self.stride]\n",
    "\n",
    "        # self.blocks_layer_to_dim = {\n",
    "        #     0: 16,\n",
    "        #     1: 24,\n",
    "        #     2: 32,\n",
    "        #     3: 64,\n",
    "        #     4: 96,\n",
    "        #     5: 160,\n",
    "        #     6: 320,\n",
    "        # }\n",
    "\n",
    "        # load the first n layers of the pretrained mobilenet\n",
    "        model = timm.create_model(model_name, pretrained=True, features_only=True)\n",
    "\n",
    "        c = list(model.children())\n",
    "        # first two layers (\"stem\" + \"bn1\") and first 3 layers of \"blocks\"\n",
    "        self.forward_features = nn.Sequential(*(c[:2] + list((c[2][: n + 1]))))\n",
    "\n",
    "        self.stride_to_dim = dict(\n",
    "            zip(model.feature_info.reduction(), model.feature_info.channels())\n",
    "        )\n",
    "        self.classifier = nn.Conv2d(\n",
    "            in_channels=self.stride_to_dim[self.stride],\n",
    "            out_channels=self.nc,\n",
    "            kernel_size=1,  # 1x1 conv as fc\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self._initialize_classifier()\n",
    "\n",
    "    def _initialize_classifier(self):\n",
    "        # weight initialization for the classifier layers\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2CentroidMap2(nn.Module):\n",
    "    \"\"\"\n",
    "    modified from timm.\n",
    "    use timm's out_indices to get the output,\n",
    "    slower than digging into the model's children like the previous implementations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes=1,\n",
    "        stride=8,\n",
    "        model_name=\"mobilenetv2_100\",\n",
    "    ):\n",
    "        super(MobileNetV2CentroidMap2, self).__init__()\n",
    "        self.nc = n_classes\n",
    "        self.stride = stride\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            model_name, pretrained=True, features_only=True, out_indices=(2,)\n",
    "        )\n",
    "        stride_to_channel = dict(\n",
    "            zip(self.model.feature_info.reduction(), self.model.feature_info.channels())\n",
    "        )\n",
    "        self.classifier = nn.Conv2d(\n",
    "            in_channels=stride_to_channel[self.stride],\n",
    "            out_channels=self.nc,\n",
    "            kernel_size=1,  # 1x1 conv as fc\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        # weight initialization for the classifier layers\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)[0]\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2CentroidMapTV().to(device)\n",
    "model_timm1 = MobileNetV2CentroidMap().to(device)\n",
    "model_timm2 = MobileNetV2CentroidMap2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "torch_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "torch_output = model(torch_input)\n",
    "print(torch_output.shape)\n",
    "torch_output = model_timm1(torch_input)\n",
    "print(torch_output.shape)\n",
    "torch_output = model_timm2(torch_input)\n",
    "print(torch_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_input = torch.randn(256, 3, 224, 224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision time: 7.288564205169678\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for _ in range(100):\n",
    "    torch_output = model(torch_input)\n",
    "print(f\"torchvision time: {time.time()-t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_timm1 time: 8.201338291168213\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for _ in range(100):\n",
    "    torch_output = model_timm1(torch_input)\n",
    "print(f\"model_timm1 time: {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_timm2 time: 11.666654825210571\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for _ in range(100):\n",
    "    torch_output = model_timm2(torch_input)\n",
    "print(f\"model_timm2 time: {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## mobilenetv4_conv_small.e2400_r224_in1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\"mobilenetv4_conv_small.e2400_r224_in1k\", pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 112, 112])\n",
      "torch.Size([1, 32, 56, 56])\n",
      "torch.Size([1, 64, 28, 28])\n",
      "torch.Size([1, 96, 14, 14])\n",
      "torch.Size([1, 960, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(\n",
    "    transforms(img).unsqueeze(0)\n",
    ")  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 960, 8, 8) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Conv2d: 1-1                                      [-1, 32, 112, 112]        864\n",
       "BatchNorm2d: 1-2                                 [-1, 32, 112, 112]        64\n",
       "ReLU: 1-3                                        [-1, 32, 112, 112]        --\n",
       "Sequential: 1                                    []                        --\n",
       "|    Sequential: 2-1                             [-1, 32, 56, 56]          --\n",
       "|    |    ConvBnAct: 3-1                         [-1, 32, 56, 56]          9,280\n",
       "|    |    ConvBnAct: 3-2                         [-1, 32, 56, 56]          1,088\n",
       "|    Sequential: 2-2                             [-1, 64, 28, 28]          --\n",
       "|    |    ConvBnAct: 3-3                         [-1, 96, 28, 28]          27,840\n",
       "|    |    ConvBnAct: 3-4                         [-1, 64, 28, 28]          6,272\n",
       "|    Sequential: 2-3                             [-1, 96, 14, 14]          --\n",
       "|    |    UniversalInvertedResidual: 3-5         [-1, 96, 14, 14]          38,208\n",
       "|    |    UniversalInvertedResidual: 3-6         [-1, 96, 14, 14]          39,552\n",
       "|    |    UniversalInvertedResidual: 3-7         [-1, 96, 14, 14]          39,552\n",
       "|    |    UniversalInvertedResidual: 3-8         [-1, 96, 14, 14]          39,552\n",
       "|    |    UniversalInvertedResidual: 3-9         [-1, 96, 14, 14]          39,552\n",
       "|    |    UniversalInvertedResidual: 3-10        [-1, 96, 14, 14]          75,744\n",
       "|    Sequential: 2-4                             [-1, 128, 7, 7]           --\n",
       "|    |    UniversalInvertedResidual: 3-11        [-1, 128, 7, 7]           137,824\n",
       "|    |    UniversalInvertedResidual: 3-12        [-1, 128, 7, 7]           149,632\n",
       "|    |    UniversalInvertedResidual: 3-13        [-1, 128, 7, 7]           146,176\n",
       "|    |    UniversalInvertedResidual: 3-14        [-1, 128, 7, 7]           109,696\n",
       "|    |    UniversalInvertedResidual: 3-15        [-1, 128, 7, 7]           137,984\n",
       "|    |    UniversalInvertedResidual: 3-16        [-1, 128, 7, 7]           137,984\n",
       "|    Sequential: 2-5                             [-1, 960, 7, 7]           --\n",
       "|    |    ConvBnAct: 3-17                        [-1, 960, 7, 7]           124,800\n",
       "====================================================================================================\n",
       "Total params: 1,261,664\n",
       "Trainable params: 1,261,664\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 79.05\n",
       "====================================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 8.97\n",
       "Params size (MB): 4.81\n",
       "Estimated Total Size (MB): 14.36\n",
       "===================================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "summary(model, (3, 224, 224), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fvcore summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 1.262M                 | 0.382G     |\\n'\n",
      " '|  conv_stem         |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight       |   (32,)                |            |\\n'\n",
      " '|   bn1.bias         |   (32,)                |            |\\n'\n",
      " '|  blocks            |  1.261M                |  0.359G    |\\n'\n",
      " '|   blocks.0         |   10.368K              |   66.355M  |\\n'\n",
      " '|    blocks.0.0      |    9.28K               |    59.392M |\\n'\n",
      " '|    blocks.0.1      |    1.088K              |    6.963M  |\\n'\n",
      " '|   blocks.1         |   34.112K              |   54.579M  |\\n'\n",
      " '|    blocks.1.0      |    27.84K              |    44.544M |\\n'\n",
      " '|    blocks.1.1      |    6.272K              |    10.035M |\\n'\n",
      " '|   blocks.2         |   0.272M               |   0.126G   |\\n'\n",
      " '|    blocks.2.0      |    38.208K             |    32.563M |\\n'\n",
      " '|    blocks.2.1      |    39.552K             |    15.821M |\\n'\n",
      " '|    blocks.2.2      |    39.552K             |    15.821M |\\n'\n",
      " '|    blocks.2.3      |    39.552K             |    15.821M |\\n'\n",
      " '|    blocks.2.4      |    39.552K             |    15.821M |\\n'\n",
      " '|    blocks.2.5      |    75.744K             |    30.298M |\\n'\n",
      " '|   blocks.3         |   0.819M               |   99.181M  |\\n'\n",
      " '|    blocks.3.0      |    0.138M              |    31.034M |\\n'\n",
      " '|    blocks.3.1      |    0.15M               |    14.963M |\\n'\n",
      " '|    blocks.3.2      |    0.146M              |    14.618M |\\n'\n",
      " '|    blocks.3.3      |    0.11M               |    10.97M  |\\n'\n",
      " '|    blocks.3.4      |    0.138M              |    13.798M |\\n'\n",
      " '|    blocks.3.5      |    0.138M              |    13.798M |\\n'\n",
      " '|   blocks.4.0       |   0.125M               |   12.48M   |\\n'\n",
      " '|    blocks.4.0.conv |    0.123M              |    12.288M |\\n'\n",
      " '|    blocks.4.0.bn1  |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| stages                | 1.222M                 | 0.367G     |\\n'\n",
      " '|  0.0                  |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.0.0               |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.0.0.weight       |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.0.1               |   64                   |   1.638M   |\\n'\n",
      " '|    0.0.1.weight       |    (32,)               |            |\\n'\n",
      " '|    0.0.1.bias         |    (32,)               |            |\\n'\n",
      " '|  1                    |  10.368K               |  66.355M   |\\n'\n",
      " '|   1.0                 |   9.28K                |   59.392M  |\\n'\n",
      " '|    1.0.0              |    9.216K              |    58.982M |\\n'\n",
      " '|    1.0.1              |    64                  |    0.41M   |\\n'\n",
      " '|   1.1                 |   1.088K               |   6.963M   |\\n'\n",
      " '|    1.1.0              |    1.024K              |    6.554M  |\\n'\n",
      " '|    1.1.1              |    64                  |    0.41M   |\\n'\n",
      " '|  2                    |  34.112K               |  54.579M   |\\n'\n",
      " '|   2.0                 |   27.84K               |   44.544M  |\\n'\n",
      " '|    2.0.0              |    27.648K             |    44.237M |\\n'\n",
      " '|    2.0.1              |    0.192K              |    0.307M  |\\n'\n",
      " '|   2.1                 |   6.272K               |   10.035M  |\\n'\n",
      " '|    2.1.0              |    6.144K              |    9.83M   |\\n'\n",
      " '|    2.1.1              |    0.128K              |    0.205M  |\\n'\n",
      " '|  3                    |  0.233M                |  0.11G     |\\n'\n",
      " '|   3.0                 |   38.208K              |   32.563M  |\\n'\n",
      " '|    3.0.start_dw_conv  |    1.728K              |    2.765M  |\\n'\n",
      " '|    3.0.expand_conv    |    12.672K             |    20.275M |\\n'\n",
      " '|    3.0.middle_dw_conv |    5.184K              |    2.074M  |\\n'\n",
      " '|    3.0.project_conv   |    18.624K             |    7.45M   |\\n'\n",
      " '|   3.1                 |   39.552K              |   15.821M  |\\n'\n",
      " '|    3.1.expand_conv    |    18.816K             |    7.526M  |\\n'\n",
      " '|    3.1.middle_dw_conv |    2.112K              |    0.845M  |\\n'\n",
      " '|    3.1.project_conv   |    18.624K             |    7.45M   |\\n'\n",
      " '|   3.2                 |   39.552K              |   15.821M  |\\n'\n",
      " '|    3.2.expand_conv    |    18.816K             |    7.526M  |\\n'\n",
      " '|    3.2.middle_dw_conv |    2.112K              |    0.845M  |\\n'\n",
      " '|    3.2.project_conv   |    18.624K             |    7.45M   |\\n'\n",
      " '|   3.3                 |   39.552K              |   15.821M  |\\n'\n",
      " '|    3.3.expand_conv    |    18.816K             |    7.526M  |\\n'\n",
      " '|    3.3.middle_dw_conv |    2.112K              |    0.845M  |\\n'\n",
      " '|    3.3.project_conv   |    18.624K             |    7.45M   |\\n'\n",
      " '|   3.4                 |   75.744K              |   30.298M  |\\n'\n",
      " '|    3.4.start_dw_conv  |    1.056K              |    0.422M  |\\n'\n",
      " '|    3.4.expand_conv    |    37.632K             |    15.053M |\\n'\n",
      " '|    3.4.project_conv   |    37.056K             |    14.822M |\\n'\n",
      " '|  4                    |  0.944M                |  0.112G    |\\n'\n",
      " '|   4.0                 |   0.138M               |   31.034M  |\\n'\n",
      " '|    4.0.start_dw_conv  |    1.056K              |    0.422M  |\\n'\n",
      " '|    4.0.expand_conv    |    56.448K             |    22.579M |\\n'\n",
      " '|    4.0.middle_dw_conv |    6.336K              |    0.634M  |\\n'\n",
      " '|    4.0.project_conv   |    73.984K             |    7.398M  |\\n'\n",
      " '|   4.1                 |   0.15M                |   14.963M  |\\n'\n",
      " '|    4.1.start_dw_conv  |    3.456K              |    0.346M  |\\n'\n",
      " '|    4.1.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.1.middle_dw_conv |    13.824K             |    1.382M  |\\n'\n",
      " '|    4.1.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.2                 |   0.146M               |   14.618M  |\\n'\n",
      " '|    4.2.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.2.middle_dw_conv |    13.824K             |    1.382M  |\\n'\n",
      " '|    4.2.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.3                 |   0.11M                |   10.97M   |\\n'\n",
      " '|    4.3.expand_conv    |    49.92K              |    4.992M  |\\n'\n",
      " '|    4.3.middle_dw_conv |    10.368K             |    1.037M  |\\n'\n",
      " '|    4.3.project_conv   |    49.408K             |    4.941M  |\\n'\n",
      " '|   4.4                 |   0.138M               |   13.798M  |\\n'\n",
      " '|    4.4.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.4.middle_dw_conv |    5.632K              |    0.563M  |\\n'\n",
      " '|    4.4.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.5                 |   0.138M               |   13.798M  |\\n'\n",
      " '|    4.5.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.5.middle_dw_conv |    5.632K              |    0.563M  |\\n'\n",
      " '|    4.5.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.6                 |   0.125M               |   12.48M   |\\n'\n",
      " '|    4.6.0              |    0.123M              |    12.288M |\\n'\n",
      " '|    4.6.1              |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from models.mobilenetv4 import MobileNetV4\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = MobileNetV4(arch=\"small\", n_classes=-1, width_multiplier=1.0)\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv4_conv_medium.e500_r256_in1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1547fe16d75c4a4daba9a99b60aededc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\"mobilenetv4_conv_medium.e500_r256_in1k\", pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 128, 128])\n",
      "torch.Size([1, 48, 64, 64])\n",
      "torch.Size([1, 80, 32, 32])\n",
      "torch.Size([1, 160, 16, 16])\n",
      "torch.Size([1, 960, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(\n",
    "    transforms(img).unsqueeze(0)\n",
    ")  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 960, 8, 8) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fvcore summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 7.203M                 | 1.708G     |\\n'\n",
      " '|  conv_stem             |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight     |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight           |   (32,)                |            |\\n'\n",
      " '|   bn1.bias             |   (32,)                |            |\\n'\n",
      " '|  blocks                |  7.202M                |  1.684G    |\\n'\n",
      " '|   blocks.0.0           |   43.36K               |   0.278G   |\\n'\n",
      " '|    blocks.0.0.conv_exp |    36.864K             |    0.236G  |\\n'\n",
      " '|    blocks.0.0.bn1      |    0.256K              |    1.638M  |\\n'\n",
      " '|    blocks.0.0.conv_pwl |    6.144K              |    39.322M |\\n'\n",
      " '|    blocks.0.0.bn2      |    96                  |    0.614M  |\\n'\n",
      " '|   blocks.1             |   59.552K              |   0.144G   |\\n'\n",
      " '|    blocks.1.0          |    30.832K             |    97.946M |\\n'\n",
      " '|    blocks.1.1          |    28.72K              |    45.952M |\\n'\n",
      " '|   blocks.2             |   1.521M               |   0.657G   |\\n'\n",
      " '|    blocks.2.0          |    0.13M               |    0.1G    |\\n'\n",
      " '|    blocks.2.1          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.2          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.3          |    0.225M              |    90.176M |\\n'\n",
      " '|    blocks.2.4          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.5          |    0.208M              |    83.264M |\\n'\n",
      " '|    blocks.2.6          |    0.103M              |    41.344M |\\n'\n",
      " '|    blocks.2.7          |    0.208M              |    83.264M |\\n'\n",
      " '|   blocks.3             |   5.331M               |   0.581G   |\\n'\n",
      " '|    blocks.3.0          |    0.432M              |    91.155M |\\n'\n",
      " '|    blocks.3.1          |    0.561M              |    56.141M |\\n'\n",
      " '|    blocks.3.2          |    0.557M              |    55.731M |\\n'\n",
      " '|    blocks.3.3          |    0.557M              |    55.731M |\\n'\n",
      " '|    blocks.3.4          |    0.527M              |    52.685M |\\n'\n",
      " '|    blocks.3.5          |    0.53M               |    52.966M |\\n'\n",
      " '|    blocks.3.6          |    0.28M               |    28.032M |\\n'\n",
      " '|    blocks.3.7          |    0.561M              |    56.141M |\\n'\n",
      " '|    blocks.3.8          |    0.527M              |    52.685M |\\n'\n",
      " '|    blocks.3.9          |    0.527M              |    52.685M |\\n'\n",
      " '|    blocks.3.10         |    0.271M              |    27.059M |\\n'\n",
      " '|   blocks.4.0           |   0.248M               |   24.768M  |\\n'\n",
      " '|    blocks.4.0.conv     |    0.246M              |    24.576M |\\n'\n",
      " '|    blocks.4.0.bn1      |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| stages                | 6.371M                 | 1.369G     |\\n'\n",
      " '|  0.0                  |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.0.0               |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.0.0.weight       |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.0.1               |   64                   |   1.638M   |\\n'\n",
      " '|    0.0.1.weight       |    (32,)               |            |\\n'\n",
      " '|    0.0.1.bias         |    (32,)               |            |\\n'\n",
      " '|  1                    |  10.368K               |  66.355M   |\\n'\n",
      " '|   1.0                 |   9.28K                |   59.392M  |\\n'\n",
      " '|    1.0.0              |    9.216K              |    58.982M |\\n'\n",
      " '|    1.0.1              |    64                  |    0.41M   |\\n'\n",
      " '|   1.1                 |   1.088K               |   6.963M   |\\n'\n",
      " '|    1.1.0              |    1.024K              |    6.554M  |\\n'\n",
      " '|    1.1.1              |    64                  |    0.41M   |\\n'\n",
      " '|  2                    |  47.28K                |  98.227M   |\\n'\n",
      " '|   2.0                 |   18.56K               |   52.275M  |\\n'\n",
      " '|    2.0.start_dw_conv  |    0.352K              |    2.253M  |\\n'\n",
      " '|    2.0.expand_conv    |    4.352K              |    27.853M |\\n'\n",
      " '|    2.0.middle_dw_conv |    3.456K              |    5.53M   |\\n'\n",
      " '|    2.0.project_conv   |    10.4K               |    16.64M  |\\n'\n",
      " '|   2.1                 |   28.72K               |   45.952M  |\\n'\n",
      " '|    2.1.start_dw_conv  |    0.88K               |    1.408M  |\\n'\n",
      " '|    2.1.expand_conv    |    13.12K              |    20.992M |\\n'\n",
      " '|    2.1.middle_dw_conv |    1.76K               |    2.816M  |\\n'\n",
      " '|    2.1.project_conv   |    12.96K              |    20.736M |\\n'\n",
      " '|  3                    |  1.51M                 |  0.652G    |\\n'\n",
      " '|   3.0                 |   0.13M                |   0.1G     |\\n'\n",
      " '|    3.0.start_dw_conv  |    0.88K               |    1.408M  |\\n'\n",
      " '|    3.0.expand_conv    |    39.36K              |    62.976M |\\n'\n",
      " '|    3.0.middle_dw_conv |    12.96K              |    5.184M  |\\n'\n",
      " '|    3.0.project_conv   |    77.12K              |    30.848M |\\n'\n",
      " '|   3.1                 |   0.215M               |   86.08M   |\\n'\n",
      " '|    3.1.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.1.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.1.middle_dw_conv |    7.04K               |    2.816M  |\\n'\n",
      " '|    3.1.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.2                 |   0.215M               |   86.08M   |\\n'\n",
      " '|    3.2.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.2.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.2.middle_dw_conv |    7.04K               |    2.816M  |\\n'\n",
      " '|    3.2.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.3                 |   0.206M               |   82.56M   |\\n'\n",
      " '|    3.3.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.3.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.4                 |   0.225M               |   90.176M  |\\n'\n",
      " '|    3.4.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.4.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.4.middle_dw_conv |    17.28K              |    6.912M  |\\n'\n",
      " '|    3.4.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.5                 |   0.206M               |   82.56M   |\\n'\n",
      " '|    3.5.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.5.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.6                 |   0.103M               |   41.344M  |\\n'\n",
      " '|    3.6.expand_conv    |    51.84K              |    20.736M |\\n'\n",
      " '|    3.6.project_conv   |    51.52K              |    20.608M |\\n'\n",
      " '|   3.7                 |   0.208M               |   83.264M  |\\n'\n",
      " '|    3.7.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.7.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.7.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|  4                    |  4.802M                |  0.528G    |\\n'\n",
      " '|   4.0                 |   0.432M               |   91.155M  |\\n'\n",
      " '|    4.0.start_dw_conv  |    4.32K               |    1.728M  |\\n'\n",
      " '|    4.0.expand_conv    |    0.156M              |    62.208M |\\n'\n",
      " '|    4.0.middle_dw_conv |    25.92K              |    2.592M  |\\n'\n",
      " '|    4.0.project_conv   |    0.246M              |    24.627M |\\n'\n",
      " '|   4.1                 |   0.561M               |   56.141M  |\\n'\n",
      " '|    4.1.start_dw_conv  |    6.912K              |    0.691M  |\\n'\n",
      " '|    4.1.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.1.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.1.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.2                 |   0.557M               |   55.731M  |\\n'\n",
      " '|    4.2.start_dw_conv  |    2.816K              |    0.282M  |\\n'\n",
      " '|    4.2.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.2.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.2.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.3                 |   0.557M               |   55.731M  |\\n'\n",
      " '|    4.3.start_dw_conv  |    2.816K              |    0.282M  |\\n'\n",
      " '|    4.3.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.3.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.3.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.4                 |   0.527M               |   52.685M  |\\n'\n",
      " '|    4.4.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.4.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.5                 |   0.53M                |   52.966M  |\\n'\n",
      " '|    4.5.start_dw_conv  |    2.816K              |    0.282M  |\\n'\n",
      " '|    4.5.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.5.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.6                 |   0.557M               |   55.731M  |\\n'\n",
      " '|    4.6.start_dw_conv  |    2.816K              |    0.282M  |\\n'\n",
      " '|    4.6.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.6.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.6.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.7                 |   0.561M               |   56.141M  |\\n'\n",
      " '|    4.7.start_dw_conv  |    6.912K              |    0.691M  |\\n'\n",
      " '|    4.7.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.7.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.7.project_conv   |    0.263M              |    26.266M |\\n'\n",
      " '|   4.8                 |   0.271M               |   27.059M  |\\n'\n",
      " '|    4.8.start_dw_conv  |    6.912K              |    0.691M  |\\n'\n",
      " '|    4.8.expand_conv    |    0.132M              |    13.21M  |\\n'\n",
      " '|    4.8.project_conv   |    0.132M              |    13.158M |\\n'\n",
      " '|   4.9                 |   0.248M               |   24.768M  |\\n'\n",
      " '|    4.9.0              |    0.246M              |    24.576M |\\n'\n",
      " '|    4.9.1              |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from models.mobilenetv4 import MobileNetV4\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = MobileNetV4(arch=\"medium\", n_classes=-1, width_multiplier=1.0)\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv4_medium_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n",
      "Feature map 1 shape: torch.Size([1, 32, 112, 112])\n",
      "Feature map 2 shape: torch.Size([1, 32, 56, 56])\n",
      "Feature map 3 shape: torch.Size([1, 80, 28, 28])\n",
      "Feature map 4 shape: torch.Size([1, 160, 14, 14])\n",
      "Feature map 5 shape: torch.Size([1, 448, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from models.mobilenetv4 import MobileNetV4\n",
    "\n",
    "model = MobileNetV4(arch=\"medium_seg\", n_classes=1000, width_multiplier=1.0)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # Example input\n",
    "output = model(input_tensor)\n",
    "print(output.shape)\n",
    "\n",
    "features = model.forward_features(input_tensor)\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"Feature map {i + 1} shape: {feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------|:-----------------------|:-----------|\\n'\n",
      " '| stages                | 3.12M                  | 1.016G     |\\n'\n",
      " '|  0.0                  |  0.928K                |  23.757M   |\\n'\n",
      " '|   0.0.0               |   0.864K               |   22.118M  |\\n'\n",
      " '|    0.0.0.weight       |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   0.0.1               |   64                   |   1.638M   |\\n'\n",
      " '|    0.0.1.weight       |    (32,)               |            |\\n'\n",
      " '|    0.0.1.bias         |    (32,)               |            |\\n'\n",
      " '|  1                    |  10.368K               |  66.355M   |\\n'\n",
      " '|   1.0                 |   9.28K                |   59.392M  |\\n'\n",
      " '|    1.0.0              |    9.216K              |    58.982M |\\n'\n",
      " '|    1.0.1              |    64                  |    0.41M   |\\n'\n",
      " '|   1.1                 |   1.088K               |   6.963M   |\\n'\n",
      " '|    1.1.0              |    1.024K              |    6.554M  |\\n'\n",
      " '|    1.1.1              |    64                  |    0.41M   |\\n'\n",
      " '|  2                    |  47.28K                |  98.227M   |\\n'\n",
      " '|   2.0                 |   18.56K               |   52.275M  |\\n'\n",
      " '|    2.0.start_dw_conv  |    0.352K              |    2.253M  |\\n'\n",
      " '|    2.0.expand_conv    |    4.352K              |    27.853M |\\n'\n",
      " '|    2.0.middle_dw_conv |    3.456K              |    5.53M   |\\n'\n",
      " '|    2.0.project_conv   |    10.4K               |    16.64M  |\\n'\n",
      " '|   2.1                 |   28.72K               |   45.952M  |\\n'\n",
      " '|    2.1.start_dw_conv  |    0.88K               |    1.408M  |\\n'\n",
      " '|    2.1.expand_conv    |    13.12K              |    20.992M |\\n'\n",
      " '|    2.1.middle_dw_conv |    1.76K               |    2.816M  |\\n'\n",
      " '|    2.1.project_conv   |    12.96K              |    20.736M |\\n'\n",
      " '|  3                    |  1.418M                |  0.615G    |\\n'\n",
      " '|   3.0                 |   0.13M                |   0.1G     |\\n'\n",
      " '|    3.0.start_dw_conv  |    0.88K               |    1.408M  |\\n'\n",
      " '|    3.0.expand_conv    |    39.36K              |    62.976M |\\n'\n",
      " '|    3.0.middle_dw_conv |    12.96K              |    5.184M  |\\n'\n",
      " '|    3.0.project_conv   |    77.12K              |    30.848M |\\n'\n",
      " '|   3.1                 |   0.215M               |   86.08M   |\\n'\n",
      " '|    3.1.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.1.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.1.middle_dw_conv |    7.04K               |    2.816M  |\\n'\n",
      " '|    3.1.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.2                 |   0.215M               |   86.08M   |\\n'\n",
      " '|    3.2.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.2.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.2.middle_dw_conv |    7.04K               |    2.816M  |\\n'\n",
      " '|    3.2.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.3                 |   0.225M               |   90.176M  |\\n'\n",
      " '|    3.3.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.3.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.3.middle_dw_conv |    17.28K              |    6.912M  |\\n'\n",
      " '|    3.3.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.4                 |   0.215M               |   86.08M   |\\n'\n",
      " '|    3.4.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.4.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.4.middle_dw_conv |    7.04K               |    2.816M  |\\n'\n",
      " '|    3.4.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.5                 |   0.208M               |   83.264M  |\\n'\n",
      " '|    3.5.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.5.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.5.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|   3.6                 |   0.208M               |   83.264M  |\\n'\n",
      " '|    3.6.start_dw_conv  |    1.76K               |    0.704M  |\\n'\n",
      " '|    3.6.expand_conv    |    0.104M              |    41.472M |\\n'\n",
      " '|    3.6.project_conv   |    0.103M              |    41.088M |\\n'\n",
      " '|  4                    |  1.643M                |  0.212G    |\\n'\n",
      " '|   4.0                 |   0.432M               |   91.155M  |\\n'\n",
      " '|    4.0.start_dw_conv  |    4.32K               |    1.728M  |\\n'\n",
      " '|    4.0.expand_conv    |    0.156M              |    62.208M |\\n'\n",
      " '|    4.0.middle_dw_conv |    25.92K              |    2.592M  |\\n'\n",
      " '|    4.0.project_conv   |    0.246M              |    24.627M |\\n'\n",
      " '|   4.1                 |   0.43M                |   43.008M  |\\n'\n",
      " '|    4.1.start_dw_conv  |    6.912K              |    0.691M  |\\n'\n",
      " '|    4.1.expand_conv    |    0.264M              |    26.419M |\\n'\n",
      " '|    4.1.middle_dw_conv |    27.648K             |    2.765M  |\\n'\n",
      " '|    4.1.project_conv   |    0.131M              |    13.133M |\\n'\n",
      " '|   4.2                 |   0.148M               |   14.758M  |\\n'\n",
      " '|    4.2.start_dw_conv  |    1.408K              |    0.141M  |\\n'\n",
      " '|    4.2.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.2.middle_dw_conv |    13.824K             |    1.382M  |\\n'\n",
      " '|    4.2.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.3                 |   0.148M               |   14.758M  |\\n'\n",
      " '|    4.3.start_dw_conv  |    1.408K              |    0.141M  |\\n'\n",
      " '|    4.3.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.3.middle_dw_conv |    13.824K             |    1.382M  |\\n'\n",
      " '|    4.3.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.4                 |   0.134M               |   13.376M  |\\n'\n",
      " '|    4.4.start_dw_conv  |    1.408K              |    0.141M  |\\n'\n",
      " '|    4.4.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.4.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.5                 |   74.624K              |   7.462M   |\\n'\n",
      " '|    4.5.start_dw_conv  |    1.408K              |    0.141M  |\\n'\n",
      " '|    4.5.expand_conv    |    33.28K              |    3.328M  |\\n'\n",
      " '|    4.5.middle_dw_conv |    6.912K              |    0.691M  |\\n'\n",
      " '|    4.5.project_conv   |    33.024K             |    3.302M  |\\n'\n",
      " '|   4.6                 |   0.15M                |   14.963M  |\\n'\n",
      " '|    4.6.start_dw_conv  |    3.456K              |    0.346M  |\\n'\n",
      " '|    4.6.expand_conv    |    66.56K              |    6.656M  |\\n'\n",
      " '|    4.6.middle_dw_conv |    13.824K             |    1.382M  |\\n'\n",
      " '|    4.6.project_conv   |    65.792K             |    6.579M  |\\n'\n",
      " '|   4.7                 |   69.76K               |   6.976M   |\\n'\n",
      " '|    4.7.start_dw_conv  |    3.456K              |    0.346M  |\\n'\n",
      " '|    4.7.expand_conv    |    33.28K              |    3.328M  |\\n'\n",
      " '|    4.7.project_conv   |    33.024K             |    3.302M  |\\n'\n",
      " '|   4.8                 |   58.24K               |   5.824M   |\\n'\n",
      " '|    4.8.0              |    57.344K             |    5.734M  |\\n'\n",
      " '|    4.8.1              |    0.896K              |    89.6K   |')\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from models.mobilenetv4 import MobileNetV4\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = MobileNetV4(arch=\"medium_seg\", n_classes=-1, width_multiplier=1.0)\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv4_conv_large.e500_r256_in1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\"mobilenetv4_conv_large.e500_r256_in1k\", pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 128, 128])\n",
      "torch.Size([1, 48, 64, 64])\n",
      "torch.Size([1, 96, 32, 32])\n",
      "torch.Size([1, 192, 16, 16])\n",
      "torch.Size([1, 960, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(\n",
    "    transforms(img).unsqueeze(0)\n",
    ")  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 960, 8, 8) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Conv2d: 1-1                                      [-1, 24, 160, 160]        648\n",
       "BatchNormAct2d: 1-2                              [-1, 24, 160, 160]        --\n",
       "|    Identity: 2-1                               [-1, 24, 160, 160]        --\n",
       "|    ReLU: 2-2                                   [-1, 24, 160, 160]        --\n",
       "Sequential: 1-3                                  [-1, 960, 10, 10]         --\n",
       "|    Sequential: 2-3                             [-1, 48, 80, 80]          --\n",
       "|    |    EdgeResidual: 3-1                      [-1, 48, 80, 80]          25,632\n",
       "|    Sequential: 2-4                             [-1, 96, 40, 40]          --\n",
       "|    |    UniversalInvertedResidual: 3-2         [-1, 96, 40, 40]          33,936\n",
       "|    |    UniversalInvertedResidual: 3-3         [-1, 96, 40, 40]          79,968\n",
       "|    Sequential: 2-5                             [-1, 192, 20, 20]         --\n",
       "|    |    UniversalInvertedResidual: 3-4         [-1, 192, 20, 20]         123,168\n",
       "|    |    UniversalInvertedResidual: 3-5         [-1, 192, 20, 20]         307,392\n",
       "|    |    UniversalInvertedResidual: 3-6         [-1, 192, 20, 20]         307,392\n",
       "|    |    UniversalInvertedResidual: 3-7         [-1, 192, 20, 20]         307,392\n",
       "|    |    UniversalInvertedResidual: 3-8         [-1, 192, 20, 20]         319,680\n",
       "|    |    UniversalInvertedResidual: 3-9         [-1, 192, 20, 20]         310,464\n",
       "|    |    UniversalInvertedResidual: 3-10        [-1, 192, 20, 20]         310,464\n",
       "|    |    UniversalInvertedResidual: 3-11        [-1, 192, 20, 20]         310,464\n",
       "|    |    UniversalInvertedResidual: 3-12        [-1, 192, 20, 20]         310,464\n",
       "|    |    UniversalInvertedResidual: 3-13        [-1, 192, 20, 20]         310,464\n",
       "|    |    UniversalInvertedResidual: 3-14        [-1, 192, 20, 20]         298,944\n",
       "|    Sequential: 2-6                             [-1, 512, 10, 10]         --\n",
       "|    |    UniversalInvertedResidual: 3-15        [-1, 512, 10, 10]         569,152\n",
       "|    |    UniversalInvertedResidual: 3-16        [-1, 512, 10, 10]         2,171,392\n",
       "|    |    UniversalInvertedResidual: 3-17        [-1, 512, 10, 10]         2,171,392\n",
       "|    |    UniversalInvertedResidual: 3-18        [-1, 512, 10, 10]         2,171,392\n",
       "|    |    UniversalInvertedResidual: 3-19        [-1, 512, 10, 10]         2,116,096\n",
       "|    |    UniversalInvertedResidual: 3-20        [-1, 512, 10, 10]         2,138,624\n",
       "|    |    UniversalInvertedResidual: 3-21        [-1, 512, 10, 10]         2,116,096\n",
       "|    |    UniversalInvertedResidual: 3-22        [-1, 512, 10, 10]         2,116,096\n",
       "|    |    UniversalInvertedResidual: 3-23        [-1, 512, 10, 10]         2,138,624\n",
       "|    |    UniversalInvertedResidual: 3-24        [-1, 512, 10, 10]         2,171,392\n",
       "|    |    UniversalInvertedResidual: 3-25        [-1, 512, 10, 10]         2,116,096\n",
       "|    |    UniversalInvertedResidual: 3-26        [-1, 512, 10, 10]         2,116,096\n",
       "|    |    UniversalInvertedResidual: 3-27        [-1, 512, 10, 10]         2,116,096\n",
       "|    Sequential: 2-7                             [-1, 960, 10, 10]         --\n",
       "|    |    ConvBnAct: 3-28                        [-1, 960, 10, 10]         493,440\n",
       "SelectAdaptivePool2d: 1-4                        [-1, 960, 1, 1]           --\n",
       "|    AdaptiveAvgPool2d: 2-8                      [-1, 960, 1, 1]           --\n",
       "|    Identity: 2-9                               [-1, 960, 1, 1]           --\n",
       "Conv2d: 1-5                                      [-1, 1280, 1, 1]          1,228,800\n",
       "BatchNormAct2d: 1-6                              [-1, 1280, 1, 1]          --\n",
       "|    Identity: 2-10                              [-1, 1280, 1, 1]          --\n",
       "|    ReLU: 2-11                                  [-1, 1280, 1, 1]          --\n",
       "Identity: 1-7                                    [-1, 1280, 1, 1]          --\n",
       "Flatten: 1-8                                     [-1, 1280]                --\n",
       "Linear: 1-9                                      [-1, 1000]                1,281,000\n",
       "====================================================================================================\n",
       "Total params: 32,588,256\n",
       "Trainable params: 32,588,256\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 349.95\n",
       "====================================================================================================\n",
       "Input size (MB): 1.17\n",
       "Forward/backward pass size (MB): 12.47\n",
       "Params size (MB): 124.31\n",
       "Estimated Total Size (MB): 137.95\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\"mobilenetv4_conv_large.e500_r256_in1k\", pretrained=True)\n",
    "model = model.eval()\n",
    "summary(model, (3, 320, 320), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fvcore summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 30.079M                | 4.464G     |\\n'\n",
      " '|  conv_stem             |  0.648K                |  16.589M   |\\n'\n",
      " '|   conv_stem.weight     |   (24, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  48                    |  1.229M    |\\n'\n",
      " '|   bn1.weight           |   (24,)                |            |\\n'\n",
      " '|   bn1.bias             |   (24,)                |            |\\n'\n",
      " '|  blocks                |  30.078M               |  4.446G    |\\n'\n",
      " '|   blocks.0.0           |   25.632K              |   0.164G   |\\n'\n",
      " '|    blocks.0.0.conv_exp |    20.736K             |    0.133G  |\\n'\n",
      " '|    blocks.0.0.bn1      |    0.192K              |    1.229M  |\\n'\n",
      " '|    blocks.0.0.conv_pwl |    4.608K              |    29.491M |\\n'\n",
      " '|    blocks.0.0.bn2      |    96                  |    0.614M  |\\n'\n",
      " '|   blocks.1             |   0.114M               |   0.231G   |\\n'\n",
      " '|    blocks.1.0          |    33.936K             |    0.103G  |\\n'\n",
      " '|    blocks.1.1          |    79.968K             |    0.128G  |\\n'\n",
      " '|   blocks.2             |   3.216M               |   1.333G   |\\n'\n",
      " '|    blocks.2.0          |    0.123M              |    95.693M |\\n'\n",
      " '|    blocks.2.1          |    0.307M              |    0.123G  |\\n'\n",
      " '|    blocks.2.2          |    0.307M              |    0.123G  |\\n'\n",
      " '|    blocks.2.3          |    0.307M              |    0.123G  |\\n'\n",
      " '|    blocks.2.4          |    0.32M               |    0.128G  |\\n'\n",
      " '|    blocks.2.5          |    0.31M               |    0.124G  |\\n'\n",
      " '|    blocks.2.6          |    0.31M               |    0.124G  |\\n'\n",
      " '|    blocks.2.7          |    0.31M               |    0.124G  |\\n'\n",
      " '|    blocks.2.8          |    0.31M               |    0.124G  |\\n'\n",
      " '|    blocks.2.9          |    0.31M               |    0.124G  |\\n'\n",
      " '|    blocks.2.10         |    0.299M              |    0.12G   |\\n'\n",
      " '|   blocks.3             |   26.229M              |   2.669G   |\\n'\n",
      " '|    blocks.3.0          |    0.569M              |    0.103G  |\\n'\n",
      " '|    blocks.3.1          |    2.171M              |    0.217G  |\\n'\n",
      " '|    blocks.3.2          |    2.171M              |    0.217G  |\\n'\n",
      " '|    blocks.3.3          |    2.171M              |    0.217G  |\\n'\n",
      " '|    blocks.3.4          |    2.116M              |    0.212G  |\\n'\n",
      " '|    blocks.3.5          |    2.139M              |    0.214G  |\\n'\n",
      " '|    blocks.3.6          |    2.116M              |    0.212G  |\\n'\n",
      " '|    blocks.3.7          |    2.116M              |    0.212G  |\\n'\n",
      " '|    blocks.3.8          |    2.139M              |    0.214G  |\\n'\n",
      " '|    blocks.3.9          |    2.171M              |    0.217G  |\\n'\n",
      " '|    blocks.3.10         |    2.116M              |    0.212G  |\\n'\n",
      " '|    blocks.3.11         |    2.116M              |    0.212G  |\\n'\n",
      " '|    blocks.3.12         |    2.116M              |    0.212G  |\\n'\n",
      " '|   blocks.4.0           |   0.493M               |   49.344M  |\\n'\n",
      " '|    blocks.4.0.conv     |    0.492M              |    49.152M |\\n'\n",
      " '|    blocks.4.0.bn1      |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_conv_large.e500_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenetv4_hybrid_medium.ix_e550_r256_in1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_hybrid_medium.ix_e550_r256_in1k\", pretrained=True\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 128, 128])\n",
      "torch.Size([1, 48, 64, 64])\n",
      "torch.Size([1, 80, 32, 32])\n",
      "torch.Size([1, 160, 16, 16])\n",
      "torch.Size([1, 960, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_hybrid_medium.ix_e550_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 32, 128, 128])\n",
    "    #  torch.Size([1, 48, 64, 64])\n",
    "    #  torch.Size([1, 80, 32, 32])\n",
    "    #  torch.Size([1, 160, 16, 16])\n",
    "    #  torch.Size([1, 960, 8, 8])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_hybrid_medium.ix_e550_r256_in1k\",\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(\n",
    "    transforms(img).unsqueeze(0)\n",
    ")  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 960, 8, 8) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Conv2d: 1-1                                      [-1, 32, 160, 160]        864\n",
       "BatchNormAct2d: 1-2                              [-1, 32, 160, 160]        --\n",
       "|    Identity: 2-1                               [-1, 32, 160, 160]        --\n",
       "|    ReLU: 2-2                                   [-1, 32, 160, 160]        --\n",
       "Sequential: 1-3                                  [-1, 960, 10, 10]         --\n",
       "|    Sequential: 2-3                             [-1, 48, 80, 80]          --\n",
       "|    |    EdgeResidual: 3-1                      [-1, 48, 80, 80]          43,360\n",
       "|    Sequential: 2-4                             [-1, 80, 40, 40]          --\n",
       "|    |    UniversalInvertedResidual: 3-2         [-1, 80, 40, 40]          30,912\n",
       "|    |    UniversalInvertedResidual: 3-3         [-1, 80, 40, 40]          28,800\n",
       "|    Sequential: 2-5                             [-1, 160, 20, 20]         --\n",
       "|    |    UniversalInvertedResidual: 3-4         [-1, 160, 20, 20]         130,480\n",
       "|    |    UniversalInvertedResidual: 3-5         [-1, 160, 20, 20]         103,520\n",
       "|    |    UniversalInvertedResidual: 3-6         [-1, 160, 20, 20]         215,360\n",
       "|    |    UniversalInvertedResidual: 3-7         [-1, 160, 20, 20]         225,600\n",
       "|    |    MobileAttention: 3-8                   [-1, 160, 20, 20]         106,400\n",
       "|    |    UniversalInvertedResidual: 3-9         [-1, 160, 20, 20]         215,360\n",
       "|    |    MobileAttention: 3-10                  [-1, 160, 20, 20]         106,400\n",
       "|    |    UniversalInvertedResidual: 3-11        [-1, 160, 20, 20]         208,320\n",
       "|    |    MobileAttention: 3-12                  [-1, 160, 20, 20]         106,400\n",
       "|    |    UniversalInvertedResidual: 3-13        [-1, 160, 20, 20]         215,360\n",
       "|    |    MobileAttention: 3-14                  [-1, 160, 20, 20]         106,400\n",
       "|    |    UniversalInvertedResidual: 3-15        [-1, 160, 20, 20]         208,320\n",
       "|    Sequential: 2-6                             [-1, 256, 10, 10]         --\n",
       "|    |    UniversalInvertedResidual: 3-16        [-1, 256, 10, 10]         432,288\n",
       "|    |    UniversalInvertedResidual: 3-17        [-1, 256, 10, 10]         561,664\n",
       "|    |    UniversalInvertedResidual: 3-18        [-1, 256, 10, 10]         557,568\n",
       "|    |    UniversalInvertedResidual: 3-19        [-1, 256, 10, 10]         557,568\n",
       "|    |    UniversalInvertedResidual: 3-20        [-1, 256, 10, 10]         263,936\n",
       "|    |    UniversalInvertedResidual: 3-21        [-1, 256, 10, 10]         280,576\n",
       "|    |    UniversalInvertedResidual: 3-22        [-1, 256, 10, 10]         263,936\n",
       "|    |    UniversalInvertedResidual: 3-23        [-1, 256, 10, 10]         527,104\n",
       "|    |    MobileAttention: 3-24                  [-1, 256, 10, 10]         164,608\n",
       "|    |    UniversalInvertedResidual: 3-25        [-1, 256, 10, 10]         529,920\n",
       "|    |    MobileAttention: 3-26                  [-1, 256, 10, 10]         164,608\n",
       "|    |    UniversalInvertedResidual: 3-27        [-1, 256, 10, 10]         561,664\n",
       "|    |    MobileAttention: 3-28                  [-1, 256, 10, 10]         164,608\n",
       "|    |    UniversalInvertedResidual: 3-29        [-1, 256, 10, 10]         534,016\n",
       "|    |    MobileAttention: 3-30                  [-1, 256, 10, 10]         164,608\n",
       "|    |    UniversalInvertedResidual: 3-31        [-1, 256, 10, 10]         534,016\n",
       "|    Sequential: 2-7                             [-1, 960, 10, 10]         --\n",
       "|    |    ConvBnAct: 3-32                        [-1, 960, 10, 10]         247,680\n",
       "SelectAdaptivePool2d: 1-4                        [-1, 960, 1, 1]           --\n",
       "|    AdaptiveAvgPool2d: 2-8                      [-1, 960, 1, 1]           --\n",
       "|    Identity: 2-9                               [-1, 960, 1, 1]           --\n",
       "Conv2d: 1-5                                      [-1, 1280, 1, 1]          1,228,800\n",
       "BatchNormAct2d: 1-6                              [-1, 1280, 1, 1]          --\n",
       "|    Identity: 2-10                              [-1, 1280, 1, 1]          --\n",
       "|    ReLU: 2-11                                  [-1, 1280, 1, 1]          --\n",
       "Identity: 1-7                                    [-1, 1280, 1, 1]          --\n",
       "Flatten: 1-8                                     [-1, 1280]                --\n",
       "Linear: 1-9                                      [-1, 1000]                1,281,000\n",
       "====================================================================================================\n",
       "Total params: 11,072,024\n",
       "Trainable params: 11,072,024\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 358.24\n",
       "====================================================================================================\n",
       "Input size (MB): 1.17\n",
       "Forward/backward pass size (MB): 26.53\n",
       "Params size (MB): 42.24\n",
       "Estimated Total Size (MB): 69.94\n",
       "===================================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_hybrid_medium.ix_e550_r256_in1k\", pretrained=True\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "summary(model, (3, 320, 320), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fvcore summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4e7f4dd1e84e3f828f865c1ad50a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 8.562M                 | 1.942G     |\\n'\n",
      " '|  conv_stem             |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight     |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight           |   (32,)                |            |\\n'\n",
      " '|   bn1.bias             |   (32,)                |            |\\n'\n",
      " '|  blocks                |  8.561M                |  1.918G    |\\n'\n",
      " '|   blocks.0.0           |   43.36K               |   0.278G   |\\n'\n",
      " '|    blocks.0.0.conv_exp |    36.864K             |    0.236G  |\\n'\n",
      " '|    blocks.0.0.bn1      |    0.256K              |    1.638M  |\\n'\n",
      " '|    blocks.0.0.conv_pwl |    6.144K              |    39.322M |\\n'\n",
      " '|    blocks.0.0.bn2      |    96                  |    0.614M  |\\n'\n",
      " '|   blocks.1             |   59.712K              |   0.144G   |\\n'\n",
      " '|    blocks.1.0          |    30.912K             |    97.946M |\\n'\n",
      " '|    blocks.1.1          |    28.8K               |    45.952M |\\n'\n",
      " '|   blocks.2             |   1.948M               |   0.798G   |\\n'\n",
      " '|    blocks.2.0          |    0.13M               |    0.1G    |\\n'\n",
      " '|    blocks.2.1          |    0.104M              |    41.344M |\\n'\n",
      " '|    blocks.2.2          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.3          |    0.226M              |    90.176M |\\n'\n",
      " '|    blocks.2.4          |    0.106M              |    35.296M |\\n'\n",
      " '|    blocks.2.5          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.6          |    0.106M              |    35.296M |\\n'\n",
      " '|    blocks.2.7          |    0.208M              |    83.264M |\\n'\n",
      " '|    blocks.2.8          |    0.106M              |    35.296M |\\n'\n",
      " '|    blocks.2.9          |    0.215M              |    86.08M  |\\n'\n",
      " '|    blocks.2.10         |    0.106M              |    35.296M |\\n'\n",
      " '|    blocks.2.11         |    0.208M              |    83.264M |\\n'\n",
      " '|   blocks.3             |   6.263M               |   0.674G   |\\n'\n",
      " '|    blocks.3.0          |    0.432M              |    91.155M |\\n'\n",
      " '|    blocks.3.1          |    0.562M              |    56.141M |\\n'\n",
      " '|    blocks.3.2          |    0.558M              |    55.731M |\\n'\n",
      " '|    blocks.3.3          |    0.558M              |    55.731M |\\n'\n",
      " '|    blocks.3.4          |    0.264M              |    26.368M |\\n'\n",
      " '|    blocks.3.5          |    0.281M              |    28.032M |\\n'\n",
      " '|    blocks.3.6          |    0.264M              |    26.368M |\\n'\n",
      " '|    blocks.3.7          |    0.527M              |    52.685M |\\n'\n",
      " '|    blocks.3.8          |    0.165M              |    16.435M |\\n'\n",
      " '|    blocks.3.9          |    0.53M               |    52.966M |\\n'\n",
      " '|    blocks.3.10         |    0.165M              |    16.435M |\\n'\n",
      " '|    blocks.3.11         |    0.562M              |    56.141M |\\n'\n",
      " '|    blocks.3.12         |    0.165M              |    16.435M |\\n'\n",
      " '|    blocks.3.13         |    0.534M              |    53.376M |\\n'\n",
      " '|    blocks.3.14         |    0.165M              |    16.435M |\\n'\n",
      " '|    blocks.3.15         |    0.534M              |    53.376M |\\n'\n",
      " '|   blocks.4.0           |   0.248M               |   24.768M  |\\n'\n",
      " '|    blocks.4.0.conv     |    0.246M              |    24.576M |\\n'\n",
      " '|    blocks.4.0.bn1      |    1.92K               |    0.192M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobilenetv4_hybrid_medium\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efficientvit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064faa8624e4494789e51ae0ea9d4df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/97.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 64, 64])\n",
      "torch.Size([1, 96, 32, 32])\n",
      "torch.Size([1, 192, 16, 16])\n",
      "torch.Size([1, 384, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientvit_b2.r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 48, 64, 64])\n",
    "    #  torch.Size([1, 96, 32, 32])\n",
    "    #  torch.Size([1, 192, 16, 16])\n",
    "    #  torch.Size([1, 384, 8, 8])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                        | 14.977M                | 3.164G     |\\n'\n",
      " '|  stem_in_conv                                |  0.696K                |  17.818M   |\\n'\n",
      " '|   stem_in_conv.conv                          |   0.648K               |   16.589M  |\\n'\n",
      " '|    stem_in_conv.conv.weight                  |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   stem_in_conv.norm                          |   48                   |   1.229M   |\\n'\n",
      " '|    stem_in_conv.norm.weight                  |    (24,)               |            |\\n'\n",
      " '|    stem_in_conv.norm.bias                    |    (24,)               |            |\\n'\n",
      " '|  stem_res0.main                              |  0.888K                |  22.733M   |\\n'\n",
      " '|   stem_res0.main.depth_conv                  |   0.264K               |   6.758M   |\\n'\n",
      " '|    stem_res0.main.depth_conv.conv            |    0.216K              |    5.53M   |\\n'\n",
      " '|    stem_res0.main.depth_conv.norm            |    48                  |    1.229M  |\\n'\n",
      " '|   stem_res0.main.point_conv                  |   0.624K               |   15.974M  |\\n'\n",
      " '|    stem_res0.main.point_conv.conv            |    0.576K              |    14.746M |\\n'\n",
      " '|    stem_res0.main.point_conv.norm            |    48                  |    1.229M  |\\n'\n",
      " '|  stages_0.blocks                             |  50.304K               |  0.37G     |\\n'\n",
      " '|   stages_0.blocks.0.main                     |   8.256K               |   0.101G   |\\n'\n",
      " '|    stages_0.blocks.0.main.inverted_conv      |    2.496K              |    63.898M |\\n'\n",
      " '|    stages_0.blocks.0.main.depth_conv         |    1.056K              |    6.758M  |\\n'\n",
      " '|    stages_0.blocks.0.main.point_conv         |    4.704K              |    30.106M |\\n'\n",
      " '|   stages_0.blocks.1.main                     |   21.024K              |   0.135G   |\\n'\n",
      " '|    stages_0.blocks.1.main.inverted_conv      |    9.6K                |    61.44M  |\\n'\n",
      " '|    stages_0.blocks.1.main.depth_conv         |    2.112K              |    13.517M |\\n'\n",
      " '|    stages_0.blocks.1.main.point_conv         |    9.312K              |    59.597M |\\n'\n",
      " '|   stages_0.blocks.2.main                     |   21.024K              |   0.135G   |\\n'\n",
      " '|    stages_0.blocks.2.main.inverted_conv      |    9.6K                |    61.44M  |\\n'\n",
      " '|    stages_0.blocks.2.main.depth_conv         |    2.112K              |    13.517M |\\n'\n",
      " '|    stages_0.blocks.2.main.point_conv         |    9.312K              |    59.597M |\\n'\n",
      " '|  stages_1.blocks                             |  0.267M                |  0.473G    |\\n'\n",
      " '|   stages_1.blocks.0.main                     |   30.336K              |   94.618M  |\\n'\n",
      " '|    stages_1.blocks.0.main.inverted_conv      |    9.6K                |    61.44M  |\\n'\n",
      " '|    stages_1.blocks.0.main.depth_conv         |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.blocks.0.main.point_conv         |    18.624K             |    29.798M |\\n'\n",
      " '|   stages_1.blocks.1.main                     |   78.912K              |   0.126G   |\\n'\n",
      " '|    stages_1.blocks.1.main.inverted_conv      |    37.632K             |    60.211M |\\n'\n",
      " '|    stages_1.blocks.1.main.depth_conv         |    4.224K              |    6.758M  |\\n'\n",
      " '|    stages_1.blocks.1.main.point_conv         |    37.056K             |    59.29M  |\\n'\n",
      " '|   stages_1.blocks.2.main                     |   78.912K              |   0.126G   |\\n'\n",
      " '|    stages_1.blocks.2.main.inverted_conv      |    37.632K             |    60.211M |\\n'\n",
      " '|    stages_1.blocks.2.main.depth_conv         |    4.224K              |    6.758M  |\\n'\n",
      " '|    stages_1.blocks.2.main.point_conv         |    37.056K             |    59.29M  |\\n'\n",
      " '|   stages_1.blocks.3.main                     |   78.912K              |   0.126G   |\\n'\n",
      " '|    stages_1.blocks.3.main.inverted_conv      |    37.632K             |    60.211M |\\n'\n",
      " '|    stages_1.blocks.3.main.depth_conv         |    4.224K              |    6.758M  |\\n'\n",
      " '|    stages_1.blocks.3.main.point_conv         |    37.056K             |    59.29M  |\\n'\n",
      " '|  stages_2.blocks                             |  2.2M                  |  0.962G    |\\n'\n",
      " '|   stages_2.blocks.0.main                     |   0.115M               |   90.01M   |\\n'\n",
      " '|    stages_2.blocks.0.main.inverted_conv.conv |    37.248K             |    58.982M |\\n'\n",
      " '|    stages_2.blocks.0.main.depth_conv.conv    |    3.84K               |    1.382M  |\\n'\n",
      " '|    stages_2.blocks.0.main.point_conv         |    74.112K             |    29.645M |\\n'\n",
      " '|   stages_2.blocks.1                          |   0.521M               |   0.218G   |\\n'\n",
      " '|    stages_2.blocks.1.context_module.main     |    0.218M              |    97.152M |\\n'\n",
      " '|    stages_2.blocks.1.local_module.main       |    0.304M              |    0.121G  |\\n'\n",
      " '|   stages_2.blocks.2                          |   0.521M               |   0.218G   |\\n'\n",
      " '|    stages_2.blocks.2.context_module.main     |    0.218M              |    97.152M |\\n'\n",
      " '|    stages_2.blocks.2.local_module.main       |    0.304M              |    0.121G  |\\n'\n",
      " '|   stages_2.blocks.3                          |   0.521M               |   0.218G   |\\n'\n",
      " '|    stages_2.blocks.3.context_module.main     |    0.218M              |    97.152M |\\n'\n",
      " '|    stages_2.blocks.3.local_module.main       |    0.304M              |    0.121G  |\\n'\n",
      " '|   stages_2.blocks.4                          |   0.521M               |   0.218G   |\\n'\n",
      " '|    stages_2.blocks.4.context_module.main     |    0.218M              |    97.152M |\\n'\n",
      " '|    stages_2.blocks.4.local_module.main       |    0.304M              |    0.121G  |\\n'\n",
      " '|  stages_3.blocks                             |  12.458M               |  1.318G    |\\n'\n",
      " '|   stages_3.blocks.0.main                     |   0.452M               |   89.242M  |\\n'\n",
      " '|    stages_3.blocks.0.main.inverted_conv.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    stages_3.blocks.0.main.depth_conv.conv    |    7.68K               |    0.691M  |\\n'\n",
      " '|    stages_3.blocks.0.main.point_conv         |    0.296M              |    29.568M |\\n'\n",
      " '|   stages_3.blocks.1                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.1.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.1.local_module.main       |    1.197M              |    0.119G  |\\n'\n",
      " '|   stages_3.blocks.2                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.2.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.2.local_module.main       |    1.197M              |    0.119G  |\\n'\n",
      " '|   stages_3.blocks.3                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.3.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.3.local_module.main       |    1.197M              |    0.119G  |\\n'\n",
      " '|   stages_3.blocks.4                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.4.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.4.local_module.main       |    1.197M              |    0.119G  |\\n'\n",
      " '|   stages_3.blocks.5                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.5.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.5.local_module.main       |    1.197M              |    0.119G  |\\n'\n",
      " '|   stages_3.blocks.6                          |   2.001M               |   0.205G   |\\n'\n",
      " '|    stages_3.blocks.6.context_module.main     |    0.804M              |    85.44M  |\\n'\n",
      " '|    stages_3.blocks.6.local_module.main       |    1.197M              |    0.119G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientvit_b2.r256_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nextvit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c6845e963341efa20778d1a6483b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/127M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"nextvit_small.bd_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 96, 56, 56])\n",
    "    #  torch.Size([1, 256, 28, 28])\n",
    "    #  torch.Size([1, 512, 14, 14])\n",
    "    #  torch.Size([1, 1024, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 30.736M                | 11.788G    |\\n'\n",
      " '|  stem_0                          |  1.856K                |  47.514M   |\\n'\n",
      " '|   stem_0.conv                    |   1.728K               |   44.237M  |\\n'\n",
      " '|    stem_0.conv.weight            |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   stem_0.norm                    |   0.128K               |   3.277M   |\\n'\n",
      " '|    stem_0.norm.weight            |    (64,)               |            |\\n'\n",
      " '|    stem_0.norm.bias              |    (64,)               |            |\\n'\n",
      " '|  stem_1                          |  18.496K               |  0.473G    |\\n'\n",
      " '|   stem_1.conv                    |   18.432K              |   0.472G   |\\n'\n",
      " '|    stem_1.conv.weight            |    (32, 64, 3, 3)      |            |\\n'\n",
      " '|   stem_1.norm                    |   64                   |   1.638M   |\\n'\n",
      " '|    stem_1.norm.weight            |    (32,)               |            |\\n'\n",
      " '|    stem_1.norm.bias              |    (32,)               |            |\\n'\n",
      " '|  stem_2                          |  18.56K                |  0.475G    |\\n'\n",
      " '|   stem_2.conv                    |   18.432K              |   0.472G   |\\n'\n",
      " '|    stem_2.conv.weight            |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   stem_2.norm                    |   0.128K               |   3.277M   |\\n'\n",
      " '|    stem_2.norm.weight            |    (64,)               |            |\\n'\n",
      " '|    stem_2.norm.bias              |    (64,)               |            |\\n'\n",
      " '|  stem_3                          |  36.992K               |  0.237G    |\\n'\n",
      " '|   stem_3.conv                    |   36.864K              |   0.236G   |\\n'\n",
      " '|    stem_3.conv.weight            |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   stem_3.norm                    |   0.128K               |   0.819M   |\\n'\n",
      " '|    stem_3.norm.weight            |    (64,)               |            |\\n'\n",
      " '|    stem_3.norm.bias              |    (64,)               |            |\\n'\n",
      " '|  stages_0.blocks                 |  0.285M                |  1.817G    |\\n'\n",
      " '|   stages_0.blocks.0              |   99.264K              |   0.633G   |\\n'\n",
      " '|    stages_0.blocks.0.patch_embed |    6.336K              |    40.55M  |\\n'\n",
      " '|    stages_0.blocks.0.mhca        |    37.056K             |    0.237G  |\\n'\n",
      " '|    stages_0.blocks.0.norm        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.blocks.0.mlp         |    55.68K              |    0.354G  |\\n'\n",
      " '|   stages_0.blocks.1              |   92.928K              |   0.592G   |\\n'\n",
      " '|    stages_0.blocks.1.mhca        |    37.056K             |    0.237G  |\\n'\n",
      " '|    stages_0.blocks.1.norm        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.blocks.1.mlp         |    55.68K              |    0.354G  |\\n'\n",
      " '|   stages_0.blocks.2              |   92.928K              |   0.592G   |\\n'\n",
      " '|    stages_0.blocks.2.mhca        |    37.056K             |    0.237G  |\\n'\n",
      " '|    stages_0.blocks.2.norm        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.blocks.2.mlp         |    55.68K              |    0.354G  |\\n'\n",
      " '|  stages_1.blocks                 |  1.411M                |  2.14G     |\\n'\n",
      " '|   stages_1.blocks.0              |   0.334M               |   0.533G   |\\n'\n",
      " '|    stages_1.blocks.0.patch_embed |    18.816K             |    30.106M |\\n'\n",
      " '|    stages_1.blocks.0.mhca        |    92.544K             |    0.148G  |\\n'\n",
      " '|    stages_1.blocks.0.norm        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.blocks.0.mlp         |    0.222M              |    0.354G  |\\n'\n",
      " '|   stages_1.blocks.1              |   0.315M               |   0.503G   |\\n'\n",
      " '|    stages_1.blocks.1.mhca        |    92.544K             |    0.148G  |\\n'\n",
      " '|    stages_1.blocks.1.norm        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.blocks.1.mlp         |    0.222M              |    0.354G  |\\n'\n",
      " '|   stages_1.blocks.2              |   0.315M               |   0.503G   |\\n'\n",
      " '|    stages_1.blocks.2.mhca        |    92.544K             |    0.148G  |\\n'\n",
      " '|    stages_1.blocks.2.norm        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.blocks.2.mlp         |    0.222M              |    0.354G  |\\n'\n",
      " '|   stages_1.blocks.3              |   0.447M               |   0.602G   |\\n'\n",
      " '|    stages_1.blocks.3.norm1       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.blocks.3.e_mhsa      |    0.149M              |    0.125G  |\\n'\n",
      " '|    stages_1.blocks.3.projection  |    12.416K             |    19.866M |\\n'\n",
      " '|    stages_1.blocks.3.mhca        |    22.656K             |    36.25M  |\\n'\n",
      " '|    stages_1.blocks.3.norm2       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.blocks.3.mlp         |    0.263M              |    0.419G  |\\n'\n",
      " '|  stages_2.blocks                 |  12.957M               |  4.998G    |\\n'\n",
      " '|   stages_2.blocks.0              |   1.245M               |   0.497G   |\\n'\n",
      " '|    stages_2.blocks.0.patch_embed |    99.072K             |    39.629M |\\n'\n",
      " '|    stages_2.blocks.0.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.0.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.0.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.1              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.1.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.1.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.1.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.2              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.2.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.2.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.2.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.3              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.3.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.3.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.3.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.4              |   1.747M               |   0.609G   |\\n'\n",
      " '|    stages_2.blocks.4.norm1       |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.4.e_mhsa      |    0.592M              |    0.148G  |\\n'\n",
      " '|    stages_2.blocks.4.projection  |    49.408K             |    19.763M |\\n'\n",
      " '|    stages_2.blocks.4.mhca        |    53.504K             |    21.402M |\\n'\n",
      " '|    stages_2.blocks.4.norm2       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.blocks.4.mlp         |    1.05M               |    0.419G  |\\n'\n",
      " '|   stages_2.blocks.5              |   1.343M               |   0.537G   |\\n'\n",
      " '|    stages_2.blocks.5.patch_embed |    0.197M              |    78.95M  |\\n'\n",
      " '|    stages_2.blocks.5.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.5.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.5.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.6              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.6.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.6.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.6.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.7              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.7.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.7.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.7.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.8              |   1.146M               |   0.458G   |\\n'\n",
      " '|    stages_2.blocks.8.mhca        |    0.259M              |    0.104G  |\\n'\n",
      " '|    stages_2.blocks.8.norm        |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.8.mlp         |    0.886M              |    0.354G  |\\n'\n",
      " '|   stages_2.blocks.9              |   1.747M               |   0.609G   |\\n'\n",
      " '|    stages_2.blocks.9.norm1       |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.blocks.9.e_mhsa      |    0.592M              |    0.148G  |\\n'\n",
      " '|    stages_2.blocks.9.projection  |    49.408K             |    19.763M |\\n'\n",
      " '|    stages_2.blocks.9.mhca        |    53.504K             |    21.402M |\\n'\n",
      " '|    stages_2.blocks.9.norm2       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.blocks.9.mlp         |    1.05M               |    0.419G  |\\n'\n",
      " '|  stages_3.blocks                 |  16.007M               |  1.599G    |\\n'\n",
      " '|   stages_3.blocks.0              |   4.751M               |   0.475G   |\\n'\n",
      " '|    stages_3.blocks.0.patch_embed |    0.395M              |    39.475M |\\n'\n",
      " '|    stages_3.blocks.0.mhca        |    0.813M              |    81.254M |\\n'\n",
      " '|    stages_3.blocks.0.norm        |    1.536K              |    0.154M  |\\n'\n",
      " '|    stages_3.blocks.0.mlp         |    3.542M              |    0.354G  |\\n'\n",
      " '|   stages_3.blocks.1              |   4.356M               |   0.435G   |\\n'\n",
      " '|    stages_3.blocks.1.mhca        |    0.813M              |    81.254M |\\n'\n",
      " '|    stages_3.blocks.1.norm        |    1.536K              |    0.154M  |\\n'\n",
      " '|    stages_3.blocks.1.mlp         |    3.542M              |    0.354G  |\\n'\n",
      " '|   stages_3.blocks.2              |   6.9M                 |   0.689G   |\\n'\n",
      " '|    stages_3.blocks.2.norm1       |    1.536K              |    0.154M  |\\n'\n",
      " '|    stages_3.blocks.2.e_mhsa      |    2.362M              |    0.236G  |\\n'\n",
      " '|    stages_3.blocks.2.projection  |    0.197M              |    19.712M |\\n'\n",
      " '|    stages_3.blocks.2.mhca        |    0.14M               |    13.978M |\\n'\n",
      " '|    stages_3.blocks.2.norm2       |    2.048K              |    0.205M  |\\n'\n",
      " '|    stages_3.blocks.2.mlp         |    4.197M              |    0.419G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"nextvit_small.bd_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastvit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45331dcfabf4f0e81c36c08bbaf374c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/38.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"fastvit_s12.apple_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 64, 64, 64])\n",
    "    #  torch.Size([1, 128, 32, 32])\n",
    "    #  torch.Size([1, 256, 16, 16])\n",
    "    #  torch.Size([1, 512, 8, 8])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 8.302M                 | 2.842G     |\\n'\n",
      " '|  stem_0                          |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem_0.conv_kxk.0              |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem_0.conv_kxk.0.conv        |    1.728K              |    44.237M |\\n'\n",
      " '|    stem_0.conv_kxk.0.bn          |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem_0.conv_scale              |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem_0.conv_scale.conv        |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem_0.conv_scale.bn          |    0.128K              |    3.277M  |\\n'\n",
      " '|  stem_1                          |  0.896K                |  5.734M    |\\n'\n",
      " '|   stem_1.conv_kxk.0              |   0.704K               |   4.506M   |\\n'\n",
      " '|    stem_1.conv_kxk.0.conv        |    0.576K              |    3.686M  |\\n'\n",
      " '|    stem_1.conv_kxk.0.bn          |    0.128K              |    0.819M  |\\n'\n",
      " '|   stem_1.conv_scale              |   0.192K               |   1.229M   |\\n'\n",
      " '|    stem_1.conv_scale.conv        |    64                  |    0.41M   |\\n'\n",
      " '|    stem_1.conv_scale.bn          |    0.128K              |    0.819M  |\\n'\n",
      " '|  stem_2                          |  4.352K                |  27.853M   |\\n'\n",
      " '|   stem_2.identity                |   0.128K               |   0.819M   |\\n'\n",
      " '|    stem_2.identity.weight        |    (64,)               |            |\\n'\n",
      " '|    stem_2.identity.bias          |    (64,)               |            |\\n'\n",
      " '|   stem_2.conv_kxk.0              |   4.224K               |   27.034M  |\\n'\n",
      " '|    stem_2.conv_kxk.0.conv        |    4.096K              |    26.214M |\\n'\n",
      " '|    stem_2.conv_kxk.0.bn          |    0.128K              |    0.819M  |\\n'\n",
      " '|  stages_0.blocks                 |  75.264K               |  0.476G    |\\n'\n",
      " '|   stages_0.blocks.0              |   37.632K              |   0.238G   |\\n'\n",
      " '|    stages_0.blocks.0.token_mixer |    1.216K              |    7.373M  |\\n'\n",
      " '|    stages_0.blocks.0.mlp         |    36.352K             |    0.231G  |\\n'\n",
      " '|    stages_0.blocks.0.layer_scale |    64                  |    0       |\\n'\n",
      " '|   stages_0.blocks.1              |   37.632K              |   0.238G   |\\n'\n",
      " '|    stages_0.blocks.1.token_mixer |    1.216K              |    7.373M  |\\n'\n",
      " '|    stages_0.blocks.1.mlp         |    36.352K             |    0.231G  |\\n'\n",
      " '|    stages_0.blocks.1.layer_scale |    64                  |    0       |\\n'\n",
      " '|  stages_1                        |  0.306M                |  0.487G    |\\n'\n",
      " '|   stages_1.downsample.proj       |   24.832K              |   39.731M  |\\n'\n",
      " '|    stages_1.downsample.proj.0    |    7.936K              |    12.698M |\\n'\n",
      " '|    stages_1.downsample.proj.1    |    16.896K             |    27.034M |\\n'\n",
      " '|   stages_1.blocks                |   0.282M               |   0.448G   |\\n'\n",
      " '|    stages_1.blocks.0             |    0.141M              |    0.224G  |\\n'\n",
      " '|    stages_1.blocks.1             |    0.141M              |    0.224G  |\\n'\n",
      " '|  stages_2                        |  3.345M                |  1.334G    |\\n'\n",
      " '|   stages_2.downsample.proj       |   82.432K              |   32.973M  |\\n'\n",
      " '|    stages_2.downsample.proj.0    |    15.872K             |    6.349M  |\\n'\n",
      " '|    stages_2.downsample.proj.1    |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.blocks                |   3.262M               |   1.301G   |\\n'\n",
      " '|    stages_2.blocks.0             |    0.544M              |    0.217G  |\\n'\n",
      " '|    stages_2.blocks.1             |    0.544M              |    0.217G  |\\n'\n",
      " '|    stages_2.blocks.2             |    0.544M              |    0.217G  |\\n'\n",
      " '|    stages_2.blocks.3             |    0.544M              |    0.217G  |\\n'\n",
      " '|    stages_2.blocks.4             |    0.544M              |    0.217G  |\\n'\n",
      " '|    stages_2.blocks.5             |    0.544M              |    0.217G  |\\n'\n",
      " '|  stages_3                        |  4.568M                |  0.456G    |\\n'\n",
      " '|   stages_3.downsample.proj       |   0.296M               |   29.594M  |\\n'\n",
      " '|    stages_3.downsample.proj.0    |    31.744K             |    3.174M  |\\n'\n",
      " '|    stages_3.downsample.proj.1    |    0.264M              |    26.419M |\\n'\n",
      " '|   stages_3.blocks                |   4.272M               |   0.426G   |\\n'\n",
      " '|    stages_3.blocks.0             |    2.136M              |    0.213G  |\\n'\n",
      " '|    stages_3.blocks.1             |    2.136M              |    0.213G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"fastvit_s12.apple_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobileone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abda04cef6ee4b5b940b01a744883be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 112, 112])\n",
      "torch.Size([1, 48, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 48, 112, 112])\n",
    "    #  torch.Size([1, 48, 56, 56])\n",
    "    #  torch.Size([1, 128, 28, 28])\n",
    "    #  torch.Size([1, 256, 14, 14])\n",
    "    #  torch.Size([1, 1024, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 4.268M                 | 2.219G     |\\n'\n",
      " '|  stem                     |  1.632K                |  41.779M   |\\n'\n",
      " '|   stem.conv_kxk.0         |   1.392K               |   35.635M  |\\n'\n",
      " '|    stem.conv_kxk.0.conv   |    1.296K              |    33.178M |\\n'\n",
      " '|    stem.conv_kxk.0.bn     |    96                  |    2.458M  |\\n'\n",
      " '|   stem.conv_scale         |   0.24K                |   6.144M   |\\n'\n",
      " '|    stem.conv_scale.conv   |    0.144K              |    3.686M  |\\n'\n",
      " '|    stem.conv_scale.bn     |    96                  |    2.458M  |\\n'\n",
      " '|  stages_0                 |  24K                   |  0.154G    |\\n'\n",
      " '|   stages_0.0              |   2.256K               |   14.438M  |\\n'\n",
      " '|    stages_0.0.conv_kxk    |    2.112K              |    13.517M |\\n'\n",
      " '|    stages_0.0.conv_scale  |    0.144K              |    0.922M  |\\n'\n",
      " '|   stages_0.1              |   9.696K               |   62.054M  |\\n'\n",
      " '|    stages_0.1.identity    |    96                  |    0.614M  |\\n'\n",
      " '|    stages_0.1.conv_kxk    |    9.6K                |    61.44M  |\\n'\n",
      " '|   stages_0.2              |   2.352K               |   15.053M  |\\n'\n",
      " '|    stages_0.2.identity    |    96                  |    0.614M  |\\n'\n",
      " '|    stages_0.2.conv_kxk    |    2.112K              |    13.517M |\\n'\n",
      " '|    stages_0.2.conv_scale  |    0.144K              |    0.922M  |\\n'\n",
      " '|   stages_0.3              |   9.696K               |   62.054M  |\\n'\n",
      " '|    stages_0.3.identity    |    96                  |    0.614M  |\\n'\n",
      " '|    stages_0.3.conv_kxk    |    9.6K                |    61.44M  |\\n'\n",
      " '|  stages_1                 |  0.539M                |  0.863G    |\\n'\n",
      " '|   stages_1.0              |   2.256K               |   3.61M    |\\n'\n",
      " '|    stages_1.0.conv_kxk    |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.0.conv_scale  |    0.144K              |    0.23M   |\\n'\n",
      " '|   stages_1.1.conv_kxk     |   25.6K                |   40.96M   |\\n'\n",
      " '|    stages_1.1.conv_kxk.0  |    6.4K                |    10.24M  |\\n'\n",
      " '|    stages_1.1.conv_kxk.1  |    6.4K                |    10.24M  |\\n'\n",
      " '|    stages_1.1.conv_kxk.2  |    6.4K                |    10.24M  |\\n'\n",
      " '|    stages_1.1.conv_kxk.3  |    6.4K                |    10.24M  |\\n'\n",
      " '|   stages_1.2              |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.2.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.2.conv_kxk    |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.2.conv_scale  |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.3              |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.3.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.3.conv_kxk    |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.4              |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.4.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.4.conv_kxk    |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.4.conv_scale  |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.5              |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.5.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.5.conv_kxk    |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.6              |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.6.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.6.conv_kxk    |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.6.conv_scale  |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.7              |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.7.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.7.conv_kxk    |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.8              |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.8.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.8.conv_kxk    |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.8.conv_scale  |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.9              |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.9.identity    |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.9.conv_kxk    |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.10             |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.10.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.10.conv_kxk   |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.10.conv_scale |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.11             |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.11.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.11.conv_kxk   |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.12             |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.12.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.12.conv_kxk   |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.12.conv_scale |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.13             |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.13.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.13.conv_kxk   |    66.56K              |    0.106G  |\\n'\n",
      " '|   stages_1.14             |   6.272K               |   10.035M  |\\n'\n",
      " '|    stages_1.14.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.14.conv_kxk   |    5.632K              |    9.011M  |\\n'\n",
      " '|    stages_1.14.conv_scale |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.15             |   66.816K              |   0.107G   |\\n'\n",
      " '|    stages_1.15.identity   |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.15.conv_kxk   |    66.56K              |    0.106G  |\\n'\n",
      " '|  stages_2                 |  2.634M                |  1.054G    |\\n'\n",
      " '|   stages_2.0              |   6.016K               |   2.406M   |\\n'\n",
      " '|    stages_2.0.conv_kxk    |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.0.conv_scale  |    0.384K              |    0.154M  |\\n'\n",
      " '|   stages_2.1.conv_kxk     |   0.133M               |   53.248M  |\\n'\n",
      " '|    stages_2.1.conv_kxk.0  |    33.28K              |    13.312M |\\n'\n",
      " '|    stages_2.1.conv_kxk.1  |    33.28K              |    13.312M |\\n'\n",
      " '|    stages_2.1.conv_kxk.2  |    33.28K              |    13.312M |\\n'\n",
      " '|    stages_2.1.conv_kxk.3  |    33.28K              |    13.312M |\\n'\n",
      " '|   stages_2.2              |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.2.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.2.conv_kxk    |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.2.conv_scale  |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.3              |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.3.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.3.conv_kxk    |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.4              |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.4.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.4.conv_kxk    |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.4.conv_scale  |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.5              |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.5.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.5.conv_kxk    |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.6              |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.6.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.6.conv_kxk    |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.6.conv_scale  |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.7              |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.7.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.7.conv_kxk    |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.8              |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.8.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.8.conv_kxk    |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.8.conv_scale  |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.9              |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.9.identity    |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.9.conv_kxk    |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.10             |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.10.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.10.conv_kxk   |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.10.conv_scale |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.11             |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.11.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.11.conv_kxk   |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.12             |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.12.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.12.conv_kxk   |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.12.conv_scale |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.13             |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.13.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.13.conv_kxk   |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.14             |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.14.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.14.conv_kxk   |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.14.conv_scale |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.15             |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.15.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.15.conv_kxk   |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.16             |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.16.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.16.conv_kxk   |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.16.conv_scale |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.17             |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.17.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.17.conv_kxk   |    0.264M              |    0.106G  |\\n'\n",
      " '|   stages_2.18             |   12.544K              |   5.018M   |\\n'\n",
      " '|    stages_2.18.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.18.conv_kxk   |    11.264K             |    4.506M  |\\n'\n",
      " '|    stages_2.18.conv_scale |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.19             |   0.265M               |   0.106G   |\\n'\n",
      " '|    stages_2.19.identity   |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.19.conv_kxk   |    0.264M              |    0.106G  |\\n'\n",
      " '|  stages_3                 |  1.069M                |  0.107G    |\\n'\n",
      " '|   stages_3.0              |   12.032K              |   1.203M   |\\n'\n",
      " '|    stages_3.0.conv_kxk    |    11.264K             |    1.126M  |\\n'\n",
      " '|    stages_3.0.conv_scale  |    0.768K              |    76.8K   |\\n'\n",
      " '|   stages_3.1.conv_kxk     |   1.057M               |   0.106G   |\\n'\n",
      " '|    stages_3.1.conv_kxk.0  |    0.264M              |    26.419M |\\n'\n",
      " '|    stages_3.1.conv_kxk.1  |    0.264M              |    26.419M |\\n'\n",
      " '|    stages_3.1.conv_kxk.2  |    0.264M              |    26.419M |\\n'\n",
      " '|    stages_3.1.conv_kxk.3  |    0.264M              |    26.419M |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd56bad63c84bdca1266b6c632e01df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                        | #parameters or shape   | #flops     |\\n'\n",
      " '|:------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                         | 3.544M                 | 1.749G     |\\n'\n",
      " '|  stem                         |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk.0             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.0.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.0.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_scale             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_scale.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_scale.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                     |  18.368K               |  0.118G    |\\n'\n",
      " '|   stages_0.0                  |   0.896K               |   5.734M   |\\n'\n",
      " '|    stages_0.0.conv_kxk.0      |    0.704K              |    4.506M  |\\n'\n",
      " '|    stages_0.0.conv_scale      |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.1.conv_kxk.0       |   6.336K               |   40.55M   |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.conv |    6.144K              |    39.322M |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.bn   |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.2                  |   1.536K               |   9.83M    |\\n'\n",
      " '|    stages_0.2.identity        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.2.conv_kxk.0      |    1.056K              |    6.758M  |\\n'\n",
      " '|    stages_0.2.conv_scale      |    0.288K              |    1.843M  |\\n'\n",
      " '|   stages_0.3                  |   9.6K                 |   61.44M   |\\n'\n",
      " '|    stages_0.3.identity        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.3.conv_kxk.0      |    9.408K              |    60.211M |\\n'\n",
      " '|  stages_1                     |  0.305M                |  0.488G    |\\n'\n",
      " '|   stages_1.0                  |   1.344K               |   2.15M    |\\n'\n",
      " '|    stages_1.0.conv_kxk.0      |    1.056K              |    1.69M   |\\n'\n",
      " '|    stages_1.0.conv_scale      |    0.288K              |    0.461M  |\\n'\n",
      " '|   stages_1.1.conv_kxk.0       |   18.816K              |   30.106M  |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.conv |    18.432K             |    29.491M |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.bn   |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.2                  |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.2.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.2.conv_kxk.0      |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.2.conv_scale      |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.3                  |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.3.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.3.conv_kxk.0      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.4                  |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.4.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.4.conv_kxk.0      |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.4.conv_scale      |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.5                  |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.5.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.5.conv_kxk.0      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.6                  |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.6.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.6.conv_kxk.0      |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.6.conv_scale      |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.7                  |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.7.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.7.conv_kxk.0      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.8                  |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.8.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.8.conv_kxk.0      |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.8.conv_scale      |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.9                  |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.9.identity        |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.9.conv_kxk.0      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.10                 |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.10.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.10.conv_kxk.0     |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.10.conv_scale     |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.11                 |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.11.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.11.conv_kxk.0     |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.12                 |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.12.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.12.conv_kxk.0     |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.12.conv_scale     |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.13                 |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.13.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.13.conv_kxk.0     |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.14                 |   3.072K               |   4.915M   |\\n'\n",
      " '|    stages_1.14.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.14.conv_kxk.0     |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.14.conv_scale     |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.15                 |   37.632K              |   60.211M  |\\n'\n",
      " '|    stages_1.15.identity       |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.15.conv_kxk.0     |    37.248K             |    59.597M |\\n'\n",
      " '|  stages_2                     |  2.553M                |  1.021G    |\\n'\n",
      " '|   stages_2.0                  |   2.688K               |   1.075M   |\\n'\n",
      " '|    stages_2.0.conv_kxk.0      |    2.112K              |    0.845M  |\\n'\n",
      " '|    stages_2.0.conv_scale      |    0.576K              |    0.23M   |\\n'\n",
      " '|   stages_2.1.conv_kxk.0       |   99.328K              |   39.731M  |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.conv |    98.304K             |    39.322M |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.bn   |    1.024K              |    0.41M   |\\n'\n",
      " '|   stages_2.2                  |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.2.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.2.conv_kxk.0      |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.2.conv_scale      |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.3                  |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.3.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.3.conv_kxk.0      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.4                  |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.4.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.4.conv_kxk.0      |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.4.conv_scale      |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.5                  |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.5.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.5.conv_kxk.0      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.6                  |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.6.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.6.conv_kxk.0      |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.6.conv_scale      |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.7                  |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.7.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.7.conv_kxk.0      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.8                  |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.8.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.8.conv_kxk.0      |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.8.conv_scale      |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.9                  |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.9.identity        |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.9.conv_kxk.0      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.10                 |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.10.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.10.conv_kxk.0     |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.10.conv_scale     |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.11                 |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.11.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.11.conv_kxk.0     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.12                 |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.12.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.12.conv_kxk.0     |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.12.conv_scale     |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.13                 |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.13.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.13.conv_kxk.0     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.14                 |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.14.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.14.conv_kxk.0     |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.14.conv_scale     |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.15                 |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.15.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.15.conv_kxk.0     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.16                 |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.16.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.16.conv_kxk.0     |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.16.conv_scale     |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.17                 |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.17.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.17.conv_kxk.0     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.18                 |   8.192K               |   3.277M   |\\n'\n",
      " '|    stages_2.18.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.18.conv_kxk.0     |    5.632K              |    2.253M  |\\n'\n",
      " '|    stages_2.18.conv_scale     |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.19                 |   0.264M               |   0.106G   |\\n'\n",
      " '|    stages_2.19.identity       |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.19.conv_kxk.0     |    0.263M              |    0.105G  |\\n'\n",
      " '|  stages_3                     |  0.665M                |  66.509M   |\\n'\n",
      " '|   stages_3.0                  |   7.168K               |   0.717M   |\\n'\n",
      " '|    stages_3.0.conv_kxk.0      |    5.632K              |    0.563M  |\\n'\n",
      " '|    stages_3.0.conv_scale      |    1.536K              |    0.154M  |\\n'\n",
      " '|   stages_3.1.conv_kxk.0       |   0.658M               |   65.792M  |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.conv |    0.655M              |    65.536M |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.bn   |    2.56K               |    0.256M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b96b860777d4b6fbebc31d1a74fabc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 640, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                        | #parameters or shape   | #flops     |\\n'\n",
      " '|:------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                         | 5.836M                 | 2.727G     |\\n'\n",
      " '|  stem                         |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk.0             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.0.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.0.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_scale             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_scale.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_scale.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                     |  18.368K               |  0.118G    |\\n'\n",
      " '|   stages_0.0                  |   0.896K               |   5.734M   |\\n'\n",
      " '|    stages_0.0.conv_kxk.0      |    0.704K              |    4.506M  |\\n'\n",
      " '|    stages_0.0.conv_scale      |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.1.conv_kxk.0       |   6.336K               |   40.55M   |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.conv |    6.144K              |    39.322M |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.bn   |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.2                  |   1.536K               |   9.83M    |\\n'\n",
      " '|    stages_0.2.identity        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.2.conv_kxk.0      |    1.056K              |    6.758M  |\\n'\n",
      " '|    stages_0.2.conv_scale      |    0.288K              |    1.843M  |\\n'\n",
      " '|   stages_0.3                  |   9.6K                 |   61.44M   |\\n'\n",
      " '|    stages_0.3.identity        |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.3.conv_kxk.0      |    9.408K              |    60.211M |\\n'\n",
      " '|  stages_1                     |  0.521M                |  0.834G    |\\n'\n",
      " '|   stages_1.0                  |   1.344K               |   2.15M    |\\n'\n",
      " '|    stages_1.0.conv_kxk.0      |    1.056K              |    1.69M   |\\n'\n",
      " '|    stages_1.0.conv_scale      |    0.288K              |    0.461M  |\\n'\n",
      " '|   stages_1.1.conv_kxk.0       |   25.088K              |   40.141M  |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.conv |    24.576K             |    39.322M |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.bn   |    0.512K              |    0.819M  |\\n'\n",
      " '|   stages_1.2                  |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.2.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.2.conv_kxk.0      |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.2.conv_scale      |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.3                  |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.3.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.3.conv_kxk.0      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.4                  |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.4.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.4.conv_kxk.0      |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.4.conv_scale      |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.5                  |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.5.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.5.conv_kxk.0      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.6                  |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.6.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.6.conv_kxk.0      |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.6.conv_scale      |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.7                  |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.7.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.7.conv_kxk.0      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.8                  |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.8.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.8.conv_kxk.0      |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.8.conv_scale      |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.9                  |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.9.identity        |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.9.conv_kxk.0      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.10                 |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.10.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.10.conv_kxk.0     |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.10.conv_scale     |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.11                 |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.11.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.11.conv_kxk.0     |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.12                 |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.12.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.12.conv_kxk.0     |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.12.conv_scale     |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.13                 |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.13.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.13.conv_kxk.0     |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.14                 |   4.096K               |   6.554M   |\\n'\n",
      " '|    stages_1.14.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.14.conv_kxk.0     |    2.816K              |    4.506M  |\\n'\n",
      " '|    stages_1.14.conv_scale     |    0.768K              |    1.229M  |\\n'\n",
      " '|   stages_1.15                 |   66.56K               |   0.106G   |\\n'\n",
      " '|    stages_1.15.identity       |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.15.conv_kxk.0     |    66.048K             |    0.106G  |\\n'\n",
      " '|  stages_2                     |  3.97M                 |  1.588G    |\\n'\n",
      " '|   stages_2.0                  |   3.584K               |   1.434M   |\\n'\n",
      " '|    stages_2.0.conv_kxk.0      |    2.816K              |    1.126M  |\\n'\n",
      " '|    stages_2.0.conv_scale      |    0.768K              |    0.307M  |\\n'\n",
      " '|   stages_2.1.conv_kxk.0       |   0.165M               |   66.048M  |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.conv |    0.164M              |    65.536M |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.bn   |    1.28K               |    0.512M  |\\n'\n",
      " '|   stages_2.2                  |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.2.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.2.conv_kxk.0      |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.2.conv_scale      |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.3                  |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.3.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.3.conv_kxk.0      |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.4                  |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.4.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.4.conv_kxk.0      |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.4.conv_scale      |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.5                  |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.5.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.5.conv_kxk.0      |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.6                  |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.6.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.6.conv_kxk.0      |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.6.conv_scale      |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.7                  |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.7.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.7.conv_kxk.0      |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.8                  |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.8.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.8.conv_kxk.0      |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.8.conv_scale      |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.9                  |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.9.identity        |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.9.conv_kxk.0      |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.10                 |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.10.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.10.conv_kxk.0     |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.10.conv_scale     |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.11                 |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.11.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.11.conv_kxk.0     |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.12                 |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.12.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.12.conv_kxk.0     |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.12.conv_scale     |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.13                 |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.13.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.13.conv_kxk.0     |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.14                 |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.14.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.14.conv_kxk.0     |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.14.conv_scale     |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.15                 |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.15.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.15.conv_kxk.0     |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.16                 |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.16.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.16.conv_kxk.0     |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.16.conv_scale     |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.17                 |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.17.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.17.conv_kxk.0     |    0.411M              |    0.164G  |\\n'\n",
      " '|   stages_2.18                 |   10.24K               |   4.096M   |\\n'\n",
      " '|    stages_2.18.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.18.conv_kxk.0     |    7.04K               |    2.816M  |\\n'\n",
      " '|    stages_2.18.conv_scale     |    1.92K               |    0.768M  |\\n'\n",
      " '|   stages_2.19                 |   0.412M               |   0.165G   |\\n'\n",
      " '|    stages_2.19.identity       |    1.28K               |    0.512M  |\\n'\n",
      " '|    stages_2.19.conv_kxk.0     |    0.411M              |    0.164G  |\\n'\n",
      " '|  stages_3                     |  1.324M                |  0.132G    |\\n'\n",
      " '|   stages_3.0                  |   8.96K                |   0.896M   |\\n'\n",
      " '|    stages_3.0.conv_kxk.0      |    7.04K               |    0.704M  |\\n'\n",
      " '|    stages_3.0.conv_scale      |    1.92K               |    0.192M  |\\n'\n",
      " '|   stages_3.1.conv_kxk.0       |   1.315M               |   0.131G   |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.conv |    1.311M              |    0.131G  |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.bn   |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 320, 28, 28])\n",
      "torch.Size([1, 768, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s3\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483494ed64c74802a6781d74cfa5ffb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/41.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                        | #parameters or shape   | #flops     |\\n'\n",
      " '|:------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                         | 8.122M                 | 3.963G     |\\n'\n",
      " '|  stem                         |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk.0             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.0.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.0.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_scale             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_scale.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_scale.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                     |  28.288K               |  0.181G    |\\n'\n",
      " '|   stages_0.0                  |   0.896K               |   5.734M   |\\n'\n",
      " '|    stages_0.0.conv_kxk.0      |    0.704K              |    4.506M  |\\n'\n",
      " '|    stages_0.0.conv_scale      |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.1.conv_kxk.0       |   8.448K               |   54.067M  |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.conv |    8.192K              |    52.429M |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.bn   |    0.256K              |    1.638M  |\\n'\n",
      " '|   stages_0.2                  |   2.048K               |   13.107M  |\\n'\n",
      " '|    stages_0.2.identity        |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.2.conv_kxk.0      |    1.408K              |    9.011M  |\\n'\n",
      " '|    stages_0.2.conv_scale      |    0.384K              |    2.458M  |\\n'\n",
      " '|   stages_0.3                  |   16.896K              |   0.108G   |\\n'\n",
      " '|    stages_0.3.identity        |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.3.conv_kxk.0      |    16.64K              |    0.106G  |\\n'\n",
      " '|  stages_1                     |  0.805M                |  1.288G    |\\n'\n",
      " '|   stages_1.0                  |   1.792K               |   2.867M   |\\n'\n",
      " '|    stages_1.0.conv_kxk.0      |    1.408K              |    2.253M  |\\n'\n",
      " '|    stages_1.0.conv_scale      |    0.384K              |    0.614M  |\\n'\n",
      " '|   stages_1.1.conv_kxk.0       |   41.6K                |   66.56M   |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.conv |    40.96K              |    65.536M |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.bn   |    0.64K               |    1.024M  |\\n'\n",
      " '|   stages_1.2                  |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.2.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.2.conv_kxk.0      |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.2.conv_scale      |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.3                  |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.3.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.3.conv_kxk.0      |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.4                  |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.4.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.4.conv_kxk.0      |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.4.conv_scale      |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.5                  |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.5.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.5.conv_kxk.0      |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.6                  |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.6.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.6.conv_kxk.0      |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.6.conv_scale      |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.7                  |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.7.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.7.conv_kxk.0      |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.8                  |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.8.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.8.conv_kxk.0      |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.8.conv_scale      |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.9                  |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.9.identity        |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.9.conv_kxk.0      |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.10                 |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.10.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.10.conv_kxk.0     |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.10.conv_scale     |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.11                 |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.11.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.11.conv_kxk.0     |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.12                 |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.12.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.12.conv_kxk.0     |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.12.conv_scale     |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.13                 |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.13.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.13.conv_kxk.0     |    0.103M              |    0.165G  |\\n'\n",
      " '|   stages_1.14                 |   5.12K                |   8.192M   |\\n'\n",
      " '|    stages_1.14.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.14.conv_kxk.0     |    3.52K               |    5.632M  |\\n'\n",
      " '|    stages_1.14.conv_scale     |    0.96K               |    1.536M  |\\n'\n",
      " '|   stages_1.15                 |   0.104M               |   0.166G   |\\n'\n",
      " '|    stages_1.15.identity       |    0.64K               |    1.024M  |\\n'\n",
      " '|    stages_1.15.conv_kxk.0     |    0.103M              |    0.165G  |\\n'\n",
      " '|  stages_2                     |  5.698M                |  2.279G    |\\n'\n",
      " '|   stages_2.0                  |   4.48K                |   1.792M   |\\n'\n",
      " '|    stages_2.0.conv_kxk.0      |    3.52K               |    1.408M  |\\n'\n",
      " '|    stages_2.0.conv_scale      |    0.96K               |    0.384M  |\\n'\n",
      " '|   stages_2.1.conv_kxk.0       |   0.247M               |   98.918M  |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.conv |    0.246M              |    98.304M |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.bn   |    1.536K              |    0.614M  |\\n'\n",
      " '|   stages_2.2                  |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.2.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.2.conv_kxk.0      |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.2.conv_scale      |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.3                  |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.3.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.3.conv_kxk.0      |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.4                  |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.4.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.4.conv_kxk.0      |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.4.conv_scale      |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.5                  |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.5.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.5.conv_kxk.0      |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.6                  |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.6.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.6.conv_kxk.0      |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.6.conv_scale      |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.7                  |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.7.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.7.conv_kxk.0      |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.8                  |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.8.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.8.conv_kxk.0      |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.8.conv_scale      |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.9                  |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.9.identity        |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.9.conv_kxk.0      |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.10                 |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.10.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.10.conv_kxk.0     |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.10.conv_scale     |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.11                 |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.11.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.11.conv_kxk.0     |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.12                 |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.12.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.12.conv_kxk.0     |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.12.conv_scale     |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.13                 |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.13.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.13.conv_kxk.0     |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.14                 |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.14.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.14.conv_kxk.0     |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.14.conv_scale     |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.15                 |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.15.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.15.conv_kxk.0     |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.16                 |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.16.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.16.conv_kxk.0     |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.16.conv_scale     |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.17                 |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.17.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.17.conv_kxk.0     |    0.591M              |    0.237G  |\\n'\n",
      " '|   stages_2.18                 |   12.288K              |   4.915M   |\\n'\n",
      " '|    stages_2.18.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.18.conv_kxk.0     |    8.448K              |    3.379M  |\\n'\n",
      " '|    stages_2.18.conv_scale     |    2.304K              |    0.922M  |\\n'\n",
      " '|   stages_2.19                 |   0.593M               |   0.237G   |\\n'\n",
      " '|    stages_2.19.identity       |    1.536K              |    0.614M  |\\n'\n",
      " '|    stages_2.19.conv_kxk.0     |    0.591M              |    0.237G  |\\n'\n",
      " '|  stages_3                     |  1.588M                |  0.159G    |\\n'\n",
      " '|   stages_3.0                  |   10.752K              |   1.075M   |\\n'\n",
      " '|    stages_3.0.conv_kxk.0      |    8.448K              |    0.845M  |\\n'\n",
      " '|    stages_3.0.conv_scale      |    2.304K              |    0.23M   |\\n'\n",
      " '|   stages_3.1.conv_kxk.0       |   1.577M               |   0.158G   |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.conv |    1.573M              |    0.157G  |\\n'\n",
      " '|    stages_3.1.conv_kxk.0.bn   |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s3\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458ce4ceca8472a97ec6ddd4be28ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/60.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 192, 56, 56])\n",
      "torch.Size([1, 448, 28, 28])\n",
      "torch.Size([1, 896, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                        | #parameters or shape   | #flops     |\\n'\n",
      " '|:------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                         | 12.902M                | 6.2G       |\\n'\n",
      " '|  stem                         |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk.0             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.0.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.0.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_scale             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_scale.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_scale.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                     |  54.272K               |  0.347G    |\\n'\n",
      " '|   stages_0.0                  |   0.896K               |   5.734M   |\\n'\n",
      " '|    stages_0.0.conv_kxk.0      |    0.704K              |    4.506M  |\\n'\n",
      " '|    stages_0.0.conv_scale      |    0.192K              |    1.229M  |\\n'\n",
      " '|   stages_0.1.conv_kxk.0       |   12.672K              |   81.101M  |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.conv |    12.288K             |    78.643M |\\n'\n",
      " '|    stages_0.1.conv_kxk.0.bn   |    0.384K              |    2.458M  |\\n'\n",
      " '|   stages_0.2                  |   3.072K               |   19.661M  |\\n'\n",
      " '|    stages_0.2.identity        |    0.384K              |    2.458M  |\\n'\n",
      " '|    stages_0.2.conv_kxk.0      |    2.112K              |    13.517M |\\n'\n",
      " '|    stages_0.2.conv_scale      |    0.576K              |    3.686M  |\\n'\n",
      " '|   stages_0.3                  |   37.632K              |   0.241G   |\\n'\n",
      " '|    stages_0.3.identity        |    0.384K              |    2.458M  |\\n'\n",
      " '|    stages_0.3.conv_kxk.0      |    37.248K             |    0.238G  |\\n'\n",
      " '|  stages_1                     |  1.557M                |  2.492G    |\\n'\n",
      " '|   stages_1.0                  |   2.688K               |   4.301M   |\\n'\n",
      " '|    stages_1.0.conv_kxk.0      |    2.112K              |    3.379M  |\\n'\n",
      " '|    stages_1.0.conv_scale      |    0.576K              |    0.922M  |\\n'\n",
      " '|   stages_1.1.conv_kxk.0       |   86.912K              |   0.139G   |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.conv |    86.016K             |    0.138G  |\\n'\n",
      " '|    stages_1.1.conv_kxk.0.bn   |    0.896K              |    1.434M  |\\n'\n",
      " '|   stages_1.2                  |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.2.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.2.conv_kxk.0      |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.2.conv_scale      |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.3                  |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.3.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.3.conv_kxk.0      |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.4                  |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.4.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.4.conv_kxk.0      |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.4.conv_scale      |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.5                  |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.5.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.5.conv_kxk.0      |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.6                  |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.6.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.6.conv_kxk.0      |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.6.conv_scale      |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.7                  |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.7.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.7.conv_kxk.0      |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.8                  |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.8.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.8.conv_kxk.0      |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.8.conv_scale      |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.9                  |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.9.identity        |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.9.conv_kxk.0      |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.10                 |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.10.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.10.conv_kxk.0     |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.10.conv_scale     |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.11                 |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.11.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.11.conv_kxk.0     |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.12                 |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.12.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.12.conv_kxk.0     |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.12.conv_scale     |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.13                 |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.13.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.13.conv_kxk.0     |    0.202M              |    0.323G  |\\n'\n",
      " '|   stages_1.14                 |   7.168K               |   11.469M  |\\n'\n",
      " '|    stages_1.14.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.14.conv_kxk.0     |    4.928K              |    7.885M  |\\n'\n",
      " '|    stages_1.14.conv_scale     |    1.344K              |    2.15M   |\\n'\n",
      " '|   stages_1.15                 |   0.202M               |   0.324G   |\\n'\n",
      " '|    stages_1.15.identity       |    0.896K              |    1.434M  |\\n'\n",
      " '|    stages_1.15.conv_kxk.0     |    0.202M              |    0.323G  |\\n'\n",
      " '|  stages_2                     |  8.809M                |  3.119G    |\\n'\n",
      " '|   stages_2.0                  |   6.272K               |   2.509M   |\\n'\n",
      " '|    stages_2.0.conv_kxk.0      |    4.928K              |    1.971M  |\\n'\n",
      " '|    stages_2.0.conv_scale      |    1.344K              |    0.538M  |\\n'\n",
      " '|   stages_2.1.conv_kxk.0       |   0.403M               |   0.161G   |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.conv |    0.401M              |    0.161G  |\\n'\n",
      " '|    stages_2.1.conv_kxk.0.bn   |    1.792K              |    0.717M  |\\n'\n",
      " '|   stages_2.2                  |   14.336K              |   5.734M   |\\n'\n",
      " '|    stages_2.2.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.2.conv_kxk.0      |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.2.conv_scale      |    2.688K              |    1.075M  |\\n'\n",
      " '|   stages_2.3                  |   0.806M               |   0.323G   |\\n'\n",
      " '|    stages_2.3.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.3.conv_kxk.0      |    0.805M              |    0.322G  |\\n'\n",
      " '|   stages_2.4                  |   14.336K              |   5.734M   |\\n'\n",
      " '|    stages_2.4.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.4.conv_kxk.0      |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.4.conv_scale      |    2.688K              |    1.075M  |\\n'\n",
      " '|   stages_2.5                  |   0.806M               |   0.323G   |\\n'\n",
      " '|    stages_2.5.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.5.conv_kxk.0      |    0.805M              |    0.322G  |\\n'\n",
      " '|   stages_2.6                  |   14.336K              |   5.734M   |\\n'\n",
      " '|    stages_2.6.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.6.conv_kxk.0      |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.6.conv_scale      |    2.688K              |    1.075M  |\\n'\n",
      " '|   stages_2.7                  |   0.806M               |   0.323G   |\\n'\n",
      " '|    stages_2.7.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.7.conv_kxk.0      |    0.805M              |    0.322G  |\\n'\n",
      " '|   stages_2.8                  |   14.336K              |   5.734M   |\\n'\n",
      " '|    stages_2.8.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.8.conv_kxk.0      |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.8.conv_scale      |    2.688K              |    1.075M  |\\n'\n",
      " '|   stages_2.9                  |   0.806M               |   0.323G   |\\n'\n",
      " '|    stages_2.9.identity        |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.9.conv_kxk.0      |    0.805M              |    0.322G  |\\n'\n",
      " '|   stages_2.10                 |   0.116M               |   5.835M   |\\n'\n",
      " '|    stages_2.10.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.10.conv_kxk.0     |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.10.conv_scale     |    2.688K              |    1.075M  |\\n'\n",
      " '|    stages_2.10.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.11                 |   0.908M               |   0.323G   |\\n'\n",
      " '|    stages_2.11.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.11.conv_kxk.0     |    0.805M              |    0.322G  |\\n'\n",
      " '|    stages_2.11.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.12                 |   0.116M               |   5.835M   |\\n'\n",
      " '|    stages_2.12.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.12.conv_kxk.0     |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.12.conv_scale     |    2.688K              |    1.075M  |\\n'\n",
      " '|    stages_2.12.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.13                 |   0.908M               |   0.323G   |\\n'\n",
      " '|    stages_2.13.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.13.conv_kxk.0     |    0.805M              |    0.322G  |\\n'\n",
      " '|    stages_2.13.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.14                 |   0.116M               |   5.835M   |\\n'\n",
      " '|    stages_2.14.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.14.conv_kxk.0     |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.14.conv_scale     |    2.688K              |    1.075M  |\\n'\n",
      " '|    stages_2.14.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.15                 |   0.908M               |   0.323G   |\\n'\n",
      " '|    stages_2.15.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.15.conv_kxk.0     |    0.805M              |    0.322G  |\\n'\n",
      " '|    stages_2.15.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.16                 |   0.116M               |   5.835M   |\\n'\n",
      " '|    stages_2.16.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.16.conv_kxk.0     |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.16.conv_scale     |    2.688K              |    1.075M  |\\n'\n",
      " '|    stages_2.16.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.17                 |   0.908M               |   0.323G   |\\n'\n",
      " '|    stages_2.17.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.17.conv_kxk.0     |    0.805M              |    0.322G  |\\n'\n",
      " '|    stages_2.17.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.18                 |   0.116M               |   5.835M   |\\n'\n",
      " '|    stages_2.18.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.18.conv_kxk.0     |    9.856K              |    3.942M  |\\n'\n",
      " '|    stages_2.18.conv_scale     |    2.688K              |    1.075M  |\\n'\n",
      " '|    stages_2.18.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_2.19                 |   0.908M               |   0.323G   |\\n'\n",
      " '|    stages_2.19.identity       |    1.792K              |    0.717M  |\\n'\n",
      " '|    stages_2.19.conv_kxk.0     |    0.805M              |    0.322G  |\\n'\n",
      " '|    stages_2.19.attn           |    0.101M              |    0.1M    |\\n'\n",
      " '|  stages_3                     |  2.479M                |  0.186G    |\\n'\n",
      " '|   stages_3.0                  |   0.114M               |   1.355M   |\\n'\n",
      " '|    stages_3.0.conv_kxk.0      |    9.856K              |    0.986M  |\\n'\n",
      " '|    stages_3.0.conv_scale      |    2.688K              |    0.269M  |\\n'\n",
      " '|    stages_3.0.attn            |    0.101M              |    0.1M    |\\n'\n",
      " '|   stages_3.1                  |   2.366M               |   0.184G   |\\n'\n",
      " '|    stages_3.1.conv_kxk.0      |    1.839M              |    0.184G  |\\n'\n",
      " '|    stages_3.1.attn            |    0.526M              |    0.524M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"mobileone_s4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convnext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46151178339e4a6e81253c05e5da8bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 384, 14, 14])\n",
      "torch.Size([1, 768, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"convnext_tiny.fb_in22k_ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 96, 56, 56])\n",
    "    #  torch.Size([1, 192, 28, 28])\n",
    "    #  torch.Size([1, 384, 14, 14])\n",
    "    #  torch.Size([1, 768, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 27.819M                | 9.122G     |\\n'\n",
      " '|  stem_0                      |  4.704K                |  29.491M   |\\n'\n",
      " '|   stem_0.weight              |   (96, 3, 4, 4)        |            |\\n'\n",
      " '|   stem_0.bias                |   (96,)                |            |\\n'\n",
      " '|  stem_1                      |  0.192K                |  3.072M    |\\n'\n",
      " '|   stem_1.weight              |   (96,)                |            |\\n'\n",
      " '|   stem_1.bias                |   (96,)                |            |\\n'\n",
      " '|  stages_0.blocks             |  0.238M                |  1.515G    |\\n'\n",
      " '|   stages_0.blocks.0          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.0.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.0.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.0.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.0.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|   stages_0.blocks.1          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.1.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.1.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.1.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.1.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|   stages_0.blocks.2          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.2.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.2.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.2.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.2.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|  stages_1                    |  0.992M                |  1.586G    |\\n'\n",
      " '|   stages_1.downsample        |   74.112K              |   0.121G   |\\n'\n",
      " '|    stages_1.downsample.0     |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_1.downsample.1     |    73.92K              |    0.118G  |\\n'\n",
      " '|   stages_1.blocks            |   0.918M               |   1.465G   |\\n'\n",
      " '|    stages_1.blocks.0         |    0.306M              |    0.488G  |\\n'\n",
      " '|    stages_1.blocks.1         |    0.306M              |    0.488G  |\\n'\n",
      " '|    stages_1.blocks.2         |    0.306M              |    0.488G  |\\n'\n",
      " '|  stages_2                    |  11.113M               |  4.441G    |\\n'\n",
      " '|   stages_2.downsample        |   0.296M               |   0.12G    |\\n'\n",
      " '|    stages_2.downsample.0     |    0.384K              |    1.536M  |\\n'\n",
      " '|    stages_2.downsample.1     |    0.295M              |    0.118G  |\\n'\n",
      " '|   stages_2.blocks            |   10.817M              |   4.321G   |\\n'\n",
      " '|    stages_2.blocks.0         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.1         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.2         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.3         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.4         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.5         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.6         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.7         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.8         |    1.202M              |    0.48G   |\\n'\n",
      " '|  stages_3                    |  15.471M               |  1.547G    |\\n'\n",
      " '|   stages_3.downsample        |   1.181M               |   0.119G   |\\n'\n",
      " '|    stages_3.downsample.0     |    0.768K              |    0.768M  |\\n'\n",
      " '|    stages_3.downsample.1     |    1.18M               |    0.118G  |\\n'\n",
      " '|   stages_3.blocks            |   14.289M              |   1.428G   |\\n'\n",
      " '|    stages_3.blocks.0         |    4.763M              |    0.476G  |\\n'\n",
      " '|    stages_3.blocks.1         |    4.763M              |    0.476G  |\\n'\n",
      " '|    stages_3.blocks.2         |    4.763M              |    0.476G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"convnext_tiny.fb_in22k_ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb80fc31d6f48d8a4e5ec30b80bed38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 384, 14, 14])\n",
      "torch.Size([1, 768, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"convnext_small.fb_in22k_ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 96, 56, 56])\n",
    "    #  torch.Size([1, 192, 28, 28])\n",
    "    #  torch.Size([1, 384, 14, 14])\n",
    "    #  torch.Size([1, 768, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 49.453M                | 17.764G    |\\n'\n",
      " '|  stem_0                      |  4.704K                |  29.491M   |\\n'\n",
      " '|   stem_0.weight              |   (96, 3, 4, 4)        |            |\\n'\n",
      " '|   stem_0.bias                |   (96,)                |            |\\n'\n",
      " '|  stem_1                      |  0.192K                |  3.072M    |\\n'\n",
      " '|   stem_1.weight              |   (96,)                |            |\\n'\n",
      " '|   stem_1.bias                |   (96,)                |            |\\n'\n",
      " '|  stages_0.blocks             |  0.238M                |  1.515G    |\\n'\n",
      " '|   stages_0.blocks.0          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.0.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.0.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.0.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.0.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|   stages_0.blocks.1          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.1.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.1.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.1.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.1.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|   stages_0.blocks.2          |   79.296K              |   0.505G   |\\n'\n",
      " '|    stages_0.blocks.2.gamma   |    (96,)               |            |\\n'\n",
      " '|    stages_0.blocks.2.conv_dw |    4.8K                |    30.106M |\\n'\n",
      " '|    stages_0.blocks.2.norm    |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_0.blocks.2.mlp     |    74.208K             |    0.472G  |\\n'\n",
      " '|  stages_1                    |  0.992M                |  1.586G    |\\n'\n",
      " '|   stages_1.downsample        |   74.112K              |   0.121G   |\\n'\n",
      " '|    stages_1.downsample.0     |    0.192K              |    3.072M  |\\n'\n",
      " '|    stages_1.downsample.1     |    73.92K              |    0.118G  |\\n'\n",
      " '|   stages_1.blocks            |   0.918M               |   1.465G   |\\n'\n",
      " '|    stages_1.blocks.0         |    0.306M              |    0.488G  |\\n'\n",
      " '|    stages_1.blocks.1         |    0.306M              |    0.488G  |\\n'\n",
      " '|    stages_1.blocks.2         |    0.306M              |    0.488G  |\\n'\n",
      " '|  stages_2                    |  32.748M               |  13.084G   |\\n'\n",
      " '|   stages_2.downsample        |   0.296M               |   0.12G    |\\n'\n",
      " '|    stages_2.downsample.0     |    0.384K              |    1.536M  |\\n'\n",
      " '|    stages_2.downsample.1     |    0.295M              |    0.118G  |\\n'\n",
      " '|   stages_2.blocks            |   32.452M              |   12.964G  |\\n'\n",
      " '|    stages_2.blocks.0         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.1         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.2         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.3         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.4         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.5         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.6         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.7         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.8         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.9         |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.10        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.11        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.12        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.13        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.14        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.15        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.16        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.17        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.18        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.19        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.20        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.21        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.22        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.23        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.24        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.25        |    1.202M              |    0.48G   |\\n'\n",
      " '|    stages_2.blocks.26        |    1.202M              |    0.48G   |\\n'\n",
      " '|  stages_3                    |  15.471M               |  1.547G    |\\n'\n",
      " '|   stages_3.downsample        |   1.181M               |   0.119G   |\\n'\n",
      " '|    stages_3.downsample.0     |    0.768K              |    0.768M  |\\n'\n",
      " '|    stages_3.downsample.1     |    1.18M               |    0.118G  |\\n'\n",
      " '|   stages_3.blocks            |   14.289M              |   1.428G   |\\n'\n",
      " '|    stages_3.blocks.0         |    4.763M              |    0.476G  |\\n'\n",
      " '|    stages_3.blocks.1         |    4.763M              |    0.476G  |\\n'\n",
      " '|    stages_3.blocks.2         |    4.763M              |    0.476G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"convnext_small.fb_in22k_ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet18.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 64, 112, 112])\n",
    "    #  torch.Size([1, 64, 56, 56])\n",
    "    #  torch.Size([1, 128, 28, 28])\n",
    "    #  torch.Size([1, 256, 14, 14])\n",
    "    #  torch.Size([1, 512, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 11.177M                | 3.711G     |\\n'\n",
      " '|  conv1                 |  9.408K                |  0.241G    |\\n'\n",
      " '|   conv1.weight         |   (64, 3, 7, 7)        |            |\\n'\n",
      " '|  bn1                   |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight           |   (64,)                |            |\\n'\n",
      " '|   bn1.bias             |   (64,)                |            |\\n'\n",
      " '|  layer1                |  0.148M                |  0.947G    |\\n'\n",
      " '|   layer1.0             |   73.984K              |   0.473G   |\\n'\n",
      " '|    layer1.0.conv1      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|   layer1.1             |   73.984K              |   0.473G   |\\n'\n",
      " '|    layer1.1.conv1      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|  layer2                |  0.526M                |  0.841G    |\\n'\n",
      " '|   layer2.0             |   0.23M                |   0.368G   |\\n'\n",
      " '|    layer2.0.conv1      |    73.728K             |    0.118G  |\\n'\n",
      " '|    layer2.0.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.0.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.downsample |    8.448K              |    13.517M |\\n'\n",
      " '|   layer2.1             |   0.295M               |   0.473G   |\\n'\n",
      " '|    layer2.1.conv1      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|  layer3                |  2.1M                  |  0.84G     |\\n'\n",
      " '|   layer3.0             |   0.919M               |   0.368G   |\\n'\n",
      " '|    layer3.0.conv1      |    0.295M              |    0.118G  |\\n'\n",
      " '|    layer3.0.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.0.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.downsample |    33.28K              |    13.312M |\\n'\n",
      " '|   layer3.1             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.1.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|  layer4                |  8.394M                |  0.839G    |\\n'\n",
      " '|   layer4.0             |   3.673M               |   0.367G   |\\n'\n",
      " '|    layer4.0.conv1      |    1.18M               |    0.118G  |\\n'\n",
      " '|    layer4.0.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.0.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.downsample |    0.132M              |    13.21M  |\\n'\n",
      " '|   layer4.1             |   4.721M               |   0.472G   |\\n'\n",
      " '|    layer4.1.conv1      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn2        |    1.024K              |    0.102M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet18.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet34.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 21.285M                | 7.491G     |\\n'\n",
      " '|  conv1                 |  9.408K                |  0.241G    |\\n'\n",
      " '|   conv1.weight         |   (64, 3, 7, 7)        |            |\\n'\n",
      " '|  bn1                   |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight           |   (64,)                |            |\\n'\n",
      " '|   bn1.bias             |   (64,)                |            |\\n'\n",
      " '|  layer1                |  0.222M                |  1.42G     |\\n'\n",
      " '|   layer1.0             |   73.984K              |   0.473G   |\\n'\n",
      " '|    layer1.0.conv1      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|   layer1.1             |   73.984K              |   0.473G   |\\n'\n",
      " '|    layer1.1.conv1      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|   layer1.2             |   73.984K              |   0.473G   |\\n'\n",
      " '|    layer1.2.conv1      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|  layer2                |  1.116M                |  1.786G    |\\n'\n",
      " '|   layer2.0             |   0.23M                |   0.368G   |\\n'\n",
      " '|    layer2.0.conv1      |    73.728K             |    0.118G  |\\n'\n",
      " '|    layer2.0.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.0.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.downsample |    8.448K              |    13.517M |\\n'\n",
      " '|   layer2.1             |   0.295M               |   0.473G   |\\n'\n",
      " '|    layer2.1.conv1      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|   layer2.2             |   0.295M               |   0.473G   |\\n'\n",
      " '|    layer2.2.conv1      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.2.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.2.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.2.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|   layer2.3             |   0.295M               |   0.473G   |\\n'\n",
      " '|    layer2.3.conv1      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.3.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.3.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.3.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|  layer3                |  6.822M                |  2.729G    |\\n'\n",
      " '|   layer3.0             |   0.919M               |   0.368G   |\\n'\n",
      " '|    layer3.0.conv1      |    0.295M              |    0.118G  |\\n'\n",
      " '|    layer3.0.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.0.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.downsample |    33.28K              |    13.312M |\\n'\n",
      " '|   layer3.1             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.1.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|   layer3.2             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.2.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.2.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.2.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.2.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|   layer3.3             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.3.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.3.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.3.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.3.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|   layer3.4             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.4.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.4.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.4.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.4.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|   layer3.5             |   1.181M               |   0.472G   |\\n'\n",
      " '|    layer3.5.conv1      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.5.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.5.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.5.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|  layer4                |  13.114M               |  1.311G    |\\n'\n",
      " '|   layer4.0             |   3.673M               |   0.367G   |\\n'\n",
      " '|    layer4.0.conv1      |    1.18M               |    0.118G  |\\n'\n",
      " '|    layer4.0.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.0.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.downsample |    0.132M              |    13.21M  |\\n'\n",
      " '|   layer4.1             |   4.721M               |   0.472G   |\\n'\n",
      " '|    layer4.1.conv1      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|   layer4.2             |   4.721M               |   0.472G   |\\n'\n",
      " '|    layer4.2.conv1      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.2.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.2.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.2.bn2        |    1.024K              |    0.102M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet34.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 256, 56, 56])\n",
      "torch.Size([1, 512, 28, 28])\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet50.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 64, 112, 112])\n",
    "    #  torch.Size([1, 256, 56, 56])\n",
    "    #  torch.Size([1, 512, 28, 28])\n",
    "    #  torch.Size([1, 1024, 14, 14])\n",
    "    #  torch.Size([1, 2048, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 23.508M                | 8.386G     |\\n'\n",
      " '|  conv1                 |  9.408K                |  0.241G    |\\n'\n",
      " '|   conv1.weight         |   (64, 3, 7, 7)        |            |\\n'\n",
      " '|  bn1                   |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight           |   (64,)                |            |\\n'\n",
      " '|   bn1.bias             |   (64,)                |            |\\n'\n",
      " '|  layer1                |  0.216M                |  1.381G    |\\n'\n",
      " '|   layer1.0             |   75.008K              |   0.48G    |\\n'\n",
      " '|    layer1.0.conv1      |    4.096K              |    26.214M |\\n'\n",
      " '|    layer1.0.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.0.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|    layer1.0.downsample |    16.896K             |    0.108G  |\\n'\n",
      " '|   layer1.1             |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.1.conv1      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.2             |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.2.conv1      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|  layer2                |  1.22M                 |  2.11G     |\\n'\n",
      " '|   layer2.0             |   0.379M               |   0.766G   |\\n'\n",
      " '|    layer2.0.conv1      |    32.768K             |    0.21G   |\\n'\n",
      " '|    layer2.0.bn1        |    0.256K              |    1.638M  |\\n'\n",
      " '|    layer2.0.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.0.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.0.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|    layer2.0.downsample |    0.132M              |    0.211G  |\\n'\n",
      " '|   layer2.1             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.1.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.1.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.1.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|   layer2.2             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.2.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.2.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.2.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.2.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.2.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.2.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|   layer2.3             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.3.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.3.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.3.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.3.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.3.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.3.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|  layer3                |  7.098M                |  2.997G    |\\n'\n",
      " '|   layer3.0             |   1.512M               |   0.763G   |\\n'\n",
      " '|    layer3.0.conv1      |    0.131M              |    0.21G   |\\n'\n",
      " '|    layer3.0.bn1        |    0.512K              |    0.819M  |\\n'\n",
      " '|    layer3.0.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.0.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.0.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|    layer3.0.downsample |    0.526M              |    0.211G  |\\n'\n",
      " '|   layer3.1             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.1.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.1.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.1.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.2             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.2.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.2.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.2.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.2.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.2.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.2.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.3             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.3.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.3.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.3.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.3.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.3.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.3.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.4             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.4.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.4.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.4.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.4.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.4.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.4.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.5             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.5.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.5.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.5.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.5.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.5.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.5.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|  layer4                |  14.965M               |  1.654G    |\\n'\n",
      " '|   layer4.0             |   6.04M                |   0.762G   |\\n'\n",
      " '|    layer4.0.conv1      |    0.524M              |    0.21G   |\\n'\n",
      " '|    layer4.0.bn1        |    1.024K              |    0.41M   |\\n'\n",
      " '|    layer4.0.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.0.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.0.bn3        |    4.096K              |    0.41M   |\\n'\n",
      " '|    layer4.0.downsample |    2.101M              |    0.21G   |\\n'\n",
      " '|   layer4.1             |   4.463M               |   0.446G   |\\n'\n",
      " '|    layer4.1.conv1      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.1.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.1.bn3        |    4.096K              |    0.41M   |\\n'\n",
      " '|   layer4.2             |   4.463M               |   0.446G   |\\n'\n",
      " '|    layer4.2.conv1      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.2.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.2.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.2.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.2.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.2.bn3        |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet50.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021ab83fea074d27805564e3f917dabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 256, 56, 56])\n",
      "torch.Size([1, 512, 28, 28])\n",
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet101.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 42.5M                  | 15.983G    |\\n'\n",
      " '|  conv1                 |  9.408K                |  0.241G    |\\n'\n",
      " '|   conv1.weight         |   (64, 3, 7, 7)        |            |\\n'\n",
      " '|  bn1                   |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight           |   (64,)                |            |\\n'\n",
      " '|   bn1.bias             |   (64,)                |            |\\n'\n",
      " '|  layer1                |  0.216M                |  1.381G    |\\n'\n",
      " '|   layer1.0             |   75.008K              |   0.48G    |\\n'\n",
      " '|    layer1.0.conv1      |    4.096K              |    26.214M |\\n'\n",
      " '|    layer1.0.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.0.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|    layer1.0.downsample |    16.896K             |    0.108G  |\\n'\n",
      " '|   layer1.1             |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.1.conv1      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.2             |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.2.conv1      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn1        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv2      |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn2        |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv3      |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn3        |    0.512K              |    3.277M  |\\n'\n",
      " '|  layer2                |  1.22M                 |  2.11G     |\\n'\n",
      " '|   layer2.0             |   0.379M               |   0.766G   |\\n'\n",
      " '|    layer2.0.conv1      |    32.768K             |    0.21G   |\\n'\n",
      " '|    layer2.0.bn1        |    0.256K              |    1.638M  |\\n'\n",
      " '|    layer2.0.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.0.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.0.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.0.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|    layer2.0.downsample |    0.132M              |    0.211G  |\\n'\n",
      " '|   layer2.1             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.1.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.1.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.1.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.1.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.1.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|   layer2.2             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.2.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.2.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.2.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.2.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.2.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.2.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|   layer2.3             |   0.28M                |   0.448G   |\\n'\n",
      " '|    layer2.3.conv1      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.3.bn1        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.3.conv2      |    0.147M              |    0.236G  |\\n'\n",
      " '|    layer2.3.bn2        |    0.256K              |    0.41M   |\\n'\n",
      " '|    layer2.3.conv3      |    65.536K             |    0.105G  |\\n'\n",
      " '|    layer2.3.bn3        |    1.024K              |    1.638M  |\\n'\n",
      " '|  layer3                |  26.09M                |  10.594G   |\\n'\n",
      " '|   layer3.0             |   1.512M               |   0.763G   |\\n'\n",
      " '|    layer3.0.conv1      |    0.131M              |    0.21G   |\\n'\n",
      " '|    layer3.0.bn1        |    0.512K              |    0.819M  |\\n'\n",
      " '|    layer3.0.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.0.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.0.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.0.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|    layer3.0.downsample |    0.526M              |    0.211G  |\\n'\n",
      " '|   layer3.1             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.1.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.1.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.1.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.1.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.1.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.2             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.2.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.2.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.2.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.2.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.2.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.2.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.3             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.3.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.3.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.3.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.3.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.3.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.3.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.4             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.4.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.4.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.4.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.4.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.4.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.4.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.5             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.5.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.5.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.5.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.5.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.5.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.5.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.6             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.6.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.6.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.6.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.6.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.6.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.6.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.7             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.7.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.7.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.7.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.7.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.7.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.7.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.8             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.8.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.8.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.8.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.8.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.8.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.8.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.9             |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.9.conv1      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.9.bn1        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.9.conv2      |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.9.bn2        |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.9.conv3      |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.9.bn3        |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.10            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.10.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.10.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.10.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.10.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.10.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.10.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.11            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.11.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.11.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.11.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.11.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.11.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.11.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.12            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.12.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.12.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.12.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.12.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.12.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.12.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.13            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.13.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.13.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.13.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.13.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.13.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.13.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.14            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.14.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.14.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.14.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.14.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.14.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.14.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.15            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.15.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.15.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.15.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.15.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.15.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.15.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.16            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.16.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.16.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.16.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.16.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.16.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.16.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.17            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.17.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.17.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.17.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.17.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.17.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.17.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.18            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.18.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.18.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.18.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.18.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.18.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.18.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.19            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.19.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.19.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.19.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.19.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.19.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.19.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.20            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.20.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.20.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.20.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.20.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.20.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.20.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.21            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.21.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.21.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.21.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.21.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.21.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.21.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|   layer3.22            |   1.117M               |   0.447G   |\\n'\n",
      " '|    layer3.22.conv1     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.22.bn1       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.22.conv2     |    0.59M               |    0.236G  |\\n'\n",
      " '|    layer3.22.bn2       |    0.512K              |    0.205M  |\\n'\n",
      " '|    layer3.22.conv3     |    0.262M              |    0.105G  |\\n'\n",
      " '|    layer3.22.bn3       |    2.048K              |    0.819M  |\\n'\n",
      " '|  layer4                |  14.965M               |  1.654G    |\\n'\n",
      " '|   layer4.0             |   6.04M                |   0.762G   |\\n'\n",
      " '|    layer4.0.conv1      |    0.524M              |    0.21G   |\\n'\n",
      " '|    layer4.0.bn1        |    1.024K              |    0.41M   |\\n'\n",
      " '|    layer4.0.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.0.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.0.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.0.bn3        |    4.096K              |    0.41M   |\\n'\n",
      " '|    layer4.0.downsample |    2.101M              |    0.21G   |\\n'\n",
      " '|   layer4.1             |   4.463M               |   0.446G   |\\n'\n",
      " '|    layer4.1.conv1      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.1.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.1.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.1.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.1.bn3        |    4.096K              |    0.41M   |\\n'\n",
      " '|   layer4.2             |   4.463M               |   0.446G   |\\n'\n",
      " '|    layer4.2.conv1      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.2.bn1        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.2.conv2      |    2.359M              |    0.236G  |\\n'\n",
      " '|    layer4.2.bn2        |    1.024K              |    0.102M  |\\n'\n",
      " '|    layer4.2.conv3      |    1.049M              |    0.105G  |\\n'\n",
      " '|    layer4.2.bn3        |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"resnet101.a1_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repvgg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170d8f86120439798198435028f8ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/36.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 112, 112])\n",
      "torch.Size([1, 48, 56, 56])\n",
      "torch.Size([1, 96, 28, 28])\n",
      "torch.Size([1, 192, 14, 14])\n",
      "torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 48, 112, 112])\n",
    "    #  torch.Size([1, 48, 56, 56])\n",
    "    #  torch.Size([1, 96, 28, 28])\n",
    "    #  torch.Size([1, 192, 14, 14])\n",
    "    #  torch.Size([1, 1280, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 7.828M                 | 3.102G     |\\n'\n",
      " '|  stem                       |  1.632K                |  41.779M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.392K               |   35.635M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.296K              |    33.178M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    96                  |    2.458M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.24K                |   6.144M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.144K              |    3.686M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    96                  |    2.458M  |\\n'\n",
      " '|  stages_0                   |  46.56K                |  0.298G    |\\n'\n",
      " '|   stages_0.0                |   23.232K              |   0.149G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    20.832K             |    0.133G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    2.4K                |    15.36M  |\\n'\n",
      " '|   stages_0.1                |   23.328K              |   0.149G   |\\n'\n",
      " '|    stages_0.1.identity      |    96                  |    0.614M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    20.832K             |    0.133G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    2.4K                |    15.36M  |\\n'\n",
      " '|  stages_1                   |  0.325M                |  0.519G    |\\n'\n",
      " '|   stages_1.0                |   46.464K              |   74.342M  |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    41.664K             |    66.662M |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    4.8K                |    7.68M   |\\n'\n",
      " '|   stages_1.1                |   92.736K              |   0.148G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.192K              |    0.307M  |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    83.136K             |    0.133G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    9.408K              |    15.053M |\\n'\n",
      " '|   stages_1.2                |   92.736K              |   0.148G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.192K              |    0.307M  |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    83.136K             |    0.133G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    9.408K              |    15.053M |\\n'\n",
      " '|   stages_1.3                |   92.736K              |   0.148G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.192K              |    0.307M  |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    83.136K             |    0.133G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    9.408K              |    15.053M |\\n'\n",
      " '|  stages_2                   |  4.992M                |  1.997G    |\\n'\n",
      " '|   stages_2.0                |   0.185M               |   74.035M  |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    0.166M              |    66.509M |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    18.816K             |    7.526M  |\\n'\n",
      " '|   stages_2.1                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.1.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.2                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.2.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.3                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.3.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.4                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.4.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.5                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.5.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.6                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.6.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.7                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.7.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.8                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.8.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.9                |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.9.identity      |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.10               |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.10.identity     |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.11               |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.11.identity     |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.12               |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.12.identity     |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    37.248K             |    14.899M |\\n'\n",
      " '|   stages_2.13               |   0.37M                |   0.148G   |\\n'\n",
      " '|    stages_2.13.identity     |    0.384K              |    0.154M  |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    0.332M              |    0.133G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    37.248K             |    14.899M |\\n'\n",
      " '|  stages_3.0                 |  2.463M                |  0.246G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   2.214M               |   0.221G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    2.212M              |    0.221G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    2.56K               |    0.256M  |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   0.248M               |   24.832M  |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    0.246M              |    24.576M |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    2.56K               |    0.256M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa6b0df623e481c97da12b8cb717529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/56.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 12.811M                | 5.382G     |\\n'\n",
      " '|  stem                       |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                   |  82.56K                |  0.528G    |\\n'\n",
      " '|   stages_0.0                |   41.216K              |   0.264G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|   stages_0.1                |   41.344K              |   0.265G   |\\n'\n",
      " '|    stages_0.1.identity      |    0.128K              |    0.819M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|  stages_1                   |  0.576M                |  0.922G    |\\n'\n",
      " '|   stages_1.0                |   82.432K              |   0.132G   |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    73.984K             |    0.118G  |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    8.448K              |    13.517M |\\n'\n",
      " '|   stages_1.1                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.2                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.3                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|  stages_2                   |  8.868M                |  3.547G    |\\n'\n",
      " '|   stages_2.0                |   0.329M               |   0.131G   |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    0.295M              |    0.118G  |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    33.28K              |    13.312M |\\n'\n",
      " '|   stages_2.1                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.1.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.2                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.2.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.3                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.3.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.4                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.4.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.5                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.5.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.6                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.6.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.7                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.7.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.8                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.8.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.9                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.9.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.10               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.10.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.11               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.11.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.12               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.12.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.13               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.13.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|  stages_3.0                 |  3.282M                |  0.328G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   2.952M               |   0.295G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    2.949M              |    0.295G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    2.56K               |    0.256M  |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   0.33M                |   33.024M  |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    0.328M              |    32.768M |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    2.56K               |    0.256M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a4ef7256d465cbde40477cffb4e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 384, 14, 14])\n",
      "torch.Size([1, 1408, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 26.802M                | 11.632G    |\\n'\n",
      " '|  stem                       |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                   |  0.155M                |  0.989G    |\\n'\n",
      " '|   stages_0.0                |   61.824K              |   0.396G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    55.488K             |    0.355G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    6.336K              |    40.55M  |\\n'\n",
      " '|   stages_0.1                |   92.736K              |   0.594G   |\\n'\n",
      " '|    stages_0.1.identity      |    0.192K              |    1.229M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    83.136K             |    0.532G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    9.408K              |    60.211M |\\n'\n",
      " '|  stages_1                   |  1.294M                |  2.071G    |\\n'\n",
      " '|   stages_1.0                |   0.185M               |   0.296G   |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    0.166M              |    0.266G  |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    18.816K             |    30.106M |\\n'\n",
      " '|   stages_1.1                |   0.37M                |   0.592G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    0.332M              |    0.531G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.2                |   0.37M                |   0.592G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    0.332M              |    0.531G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    37.248K             |    59.597M |\\n'\n",
      " '|   stages_1.3                |   0.37M                |   0.592G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.384K              |    0.614M  |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    0.332M              |    0.531G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    37.248K             |    59.597M |\\n'\n",
      " '|  stages_2                   |  19.938M               |  7.975G    |\\n'\n",
      " '|   stages_2.0                |   0.739M               |   0.296G   |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    0.664M              |    0.266G  |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    74.496K             |    29.798M |\\n'\n",
      " '|   stages_2.1                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.1.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.2                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.2.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.3                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.3.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.4                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.4.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.5                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.5.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.6                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.6.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.7                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.7.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.8                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.8.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.9                |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.9.identity      |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.10               |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.10.identity     |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.11               |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.11.identity     |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.12               |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.12.identity     |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    0.148M              |    59.29M  |\\n'\n",
      " '|   stages_2.13               |   1.477M               |   0.591G   |\\n'\n",
      " '|    stages_2.13.identity     |    0.768K              |    0.307M  |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    1.328M              |    0.531G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    0.148M              |    59.29M  |\\n'\n",
      " '|  stages_3.0                 |  5.412M                |  0.541G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   4.869M               |   0.487G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    4.866M              |    0.487G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    2.816K              |    0.282M  |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   0.543M               |   54.349M  |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    0.541M              |    54.067M |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    2.816K              |    0.282M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_a2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2579a3a296b4a828dfbf417f608f07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/63.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 14.537M                | 6.963G     |\\n'\n",
      " '|  stem                       |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                   |  0.165M                |  1.058G    |\\n'\n",
      " '|   stages_0.0                |   41.216K              |   0.264G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|   stages_0.1                |   41.344K              |   0.265G   |\\n'\n",
      " '|    stages_0.1.identity      |    0.128K              |    0.819M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|   stages_0.2                |   41.344K              |   0.265G   |\\n'\n",
      " '|    stages_0.2.identity      |    0.128K              |    0.819M  |\\n'\n",
      " '|    stages_0.2.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.2.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|   stages_0.3                |   41.344K              |   0.265G   |\\n'\n",
      " '|    stages_0.3.identity      |    0.128K              |    0.819M  |\\n'\n",
      " '|    stages_0.3.conv_kxk      |    36.992K             |    0.237G  |\\n'\n",
      " '|    stages_0.3.conv_1x1      |    4.224K              |    27.034M |\\n'\n",
      " '|  stages_1                   |  0.905M                |  1.449G    |\\n'\n",
      " '|   stages_1.0                |   82.432K              |   0.132G   |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    73.984K             |    0.118G  |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    8.448K              |    13.517M |\\n'\n",
      " '|   stages_1.1                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.2                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.3                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.4                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.4.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.4.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.4.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|   stages_1.5                |   0.165M               |   0.263G   |\\n'\n",
      " '|    stages_1.5.identity      |    0.256K              |    0.41M   |\\n'\n",
      " '|    stages_1.5.conv_kxk      |    0.148M              |    0.236G  |\\n'\n",
      " '|    stages_1.5.conv_1x1      |    16.64K              |    26.624M |\\n'\n",
      " '|  stages_2                   |  10.182M               |  4.073G    |\\n'\n",
      " '|   stages_2.0                |   0.329M               |   0.131G   |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    0.295M              |    0.118G  |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    33.28K              |    13.312M |\\n'\n",
      " '|   stages_2.1                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.1.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.2                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.2.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.3                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.3.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.4                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.4.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.5                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.5.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.6                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.6.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.7                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.7.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.8                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.8.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.9                |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.9.identity      |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.10               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.10.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.11               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.11.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.12               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.12.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.13               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.13.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.14               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.14.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.14.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.14.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|   stages_2.15               |   0.657M               |   0.263G   |\\n'\n",
      " '|    stages_2.15.identity     |    0.512K              |    0.205M  |\\n'\n",
      " '|    stages_2.15.conv_kxk     |    0.59M               |    0.236G  |\\n'\n",
      " '|    stages_2.15.conv_1x1     |    66.048K             |    26.419M |\\n'\n",
      " '|  stages_3.0                 |  3.282M                |  0.328G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   2.952M               |   0.295G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    2.949M              |    0.295G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    2.56K               |    0.256M  |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   0.33M                |   33.024M  |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    0.328M              |    32.768M |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    2.56K               |    0.256M  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_b1g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6fc7d857de437a92cc1644309ad1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/160M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b1g4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 37.917M                | 16.623G    |\\n'\n",
      " '|  stem                       |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                   |  0.33M                 |  2.115G    |\\n'\n",
      " '|   stages_0.0                |   82.432K              |   0.528G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    73.984K             |    0.473G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    8.448K              |    54.067M |\\n'\n",
      " '|   stages_0.1                |   41.728K              |   0.267G   |\\n'\n",
      " '|    stages_0.1.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    37.12K              |    0.238G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    4.352K              |    27.853M |\\n'\n",
      " '|   stages_0.2                |   0.165M               |   1.053G   |\\n'\n",
      " '|    stages_0.2.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.2.conv_kxk      |    0.148M              |    0.945G  |\\n'\n",
      " '|    stages_0.2.conv_1x1      |    16.64K              |    0.106G  |\\n'\n",
      " '|   stages_0.3                |   41.728K              |   0.267G   |\\n'\n",
      " '|    stages_0.3.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.3.conv_kxk      |    37.12K              |    0.238G  |\\n'\n",
      " '|    stages_0.3.conv_1x1      |    4.352K              |    27.853M |\\n'\n",
      " '|  stages_1                   |  2.139M                |  3.422G    |\\n'\n",
      " '|   stages_1.0                |   0.329M               |   0.526G   |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    0.295M              |    0.473G  |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    33.28K              |    53.248M |\\n'\n",
      " '|   stages_1.1                |   0.165M               |   0.265G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    0.148M              |    0.237G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    16.896K             |    27.034M |\\n'\n",
      " '|   stages_1.2                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.3                |   0.165M               |   0.265G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    0.148M              |    0.237G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    16.896K             |    27.034M |\\n'\n",
      " '|   stages_1.4                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.4.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.4.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.4.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.5                |   0.165M               |   0.265G   |\\n'\n",
      " '|    stages_1.5.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.5.conv_kxk      |    0.148M              |    0.237G  |\\n'\n",
      " '|    stages_1.5.conv_1x1      |    16.896K             |    27.034M |\\n'\n",
      " '|  stages_2                   |  24.952M               |  9.981G    |\\n'\n",
      " '|   stages_2.0                |   1.313M               |   0.525G   |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    1.181M              |    0.472G  |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    0.132M              |    52.838M |\\n'\n",
      " '|   stages_2.1                |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.1.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.2                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.2.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.3                |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.3.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.4                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.4.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.5                |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.5.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.6                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.6.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.7                |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.7.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.8                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.8.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.9                |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.9.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.10               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.10.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.11               |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.11.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.12               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.12.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.13               |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.13.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    66.56K              |    26.624M |\\n'\n",
      " '|   stages_2.14               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.14.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.14.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.14.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.15               |   0.658M               |   0.263G   |\\n'\n",
      " '|    stages_2.15.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.15.conv_kxk     |    0.591M              |    0.236G  |\\n'\n",
      " '|    stages_2.15.conv_1x1     |    66.56K              |    26.624M |\\n'\n",
      " '|  stages_3.0                 |  10.494M               |  1.049G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   9.441M               |   0.944G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    9.437M              |    0.944G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    4.096K              |    0.41M   |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   1.053M               |   0.105G   |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    1.049M              |    0.105G  |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b1g4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repvgg_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                      | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                       | 55.366M                | 26.846G    |\\n'\n",
      " '|  stem                       |  2.176K                |  55.706M   |\\n'\n",
      " '|   stem.conv_kxk             |   1.856K               |   47.514M  |\\n'\n",
      " '|    stem.conv_kxk.conv       |    1.728K              |    44.237M |\\n'\n",
      " '|    stem.conv_kxk.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|   stem.conv_1x1             |   0.32K                |   8.192M   |\\n'\n",
      " '|    stem.conv_1x1.conv       |    0.192K              |    4.915M  |\\n'\n",
      " '|    stem.conv_1x1.bn         |    0.128K              |    3.277M  |\\n'\n",
      " '|  stages_0                   |  0.576M                |  3.688G    |\\n'\n",
      " '|   stages_0.0                |   82.432K              |   0.528G   |\\n'\n",
      " '|    stages_0.0.conv_kxk      |    73.984K             |    0.473G  |\\n'\n",
      " '|    stages_0.0.conv_1x1      |    8.448K              |    54.067M |\\n'\n",
      " '|   stages_0.1                |   0.165M               |   1.053G   |\\n'\n",
      " '|    stages_0.1.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.1.conv_kxk      |    0.148M              |    0.945G  |\\n'\n",
      " '|    stages_0.1.conv_1x1      |    16.64K              |    0.106G  |\\n'\n",
      " '|   stages_0.2                |   0.165M               |   1.053G   |\\n'\n",
      " '|    stages_0.2.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.2.conv_kxk      |    0.148M              |    0.945G  |\\n'\n",
      " '|    stages_0.2.conv_1x1      |    16.64K              |    0.106G  |\\n'\n",
      " '|   stages_0.3                |   0.165M               |   1.053G   |\\n'\n",
      " '|    stages_0.3.identity      |    0.256K              |    1.638M  |\\n'\n",
      " '|    stages_0.3.conv_kxk      |    0.148M              |    0.945G  |\\n'\n",
      " '|    stages_0.3.conv_1x1      |    16.64K              |    0.106G  |\\n'\n",
      " '|  stages_1                   |  3.613M                |  5.781G    |\\n'\n",
      " '|   stages_1.0                |   0.329M               |   0.526G   |\\n'\n",
      " '|    stages_1.0.conv_kxk      |    0.295M              |    0.473G  |\\n'\n",
      " '|    stages_1.0.conv_1x1      |    33.28K              |    53.248M |\\n'\n",
      " '|   stages_1.1                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.1.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.1.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.1.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.2                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.2.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.2.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.2.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.3                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.3.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.3.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.3.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.4                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.4.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.4.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.4.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|   stages_1.5                |   0.657M               |   1.051G   |\\n'\n",
      " '|    stages_1.5.identity      |    0.512K              |    0.819M  |\\n'\n",
      " '|    stages_1.5.conv_kxk      |    0.59M               |    0.945G  |\\n'\n",
      " '|    stages_1.5.conv_1x1      |    66.048K             |    0.106G  |\\n'\n",
      " '|  stages_2                   |  40.68M                |  16.272G   |\\n'\n",
      " '|   stages_2.0                |   1.313M               |   0.525G   |\\n'\n",
      " '|    stages_2.0.conv_kxk      |    1.181M              |    0.472G  |\\n'\n",
      " '|    stages_2.0.conv_1x1      |    0.132M              |    52.838M |\\n'\n",
      " '|   stages_2.1                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.1.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.1.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.1.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.2                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.2.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.2.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.2.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.3                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.3.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.3.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.3.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.4                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.4.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.4.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.4.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.5                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.5.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.5.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.5.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.6                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.6.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.6.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.6.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.7                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.7.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.7.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.7.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.8                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.8.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.8.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.8.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.9                |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.9.identity      |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.9.conv_kxk      |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.9.conv_1x1      |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.10               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.10.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.10.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.10.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.11               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.11.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.11.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.11.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.12               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.12.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.12.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.12.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.13               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.13.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.13.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.13.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.14               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.14.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.14.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.14.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|   stages_2.15               |   2.625M               |   1.05G    |\\n'\n",
      " '|    stages_2.15.identity     |    1.024K              |    0.41M   |\\n'\n",
      " '|    stages_2.15.conv_kxk     |    2.36M               |    0.944G  |\\n'\n",
      " '|    stages_2.15.conv_1x1     |    0.263M              |    0.105G  |\\n'\n",
      " '|  stages_3.0                 |  10.494M               |  1.049G    |\\n'\n",
      " '|   stages_3.0.conv_kxk       |   9.441M               |   0.944G   |\\n'\n",
      " '|    stages_3.0.conv_kxk.conv |    9.437M              |    0.944G  |\\n'\n",
      " '|    stages_3.0.conv_kxk.bn   |    4.096K              |    0.41M   |\\n'\n",
      " '|   stages_3.0.conv_1x1       |   1.053M               |   0.105G   |\\n'\n",
      " '|    stages_3.0.conv_1x1.conv |    1.049M              |    0.105G  |\\n'\n",
      " '|    stages_3.0.conv_1x1.bn   |    4.096K              |    0.41M   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"repvgg_b1\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b23da227af4cf28e0b1e65126e41a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 40, 28, 28])\n",
      "torch.Size([1, 112, 14, 14])\n",
      "torch.Size([1, 320, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                 | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                  | 3.595M                 | 0.77G      |\\n'\n",
      " '|  conv_stem             |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight     |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                   |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight           |   (32,)                |            |\\n'\n",
      " '|   bn1.bias             |   (32,)                |            |\\n'\n",
      " '|  blocks                |  3.594M                |  0.747G    |\\n'\n",
      " '|   blocks.0.0           |   1.448K               |   22.938M  |\\n'\n",
      " '|    blocks.0.0.conv_dw  |    0.288K              |    7.373M  |\\n'\n",
      " '|    blocks.0.0.bn1      |    64                  |    1.638M  |\\n'\n",
      " '|    blocks.0.0.se       |    0.552K              |    0.512K  |\\n'\n",
      " '|    blocks.0.0.conv_pw  |    0.512K              |    13.107M |\\n'\n",
      " '|    blocks.0.0.bn2      |    32                  |    0.819M  |\\n'\n",
      " '|   blocks.1             |   16.714K              |   0.123G   |\\n'\n",
      " '|    blocks.1.0          |    6.004K              |    66.049M |\\n'\n",
      " '|    blocks.1.1          |    10.71K              |    56.527M |\\n'\n",
      " '|   blocks.2             |   46.64K               |   81.517M  |\\n'\n",
      " '|    blocks.2.0          |    15.35K              |    39.528M |\\n'\n",
      " '|    blocks.2.1          |    31.29K              |    41.989M |\\n'\n",
      " '|   blocks.3             |   0.243M               |   91.531M  |\\n'\n",
      " '|    blocks.3.0          |    37.13K              |    24.933M |\\n'\n",
      " '|    blocks.3.1          |    0.103M              |    33.299M |\\n'\n",
      " '|    blocks.3.2          |    0.103M              |    33.299M |\\n'\n",
      " '|   blocks.4             |   0.543M               |   0.179G   |\\n'\n",
      " '|    blocks.4.0          |    0.126M              |    42.541M |\\n'\n",
      " '|    blocks.4.1          |    0.209M              |    68.134M |\\n'\n",
      " '|    blocks.4.2          |    0.209M              |    68.134M |\\n'\n",
      " '|   blocks.5             |   2.026M               |   0.189G   |\\n'\n",
      " '|    blocks.5.0          |    0.262M              |    45.436M |\\n'\n",
      " '|    blocks.5.1          |    0.588M              |    47.727M |\\n'\n",
      " '|    blocks.5.2          |    0.588M              |    47.727M |\\n'\n",
      " '|    blocks.5.3          |    0.588M              |    47.727M |\\n'\n",
      " '|   blocks.6.0           |   0.717M               |   60.655M  |\\n'\n",
      " '|    blocks.6.0.conv_pw  |    0.221M              |    22.118M |\\n'\n",
      " '|    blocks.6.0.bn1      |    2.304K              |    0.23M   |\\n'\n",
      " '|    blocks.6.0.conv_dw  |    10.368K             |    1.037M  |\\n'\n",
      " '|    blocks.6.0.bn2      |    2.304K              |    0.23M   |\\n'\n",
      " '|    blocks.6.0.se       |    0.112M              |    0.111M  |\\n'\n",
      " '|    blocks.6.0.conv_pwl |    0.369M              |    36.864M |\\n'\n",
      " '|    blocks.6.0.bn3      |    0.64K               |    64K     |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b0\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073d39d23110478a84b020f94b947e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 40, 28, 28])\n",
      "torch.Size([1, 112, 14, 14])\n",
      "torch.Size([1, 320, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b1.ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 6.101M                 | 1.156G     |\\n'\n",
      " '|  conv_stem         |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight       |   (32,)                |            |\\n'\n",
      " '|   bn1.bias         |   (32,)                |            |\\n'\n",
      " '|  blocks            |  6.1M                  |  1.132G    |\\n'\n",
      " '|   blocks.0         |   2.06K                |   34.817M  |\\n'\n",
      " '|    blocks.0.0      |    1.448K              |    22.938M |\\n'\n",
      " '|    blocks.0.1      |    0.612K              |    11.879M |\\n'\n",
      " '|   blocks.1         |   27.424K              |   0.179G   |\\n'\n",
      " '|    blocks.1.0      |    6.004K              |    66.049M |\\n'\n",
      " '|    blocks.1.1      |    10.71K              |    56.527M |\\n'\n",
      " '|    blocks.1.2      |    10.71K              |    56.527M |\\n'\n",
      " '|   blocks.2         |   77.93K               |   0.124G   |\\n'\n",
      " '|    blocks.2.0      |    15.35K              |    39.528M |\\n'\n",
      " '|    blocks.2.1      |    31.29K              |    41.989M |\\n'\n",
      " '|    blocks.2.2      |    31.29K              |    41.989M |\\n'\n",
      " '|   blocks.3         |   0.346M               |   0.125G   |\\n'\n",
      " '|    blocks.3.0      |    37.13K              |    24.933M |\\n'\n",
      " '|    blocks.3.1      |    0.103M              |    33.299M |\\n'\n",
      " '|    blocks.3.2      |    0.103M              |    33.299M |\\n'\n",
      " '|    blocks.3.3      |    0.103M              |    33.299M |\\n'\n",
      " '|   blocks.4         |   0.752M               |   0.247G   |\\n'\n",
      " '|    blocks.4.0      |    0.126M              |    42.541M |\\n'\n",
      " '|    blocks.4.1      |    0.209M              |    68.134M |\\n'\n",
      " '|    blocks.4.2      |    0.209M              |    68.134M |\\n'\n",
      " '|    blocks.4.3      |    0.209M              |    68.134M |\\n'\n",
      " '|   blocks.5         |   2.614M               |   0.236G   |\\n'\n",
      " '|    blocks.5.0      |    0.262M              |    45.436M |\\n'\n",
      " '|    blocks.5.1      |    0.588M              |    47.727M |\\n'\n",
      " '|    blocks.5.2      |    0.588M              |    47.727M |\\n'\n",
      " '|    blocks.5.3      |    0.588M              |    47.727M |\\n'\n",
      " '|    blocks.5.4      |    0.588M              |    47.727M |\\n'\n",
      " '|   blocks.6         |   2.281M               |   0.186G   |\\n'\n",
      " '|    blocks.6.0      |    0.717M              |    60.655M |\\n'\n",
      " '|    blocks.6.1      |    1.564M              |    0.126G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b1.ft_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab23d06178f44969c90ad1d4bc19869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/36.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 128, 128])\n",
      "torch.Size([1, 24, 64, 64])\n",
      "torch.Size([1, 48, 32, 32])\n",
      "torch.Size([1, 120, 16, 16])\n",
      "torch.Size([1, 352, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 7.203M                 | 1.331G     |\\n'\n",
      " '|  conv_stem         |  0.864K                |  22.118M   |\\n'\n",
      " '|   conv_stem.weight |   (32, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  64                    |  1.638M    |\\n'\n",
      " '|   bn1.weight       |   (32,)                |            |\\n'\n",
      " '|   bn1.bias         |   (32,)                |            |\\n'\n",
      " '|  blocks            |  7.202M                |  1.307G    |\\n'\n",
      " '|   blocks.0         |   2.06K                |   34.817M  |\\n'\n",
      " '|    blocks.0.0      |    1.448K              |    22.938M |\\n'\n",
      " '|    blocks.0.1      |    0.612K              |    11.879M |\\n'\n",
      " '|   blocks.1         |   27.424K              |   0.179G   |\\n'\n",
      " '|    blocks.1.0      |    6.004K              |    66.049M |\\n'\n",
      " '|    blocks.1.1      |    10.71K              |    56.527M |\\n'\n",
      " '|    blocks.1.2      |    10.71K              |    56.527M |\\n'\n",
      " '|   blocks.2         |   0.103M               |   0.157G   |\\n'\n",
      " '|    blocks.2.0      |    16.518K             |    41.397M |\\n'\n",
      " '|    blocks.2.1      |    43.308K             |    57.761M |\\n'\n",
      " '|    blocks.2.2      |    43.308K             |    57.761M |\\n'\n",
      " '|   blocks.3         |   0.422M               |   0.155G   |\\n'\n",
      " '|    blocks.3.0      |    50.3K               |    34.522M |\\n'\n",
      " '|    blocks.3.1      |    0.124M              |    40.01M  |\\n'\n",
      " '|    blocks.3.2      |    0.124M              |    40.01M  |\\n'\n",
      " '|    blocks.3.3      |    0.124M              |    40.01M  |\\n'\n",
      " '|   blocks.4         |   0.863M               |   0.283G   |\\n'\n",
      " '|    blocks.4.0      |    0.149M              |    50.174M |\\n'\n",
      " '|    blocks.4.1      |    0.238M              |    77.611M |\\n'\n",
      " '|    blocks.4.2      |    0.238M              |    77.611M |\\n'\n",
      " '|    blocks.4.3      |    0.238M              |    77.611M |\\n'\n",
      " '|   blocks.5         |   3.049M               |   0.275G   |\\n'\n",
      " '|    blocks.5.0      |    0.301M              |    52.141M |\\n'\n",
      " '|    blocks.5.1      |    0.687M              |    55.707M |\\n'\n",
      " '|    blocks.5.2      |    0.687M              |    55.707M |\\n'\n",
      " '|    blocks.5.3      |    0.687M              |    55.707M |\\n'\n",
      " '|    blocks.5.4      |    0.687M              |    55.707M |\\n'\n",
      " '|   blocks.6         |   2.736M               |   0.224G   |\\n'\n",
      " '|    blocks.6.0      |    0.847M              |    71.711M |\\n'\n",
      " '|    blocks.6.1      |    1.889M              |    0.152G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b2\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0409baa37bca46e3a60db63fde450d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 144, 144])\n",
      "torch.Size([1, 32, 72, 72])\n",
      "torch.Size([1, 48, 36, 36])\n",
      "torch.Size([1, 136, 18, 18])\n",
      "torch.Size([1, 384, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b3\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 10.103M                | 1.953G     |\\n'\n",
      " '|  conv_stem         |  1.08K                 |  27.648M   |\\n'\n",
      " '|   conv_stem.weight |   (40, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  80                    |  2.048M    |\\n'\n",
      " '|   bn1.weight       |   (40,)                |            |\\n'\n",
      " '|   bn1.bias         |   (40,)                |            |\\n'\n",
      " '|  blocks            |  10.102M               |  1.924G    |\\n'\n",
      " '|   blocks.0         |   3.504K               |   59.803M  |\\n'\n",
      " '|    blocks.0.0      |    2.298K              |    37.07M  |\\n'\n",
      " '|    blocks.0.1      |    1.206K              |    22.733M |\\n'\n",
      " '|   blocks.1         |   48.118K              |   0.326G   |\\n'\n",
      " '|    blocks.1.0      |    11.878K             |    0.136G  |\\n'\n",
      " '|    blocks.1.1      |    18.12K              |    95.03M  |\\n'\n",
      " '|    blocks.1.2      |    18.12K              |    95.03M  |\\n'\n",
      " '|   blocks.2         |   0.111M               |   0.18G    |\\n'\n",
      " '|    blocks.2.0      |    24.296K             |    64.976M |\\n'\n",
      " '|    blocks.2.1      |    43.308K             |    57.761M |\\n'\n",
      " '|    blocks.2.2      |    43.308K             |    57.761M |\\n'\n",
      " '|   blocks.3         |   0.639M               |   0.225G   |\\n'\n",
      " '|    blocks.3.0      |    52.62K              |    35.45M  |\\n'\n",
      " '|    blocks.3.1      |    0.147M              |    47.336M |\\n'\n",
      " '|    blocks.3.2      |    0.147M              |    47.336M |\\n'\n",
      " '|    blocks.3.3      |    0.147M              |    47.336M |\\n'\n",
      " '|    blocks.3.4      |    0.147M              |    47.336M |\\n'\n",
      " '|   blocks.4         |   1.388M               |   0.454G   |\\n'\n",
      " '|    blocks.4.0      |    0.179M              |    60.271M |\\n'\n",
      " '|    blocks.4.1      |    0.302M              |    98.411M |\\n'\n",
      " '|    blocks.4.2      |    0.302M              |    98.411M |\\n'\n",
      " '|    blocks.4.3      |    0.302M              |    98.411M |\\n'\n",
      " '|    blocks.4.4      |    0.302M              |    98.411M |\\n'\n",
      " '|   blocks.5         |   4.629M               |   0.41G    |\\n'\n",
      " '|    blocks.5.0      |    0.381M              |    66.279M |\\n'\n",
      " '|    blocks.5.1      |    0.85M               |    68.833M |\\n'\n",
      " '|    blocks.5.2      |    0.85M               |    68.833M |\\n'\n",
      " '|    blocks.5.3      |    0.85M               |    68.833M |\\n'\n",
      " '|    blocks.5.4      |    0.85M               |    68.833M |\\n'\n",
      " '|    blocks.5.5      |    0.85M               |    68.833M |\\n'\n",
      " '|   blocks.6         |   3.284M               |   0.268G   |\\n'\n",
      " '|    blocks.6.0      |    1.039M              |    87.795M |\\n'\n",
      " '|    blocks.6.1      |    2.245M              |    0.18G   |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b3\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ad3af28e904ef690188a56fce6e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 160, 160])\n",
      "torch.Size([1, 32, 80, 80])\n",
      "torch.Size([1, 56, 40, 40])\n",
      "torch.Size([1, 160, 20, 20])\n",
      "torch.Size([1, 448, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 16.742M                | 3.051G     |\\n'\n",
      " '|  conv_stem         |  1.296K                |  33.178M   |\\n'\n",
      " '|   conv_stem.weight |   (48, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  96                    |  2.458M    |\\n'\n",
      " '|   bn1.weight       |   (48,)                |            |\\n'\n",
      " '|   bn1.bias         |   (48,)                |            |\\n'\n",
      " '|  blocks            |  16.741M               |  3.015G    |\\n'\n",
      " '|   blocks.0         |   4.146K               |   66.971M  |\\n'\n",
      " '|    blocks.0.0      |    2.94K               |    44.238M |\\n'\n",
      " '|    blocks.0.1      |    1.206K              |    22.733M |\\n'\n",
      " '|   blocks.1         |   66.238K              |   0.421G   |\\n'\n",
      " '|    blocks.1.0      |    11.878K             |    0.136G  |\\n'\n",
      " '|    blocks.1.1      |    18.12K              |    95.03M  |\\n'\n",
      " '|    blocks.1.2      |    18.12K              |    95.03M  |\\n'\n",
      " '|    blocks.1.3      |    18.12K              |    95.03M  |\\n'\n",
      " '|   blocks.2         |   0.198M               |   0.295G   |\\n'\n",
      " '|    blocks.2.0      |    25.848K             |    67.459M |\\n'\n",
      " '|    blocks.2.1      |    57.246K             |    75.99M  |\\n'\n",
      " '|    blocks.2.2      |    57.246K             |    75.99M  |\\n'\n",
      " '|    blocks.2.3      |    57.246K             |    75.99M  |\\n'\n",
      " '|   blocks.3         |   1.06M                |   0.367G   |\\n'\n",
      " '|    blocks.3.0      |    70.798K             |    47.811M |\\n'\n",
      " '|    blocks.3.1      |    0.198M              |    63.833M |\\n'\n",
      " '|    blocks.3.2      |    0.198M              |    63.833M |\\n'\n",
      " '|    blocks.3.3      |    0.198M              |    63.833M |\\n'\n",
      " '|    blocks.3.4      |    0.198M              |    63.833M |\\n'\n",
      " '|    blocks.3.5      |    0.198M              |    63.833M |\\n'\n",
      " '|   blocks.4         |   2.307M               |   0.752G   |\\n'\n",
      " '|    blocks.4.0      |    0.241M              |    81.074M |\\n'\n",
      " '|    blocks.4.1      |    0.413M              |    0.134G  |\\n'\n",
      " '|    blocks.4.2      |    0.413M              |    0.134G  |\\n'\n",
      " '|    blocks.4.3      |    0.413M              |    0.134G  |\\n'\n",
      " '|    blocks.4.4      |    0.413M              |    0.134G  |\\n'\n",
      " '|    blocks.4.5      |    0.413M              |    0.134G  |\\n'\n",
      " '|   blocks.5         |   8.636M               |   0.748G   |\\n'\n",
      " '|    blocks.5.0      |    0.521M              |    91.043M |\\n'\n",
      " '|    blocks.5.1      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.2      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.3      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.4      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.5      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.6      |    1.159M              |    93.79M  |\\n'\n",
      " '|    blocks.5.7      |    1.159M              |    93.79M  |\\n'\n",
      " '|   blocks.6         |   4.47M                |   0.365G   |\\n'\n",
      " '|    blocks.6.0      |    1.421M              |    0.12G   |\\n'\n",
      " '|    blocks.6.1      |    3.049M              |    0.245G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b4\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnet_b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8031b876664d42bc825cc88d74f9599b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 224, 224])\n",
      "torch.Size([1, 40, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 176, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b5\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 27.288M                | 4.79G      |\\n'\n",
      " '|  conv_stem         |  1.296K                |  33.178M   |\\n'\n",
      " '|   conv_stem.weight |   (48, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  96                    |  2.458M    |\\n'\n",
      " '|   bn1.weight       |   (48,)                |            |\\n'\n",
      " '|   bn1.bias         |   (48,)                |            |\\n'\n",
      " '|  blocks            |  27.287M               |  4.754G    |\\n'\n",
      " '|   blocks.0         |   5.352K               |   89.704M  |\\n'\n",
      " '|    blocks.0.0      |    2.94K               |    44.238M |\\n'\n",
      " '|    blocks.0.1      |    1.206K              |    22.733M |\\n'\n",
      " '|    blocks.0.2      |    1.206K              |    22.733M |\\n'\n",
      " '|   blocks.1         |   0.123M               |   0.717G   |\\n'\n",
      " '|    blocks.1.0      |    13.046K             |    0.143G  |\\n'\n",
      " '|    blocks.1.1      |    27.45K              |    0.143G  |\\n'\n",
      " '|    blocks.1.2      |    27.45K              |    0.143G  |\\n'\n",
      " '|    blocks.1.3      |    27.45K              |    0.143G  |\\n'\n",
      " '|    blocks.1.4      |    27.45K              |    0.143G  |\\n'\n",
      " '|   blocks.2         |   0.33M                |   0.486G   |\\n'\n",
      " '|    blocks.2.0      |    37.098K             |    99.666M |\\n'\n",
      " '|    blocks.2.1      |    73.104K             |    96.678M |\\n'\n",
      " '|    blocks.2.2      |    73.104K             |    96.678M |\\n'\n",
      " '|    blocks.2.3      |    73.104K             |    96.678M |\\n'\n",
      " '|    blocks.2.4      |    73.104K             |    96.678M |\\n'\n",
      " '|   blocks.3         |   1.632M               |   0.559G   |\\n'\n",
      " '|    blocks.3.0      |    91.664K             |    62.015M |\\n'\n",
      " '|    blocks.3.1      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.3.2      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.3.3      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.3.4      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.3.5      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.3.6      |    0.257M              |    82.788M |\\n'\n",
      " '|   blocks.4         |   3.286M               |   1.069G   |\\n'\n",
      " '|    blocks.4.0      |    0.306M              |    0.102G  |\\n'\n",
      " '|    blocks.4.1      |    0.497M              |    0.161G  |\\n'\n",
      " '|    blocks.4.2      |    0.497M              |    0.161G  |\\n'\n",
      " '|    blocks.4.3      |    0.497M              |    0.161G  |\\n'\n",
      " '|    blocks.4.4      |    0.497M              |    0.161G  |\\n'\n",
      " '|    blocks.4.5      |    0.497M              |    0.161G  |\\n'\n",
      " '|    blocks.4.6      |    0.497M              |    0.161G  |\\n'\n",
      " '|   blocks.5         |   12.165M              |   1.043G   |\\n'\n",
      " '|    blocks.5.0      |    0.632M              |    0.11G   |\\n'\n",
      " '|    blocks.5.1      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.2      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.3      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.4      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.5      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.6      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.7      |    1.442M              |    0.117G  |\\n'\n",
      " '|    blocks.5.8      |    1.442M              |    0.117G  |\\n'\n",
      " '|   blocks.6         |   9.745M               |   0.79G    |\\n'\n",
      " '|    blocks.6.0      |    1.792M              |    0.152G  |\\n'\n",
      " '|    blocks.6.1      |    3.976M              |    0.319G  |\\n'\n",
      " '|    blocks.6.2      |    3.976M              |    0.319G  |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b5\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnetv2_rw_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eda02e9941f411db64ad819bad86817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/55.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 112, 112])\n",
      "torch.Size([1, 40, 56, 56])\n",
      "torch.Size([1, 48, 28, 28])\n",
      "torch.Size([1, 128, 14, 14])\n",
      "torch.Size([1, 208, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnetv2_rw_t.ra2_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 24, 112, 112])\n",
    "    #  torch.Size([1, 40, 56, 56])\n",
    "    #  torch.Size([1, 48, 28, 28])\n",
    "    #  torch.Size([1, 128, 14, 14])\n",
    "    #  torch.Size([1, 208, 7, 7])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 12.409M                | 3.918G     |\\n'\n",
      " '|  conv_stem         |  0.648K                |  16.589M   |\\n'\n",
      " '|   conv_stem.weight |   (24, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  48                    |  1.229M    |\\n'\n",
      " '|   bn1.weight       |   (24,)                |            |\\n'\n",
      " '|   bn1.bias         |   (24,)                |            |\\n'\n",
      " '|  blocks            |  12.409M               |  3.901G    |\\n'\n",
      " '|   blocks.0         |   10.464K              |   0.268G   |\\n'\n",
      " '|    blocks.0.0      |    5.232K              |    0.134G  |\\n'\n",
      " '|    blocks.0.1      |    5.232K              |    0.134G  |\\n'\n",
      " '|   blocks.1         |   0.218M               |   1.396G   |\\n'\n",
      " '|    blocks.1.0      |    24.848K             |    0.159G  |\\n'\n",
      " '|    blocks.1.1      |    64.4K               |    0.412G  |\\n'\n",
      " '|    blocks.1.2      |    64.4K               |    0.412G  |\\n'\n",
      " '|    blocks.1.3      |    64.4K               |    0.412G  |\\n'\n",
      " '|   blocks.2         |   0.344M               |   0.55G    |\\n'\n",
      " '|    blocks.2.0      |    65.696K             |    0.105G  |\\n'\n",
      " '|    blocks.2.1      |    92.64K              |    0.148G  |\\n'\n",
      " '|    blocks.2.2      |    92.64K              |    0.148G  |\\n'\n",
      " '|    blocks.2.3      |    92.64K              |    0.148G  |\\n'\n",
      " '|   blocks.3         |   0.608M               |   0.209G   |\\n'\n",
      " '|    blocks.3.0      |    36.7K               |    24.28M  |\\n'\n",
      " '|    blocks.3.1      |    0.114M              |    36.879M |\\n'\n",
      " '|    blocks.3.2      |    0.114M              |    36.879M |\\n'\n",
      " '|    blocks.3.3      |    0.114M              |    36.879M |\\n'\n",
      " '|    blocks.3.4      |    0.114M              |    36.879M |\\n'\n",
      " '|    blocks.3.5      |    0.114M              |    36.879M |\\n'\n",
      " '|   blocks.4         |   2.241M               |   0.724G   |\\n'\n",
      " '|    blocks.4.0      |    0.186M              |    61.287M |\\n'\n",
      " '|    blocks.4.1      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.2      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.3      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.4      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.5      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.6      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.7      |    0.257M              |    82.788M |\\n'\n",
      " '|    blocks.4.8      |    0.257M              |    82.788M |\\n'\n",
      " '|   blocks.5         |   8.988M               |   0.755G   |\\n'\n",
      " '|    blocks.5.0      |    0.318M              |    56.846M |\\n'\n",
      " '|    blocks.5.1      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.2      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.3      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.4      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.5      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.6      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.7      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.8      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.9      |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.10     |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.11     |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.12     |    0.667M              |    53.711M |\\n'\n",
      " '|    blocks.5.13     |    0.667M              |    53.711M |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnetv2_rw_t\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficientnetv2_rw_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052bcf367afa4c46bd824ce315a8389e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/96.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 144, 144])\n",
      "torch.Size([1, 48, 72, 72])\n",
      "torch.Size([1, 64, 36, 36])\n",
      "torch.Size([1, 160, 18, 18])\n",
      "torch.Size([1, 272, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen(\n",
    "        \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnetv2_rw_s.ra2_in1k\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 24, 144, 144])\n",
    "    #  torch.Size([1, 48, 72, 72])\n",
    "    #  torch.Size([1, 64, 36, 36])\n",
    "    #  torch.Size([1, 160, 18, 18])\n",
    "    #  torch.Size([1, 272, 9, 9])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-------------------|:-----------------------|:-----------|\\n'\n",
      " '| model              | 21.657M                | 6.004G     |\\n'\n",
      " '|  conv_stem         |  0.648K                |  16.589M   |\\n'\n",
      " '|   conv_stem.weight |   (24, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1               |  48                    |  1.229M    |\\n'\n",
      " '|   bn1.weight       |   (24,)                |            |\\n'\n",
      " '|   bn1.bias         |   (24,)                |            |\\n'\n",
      " '|  blocks            |  21.657M               |  5.986G    |\\n'\n",
      " '|   blocks.0         |   11.712K              |   0.3G     |\\n'\n",
      " '|    blocks.0.0      |    5.856K              |    0.15G   |\\n'\n",
      " '|    blocks.0.1      |    5.856K              |    0.15G   |\\n'\n",
      " '|   blocks.1         |   0.304M               |   1.943G   |\\n'\n",
      " '|    blocks.1.0      |    25.632K             |    0.164G  |\\n'\n",
      " '|    blocks.1.1      |    92.64K              |    0.593G  |\\n'\n",
      " '|    blocks.1.2      |    92.64K              |    0.593G  |\\n'\n",
      " '|    blocks.1.3      |    92.64K              |    0.593G  |\\n'\n",
      " '|   blocks.2         |   0.589M               |   0.943G   |\\n'\n",
      " '|    blocks.2.0      |    95.744K             |    0.153G  |\\n'\n",
      " '|    blocks.2.1      |    0.164M              |    0.263G  |\\n'\n",
      " '|    blocks.2.2      |    0.164M              |    0.263G  |\\n'\n",
      " '|    blocks.2.3      |    0.164M              |    0.263G  |\\n'\n",
      " '|   blocks.3         |   0.918M               |   0.318G   |\\n'\n",
      " '|    blocks.3.0      |    61.2K               |    41.378M |\\n'\n",
      " '|    blocks.3.1      |    0.171M              |    55.226M |\\n'\n",
      " '|    blocks.3.2      |    0.171M              |    55.226M |\\n'\n",
      " '|    blocks.3.3      |    0.171M              |    55.226M |\\n'\n",
      " '|    blocks.3.4      |    0.171M              |    55.226M |\\n'\n",
      " '|    blocks.3.5      |    0.171M              |    55.226M |\\n'\n",
      " '|   blocks.4         |   3.464M               |   1.117G   |\\n'\n",
      " '|    blocks.4.0      |    0.281M              |    92.644M |\\n'\n",
      " '|    blocks.4.1      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.2      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.3      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.4      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.5      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.6      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.7      |    0.398M              |    0.128G  |\\n'\n",
      " '|    blocks.4.8      |    0.398M              |    0.128G  |\\n'\n",
      " '|   blocks.5         |   16.371M              |   1.366G   |\\n'\n",
      " '|    blocks.5.0      |    0.506M              |    89.507M |\\n'\n",
      " '|    blocks.5.1      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.2      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.3      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.4      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.5      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.6      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.7      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.8      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.9      |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.10     |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.11     |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.12     |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.13     |    1.133M              |    91.179M |\\n'\n",
      " '|    blocks.5.14     |    1.133M              |    91.179M |')\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "import timm\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"efficientnetv2_rw_s\",\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c81e8fdfea4230be81fc2a882448ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 37.712M                | 16.632G    |\\n'\n",
      " '|  conv1                          |  1.728K                |  44.237M   |\\n'\n",
      " '|   conv1.weight                  |   (64, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                            |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn1.bias                      |   (64,)                |            |\\n'\n",
      " '|  conv2                          |  36.864K               |  0.236G    |\\n'\n",
      " '|   conv2.weight                  |   (64, 64, 3, 3)       |            |\\n'\n",
      " '|  bn2                            |  0.128K                |  0.819M    |\\n'\n",
      " '|   bn2.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn2.bias                      |   (64,)                |            |\\n'\n",
      " '|  layer1                         |  0.286M                |  1.832G    |\\n'\n",
      " '|   layer1.0                      |   75.008K              |   0.48G    |\\n'\n",
      " '|    layer1.0.conv1               |    4.096K              |    26.214M |\\n'\n",
      " '|    layer1.0.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.0.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|    layer1.0.downsample          |    16.896K             |    0.108G  |\\n'\n",
      " '|   layer1.1                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.1.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.2                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.2.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.3                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.3.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.3.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.3.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.3.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.3.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.3.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|  transition1                    |  0.208M                |  0.664G    |\\n'\n",
      " '|   transition1.0                 |   69.18K               |   0.443G   |\\n'\n",
      " '|    transition1.0.0              |    69.12K              |    0.442G  |\\n'\n",
      " '|    transition1.0.1              |    60                  |    0.384M  |\\n'\n",
      " '|   transition1.1.0               |   0.138M               |   0.221G   |\\n'\n",
      " '|    transition1.1.0.0            |    0.138M              |    0.221G  |\\n'\n",
      " '|    transition1.1.0.1            |    0.12K               |    0.192M  |\\n'\n",
      " '|  stage2.0                       |  0.344M                |  0.863G    |\\n'\n",
      " '|   stage2.0.branches             |   0.325M               |   0.834G   |\\n'\n",
      " '|    stage2.0.branches.0          |    65.28K              |    0.418G  |\\n'\n",
      " '|    stage2.0.branches.1          |    0.26M               |    0.416G  |\\n'\n",
      " '|   stage2.0.fuse_layers          |   18.18K               |   29.28M   |\\n'\n",
      " '|    stage2.0.fuse_layers.0.1     |    1.86K               |    3.168M  |\\n'\n",
      " '|    stage2.0.fuse_layers.1.0.0   |    16.32K              |    26.112M |\\n'\n",
      " '|  transition2.2.0                |  65.04K                |  26.016M   |\\n'\n",
      " '|   transition2.2.0.0             |   64.8K                |   25.92M   |\\n'\n",
      " '|    transition2.2.0.0.weight     |    (120, 60, 3, 3)     |            |\\n'\n",
      " '|   transition2.2.0.1             |   0.24K                |   96K      |\\n'\n",
      " '|    transition2.2.0.1.weight     |    (120,)              |            |\\n'\n",
      " '|    transition2.2.0.1.bias       |    (120,)              |            |\\n'\n",
      " '|  stage3                         |  5.997M                |  5.342G    |\\n'\n",
      " '|   stage3.0                      |   1.499M               |   1.336G   |\\n'\n",
      " '|    stage3.0.branches            |    1.364M              |    1.25G   |\\n'\n",
      " '|    stage3.0.fuse_layers         |    0.135M              |    86.088M |\\n'\n",
      " '|   stage3.1                      |   1.499M               |   1.336G   |\\n'\n",
      " '|    stage3.1.branches            |    1.364M              |    1.25G   |\\n'\n",
      " '|    stage3.1.fuse_layers         |    0.135M              |    86.088M |\\n'\n",
      " '|   stage3.2                      |   1.499M               |   1.336G   |\\n'\n",
      " '|    stage3.2.branches            |    1.364M              |    1.25G   |\\n'\n",
      " '|    stage3.2.fuse_layers         |    0.135M              |    86.088M |\\n'\n",
      " '|   stage3.3                      |   1.499M               |   1.336G   |\\n'\n",
      " '|    stage3.3.branches            |    1.364M              |    1.25G   |\\n'\n",
      " '|    stage3.3.fuse_layers         |    0.135M              |    86.088M |\\n'\n",
      " '|  transition3.3.0                |  0.26M                 |  25.968M   |\\n'\n",
      " '|   transition3.3.0.0             |   0.259M               |   25.92M   |\\n'\n",
      " '|    transition3.3.0.0.weight     |    (240, 120, 3, 3)    |            |\\n'\n",
      " '|   transition3.3.0.1             |   0.48K                |   48K      |\\n'\n",
      " '|    transition3.3.0.1.weight     |    (240,)              |            |\\n'\n",
      " '|    transition3.3.0.1.bias       |    (240,)              |            |\\n'\n",
      " '|  stage4                         |  18.615M               |  5.493G    |\\n'\n",
      " '|   stage4.0                      |   6.205M               |   1.831G   |\\n'\n",
      " '|    stage4.0.branches            |    5.515M              |    1.665G  |\\n'\n",
      " '|    stage4.0.fuse_layers         |    0.69M               |    0.166G  |\\n'\n",
      " '|   stage4.1                      |   6.205M               |   1.831G   |\\n'\n",
      " '|    stage4.1.branches            |    5.515M              |    1.665G  |\\n'\n",
      " '|    stage4.1.fuse_layers         |    0.69M               |    0.166G  |\\n'\n",
      " '|   stage4.2                      |   6.205M               |   1.831G   |\\n'\n",
      " '|    stage4.2.branches            |    5.515M              |    1.665G  |\\n'\n",
      " '|    stage4.2.fuse_layers         |    0.69M               |    0.166G  |\\n'\n",
      " '|  incre_modules                  |  1.549M                |  0.471G    |\\n'\n",
      " '|   incre_modules.0.0             |   18.752K              |   0.12G    |\\n'\n",
      " '|    incre_modules.0.0.conv1      |    0.96K               |    6.144M  |\\n'\n",
      " '|    incre_modules.0.0.bn1        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv2      |    9.216K              |    58.982M |\\n'\n",
      " '|    incre_modules.0.0.bn2        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv3      |    4.096K              |    26.214M |\\n'\n",
      " '|    incre_modules.0.0.bn3        |    0.256K              |    1.638M  |\\n'\n",
      " '|    incre_modules.0.0.downsample |    4.096K              |    26.214M |\\n'\n",
      " '|   incre_modules.1.0             |   73.728K              |   0.118G   |\\n'\n",
      " '|    incre_modules.1.0.conv1      |    3.84K               |    6.144M  |\\n'\n",
      " '|    incre_modules.1.0.bn1        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv2      |    36.864K             |    58.982M |\\n'\n",
      " '|    incre_modules.1.0.bn2        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv3      |    16.384K             |    26.214M |\\n'\n",
      " '|    incre_modules.1.0.bn3        |    0.512K              |    0.819M  |\\n'\n",
      " '|    incre_modules.1.0.downsample |    15.872K             |    25.395M |\\n'\n",
      " '|   incre_modules.2.0             |   0.292M               |   0.117G   |\\n'\n",
      " '|    incre_modules.2.0.conv1      |    15.36K              |    6.144M  |\\n'\n",
      " '|    incre_modules.2.0.bn1        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv2      |    0.147M              |    58.982M |\\n'\n",
      " '|    incre_modules.2.0.bn2        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv3      |    65.536K             |    26.214M |\\n'\n",
      " '|    incre_modules.2.0.bn3        |    1.024K              |    0.41M   |\\n'\n",
      " '|    incre_modules.2.0.downsample |    62.464K             |    24.986M |\\n'\n",
      " '|   incre_modules.3.0             |   1.164M               |   0.116G   |\\n'\n",
      " '|    incre_modules.3.0.conv1      |    61.44K              |    6.144M  |\\n'\n",
      " '|    incre_modules.3.0.bn1        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv2      |    0.59M               |    58.982M |\\n'\n",
      " '|    incre_modules.3.0.bn2        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv3      |    0.262M              |    26.214M |\\n'\n",
      " '|    incre_modules.3.0.bn3        |    2.048K              |    0.205M  |\\n'\n",
      " '|    incre_modules.3.0.downsample |    0.248M              |    24.781M |\\n'\n",
      " '|  downsamp_modules               |  6.199M                |  1.417G    |\\n'\n",
      " '|   downsamp_modules.0            |   0.296M               |   0.473G   |\\n'\n",
      " '|    downsamp_modules.0.0         |    0.295M              |    0.472G  |\\n'\n",
      " '|    downsamp_modules.0.1         |    0.512K              |    0.819M  |\\n'\n",
      " '|   downsamp_modules.1            |   1.181M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.1.0         |    1.18M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.1.1         |    1.024K              |    0.41M   |\\n'\n",
      " '|   downsamp_modules.2            |   4.722M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.2.0         |    4.72M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.2.1         |    2.048K              |    0.205M  |\\n'\n",
      " '|  final_layer                    |  2.103M                |  0.21G     |\\n'\n",
      " '|   final_layer.0                 |   2.099M               |   0.21G    |\\n'\n",
      " '|    final_layer.0.weight         |    (2048, 1024, 1, 1)  |            |\\n'\n",
      " '|    final_layer.0.bias           |    (2048,)             |            |\\n'\n",
      " '|   final_layer.1                 |   4.096K               |   0.41M    |\\n'\n",
      " '|    final_layer.1.weight         |    (2048,)             |            |\\n'\n",
      " '|    final_layer.1.bias           |    (2048,)             |            |\\n'\n",
      " '|  classifier                     |  2.049M                |  2.048M    |\\n'\n",
      " '|   classifier.weight             |   (1000, 2048)         |            |\\n'\n",
      " '|   classifier.bias               |   (1000,)              |            |\\n'\n",
      " '|  global_pool.pool               |                        |  0.205M    |')\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = timm.create_model(\"hrnet_w30\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 21.299M                | 8.809G     |\\n'\n",
      " '|  conv1                          |  1.728K                |  44.237M   |\\n'\n",
      " '|   conv1.weight                  |   (64, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                            |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn1.bias                      |   (64,)                |            |\\n'\n",
      " '|  conv2                          |  36.864K               |  0.236G    |\\n'\n",
      " '|   conv2.weight                  |   (64, 64, 3, 3)       |            |\\n'\n",
      " '|  bn2                            |  0.128K                |  0.819M    |\\n'\n",
      " '|   bn2.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn2.bias                      |   (64,)                |            |\\n'\n",
      " '|  layer1                         |  0.286M                |  1.832G    |\\n'\n",
      " '|   layer1.0                      |   75.008K              |   0.48G    |\\n'\n",
      " '|    layer1.0.conv1               |    4.096K              |    26.214M |\\n'\n",
      " '|    layer1.0.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.0.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|    layer1.0.downsample          |    16.896K             |    0.108G  |\\n'\n",
      " '|   layer1.1                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.1.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.2                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.2.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.2.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.2.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.2.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|   layer1.3                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.3.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.3.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.3.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.3.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.3.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.3.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|  transition1                    |  0.125M                |  0.398G    |\\n'\n",
      " '|   transition1.0                 |   41.508K              |   0.266G   |\\n'\n",
      " '|    transition1.0.0              |    41.472K             |    0.265G  |\\n'\n",
      " '|    transition1.0.1              |    36                  |    0.23M   |\\n'\n",
      " '|   transition1.1.0               |   83.016K              |   0.133G   |\\n'\n",
      " '|    transition1.1.0.0            |    82.944K             |    0.133G  |\\n'\n",
      " '|    transition1.1.0.1            |    72                  |    0.115M  |\\n'\n",
      " '|  stage2.0                       |  0.124M                |  0.312G    |\\n'\n",
      " '|   stage2.0.branches             |   0.118M               |   0.301G   |\\n'\n",
      " '|    stage2.0.branches.0          |    23.616K             |    0.151G  |\\n'\n",
      " '|    stage2.0.branches.1          |    93.888K             |    0.15G   |\\n'\n",
      " '|   stage2.0.fuse_layers          |   6.588K               |   10.656M  |\\n'\n",
      " '|    stage2.0.fuse_layers.0.1     |    0.684K              |    1.21M   |\\n'\n",
      " '|    stage2.0.fuse_layers.1.0.0   |    5.904K              |    9.446M  |\\n'\n",
      " '|  transition2.2.0                |  23.472K               |  9.389M    |\\n'\n",
      " '|   transition2.2.0.0             |   23.328K              |   9.331M   |\\n'\n",
      " '|    transition2.2.0.0.weight     |    (72, 36, 3, 3)      |            |\\n'\n",
      " '|   transition2.2.0.1             |   0.144K               |   57.6K    |\\n'\n",
      " '|    transition2.2.0.1.weight     |    (72,)               |            |\\n'\n",
      " '|    transition2.2.0.1.bias       |    (72,)               |            |\\n'\n",
      " '|  stage3                         |  2.163M                |  1.93G     |\\n'\n",
      " '|   stage3.0                      |   0.541M               |   0.482G   |\\n'\n",
      " '|    stage3.0.branches            |    0.492M              |    0.451G  |\\n'\n",
      " '|    stage3.0.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|   stage3.1                      |   0.541M               |   0.482G   |\\n'\n",
      " '|    stage3.1.branches            |    0.492M              |    0.451G  |\\n'\n",
      " '|    stage3.1.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|   stage3.2                      |   0.541M               |   0.482G   |\\n'\n",
      " '|    stage3.2.branches            |    0.492M              |    0.451G  |\\n'\n",
      " '|    stage3.2.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|   stage3.3                      |   0.541M               |   0.482G   |\\n'\n",
      " '|    stage3.3.branches            |    0.492M              |    0.451G  |\\n'\n",
      " '|    stage3.3.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|  transition3.3.0                |  93.6K                 |  9.36M     |\\n'\n",
      " '|   transition3.3.0.0             |   93.312K              |   9.331M   |\\n'\n",
      " '|    transition3.3.0.0.weight     |    (144, 72, 3, 3)     |            |\\n'\n",
      " '|   transition3.3.0.1             |   0.288K               |   28.8K    |\\n'\n",
      " '|    transition3.3.0.1.weight     |    (144,)              |            |\\n'\n",
      " '|    transition3.3.0.1.bias       |    (144,)              |            |\\n'\n",
      " '|  stage4                         |  6.709M                |  1.983G    |\\n'\n",
      " '|   stage4.0                      |   2.236M               |   0.661G   |\\n'\n",
      " '|    stage4.0.branches            |    1.987M              |    0.601G  |\\n'\n",
      " '|    stage4.0.fuse_layers         |    0.249M              |    60.318M |\\n'\n",
      " '|   stage4.1                      |   2.236M               |   0.661G   |\\n'\n",
      " '|    stage4.1.branches            |    1.987M              |    0.601G  |\\n'\n",
      " '|    stage4.1.fuse_layers         |    0.249M              |    60.318M |\\n'\n",
      " '|   stage4.2                      |   2.236M               |   0.661G   |\\n'\n",
      " '|    stage4.2.branches            |    1.987M              |    0.601G  |\\n'\n",
      " '|    stage4.2.fuse_layers         |    0.249M              |    60.318M |\\n'\n",
      " '|  incre_modules                  |  1.386M                |  0.422G    |\\n'\n",
      " '|   incre_modules.0.0             |   16.832K              |   0.108G   |\\n'\n",
      " '|    incre_modules.0.0.conv1      |    0.576K              |    3.686M  |\\n'\n",
      " '|    incre_modules.0.0.bn1        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv2      |    9.216K              |    58.982M |\\n'\n",
      " '|    incre_modules.0.0.bn2        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv3      |    4.096K              |    26.214M |\\n'\n",
      " '|    incre_modules.0.0.bn3        |    0.256K              |    1.638M  |\\n'\n",
      " '|    incre_modules.0.0.downsample |    2.56K               |    16.384M |\\n'\n",
      " '|   incre_modules.1.0             |   66.048K              |   0.106G   |\\n'\n",
      " '|    incre_modules.1.0.conv1      |    2.304K              |    3.686M  |\\n'\n",
      " '|    incre_modules.1.0.bn1        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv2      |    36.864K             |    58.982M |\\n'\n",
      " '|    incre_modules.1.0.bn2        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv3      |    16.384K             |    26.214M |\\n'\n",
      " '|    incre_modules.1.0.bn3        |    0.512K              |    0.819M  |\\n'\n",
      " '|    incre_modules.1.0.downsample |    9.728K              |    15.565M |\\n'\n",
      " '|   incre_modules.2.0             |   0.262M               |   0.105G   |\\n'\n",
      " '|    incre_modules.2.0.conv1      |    9.216K              |    3.686M  |\\n'\n",
      " '|    incre_modules.2.0.bn1        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv2      |    0.147M              |    58.982M |\\n'\n",
      " '|    incre_modules.2.0.bn2        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv3      |    65.536K             |    26.214M |\\n'\n",
      " '|    incre_modules.2.0.bn3        |    1.024K              |    0.41M   |\\n'\n",
      " '|    incre_modules.2.0.downsample |    37.888K             |    15.155M |\\n'\n",
      " '|   incre_modules.3.0             |   1.041M               |   0.104G   |\\n'\n",
      " '|    incre_modules.3.0.conv1      |    36.864K             |    3.686M  |\\n'\n",
      " '|    incre_modules.3.0.bn1        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv2      |    0.59M               |    58.982M |\\n'\n",
      " '|    incre_modules.3.0.bn2        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv3      |    0.262M              |    26.214M |\\n'\n",
      " '|    incre_modules.3.0.bn3        |    2.048K              |    0.205M  |\\n'\n",
      " '|    incre_modules.3.0.downsample |    0.15M               |    14.95M  |\\n'\n",
      " '|  downsamp_modules               |  6.199M                |  1.417G    |\\n'\n",
      " '|   downsamp_modules.0            |   0.296M               |   0.473G   |\\n'\n",
      " '|    downsamp_modules.0.0         |    0.295M              |    0.472G  |\\n'\n",
      " '|    downsamp_modules.0.1         |    0.512K              |    0.819M  |\\n'\n",
      " '|   downsamp_modules.1            |   1.181M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.1.0         |    1.18M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.1.1         |    1.024K              |    0.41M   |\\n'\n",
      " '|   downsamp_modules.2            |   4.722M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.2.0         |    4.72M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.2.1         |    2.048K              |    0.205M  |\\n'\n",
      " '|  final_layer                    |  2.103M                |  0.21G     |\\n'\n",
      " '|   final_layer.0                 |   2.099M               |   0.21G    |\\n'\n",
      " '|    final_layer.0.weight         |    (2048, 1024, 1, 1)  |            |\\n'\n",
      " '|    final_layer.0.bias           |    (2048,)             |            |\\n'\n",
      " '|   final_layer.1                 |   4.096K               |   0.41M    |\\n'\n",
      " '|    final_layer.1.weight         |    (2048,)             |            |\\n'\n",
      " '|    final_layer.1.bias           |    (2048,)             |            |\\n'\n",
      " '|  classifier                     |  2.049M                |  2.048M    |\\n'\n",
      " '|   classifier.weight             |   (1000, 2048)         |            |\\n'\n",
      " '|   classifier.bias               |   (1000,)              |            |\\n'\n",
      " '|  global_pool.pool               |                        |  0.205M    |')\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = timm.create_model(\"hrnet_w18\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 13.187M                | 3.291G     |\\n'\n",
      " '|  conv1                          |  1.728K                |  44.237M   |\\n'\n",
      " '|   conv1.weight                  |   (64, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                            |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn1.bias                      |   (64,)                |            |\\n'\n",
      " '|  conv2                          |  36.864K               |  0.236G    |\\n'\n",
      " '|   conv2.weight                  |   (64, 64, 3, 3)       |            |\\n'\n",
      " '|  bn2                            |  0.128K                |  0.819M    |\\n'\n",
      " '|   bn2.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn2.bias                      |   (64,)                |            |\\n'\n",
      " '|  layer1.0                       |  24.192K               |  0.155G    |\\n'\n",
      " '|   layer1.0.conv1                |   2.048K               |   13.107M  |\\n'\n",
      " '|    layer1.0.conv1.weight        |    (32, 64, 1, 1)      |            |\\n'\n",
      " '|   layer1.0.bn1                  |   64                   |   0.41M    |\\n'\n",
      " '|    layer1.0.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    layer1.0.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   layer1.0.conv2                |   9.216K               |   58.982M  |\\n'\n",
      " '|    layer1.0.conv2.weight        |    (32, 32, 3, 3)      |            |\\n'\n",
      " '|   layer1.0.bn2                  |   64                   |   0.41M    |\\n'\n",
      " '|    layer1.0.bn2.weight          |    (32,)               |            |\\n'\n",
      " '|    layer1.0.bn2.bias            |    (32,)               |            |\\n'\n",
      " '|   layer1.0.conv3                |   4.096K               |   26.214M  |\\n'\n",
      " '|    layer1.0.conv3.weight        |    (128, 32, 1, 1)     |            |\\n'\n",
      " '|   layer1.0.bn3                  |   0.256K               |   1.638M   |\\n'\n",
      " '|    layer1.0.bn3.weight          |    (128,)              |            |\\n'\n",
      " '|    layer1.0.bn3.bias            |    (128,)              |            |\\n'\n",
      " '|   layer1.0.downsample           |   8.448K               |   54.067M  |\\n'\n",
      " '|    layer1.0.downsample.0        |    8.192K              |    52.429M |\\n'\n",
      " '|    layer1.0.downsample.1        |    0.256K              |    1.638M  |\\n'\n",
      " '|  transition1                    |  55.392K               |  0.177G    |\\n'\n",
      " '|   transition1.0                 |   18.464K              |   0.118G   |\\n'\n",
      " '|    transition1.0.0              |    18.432K             |    0.118G  |\\n'\n",
      " '|    transition1.0.1              |    32                  |    0.205M  |\\n'\n",
      " '|   transition1.1.0               |   36.928K              |   59.085M  |\\n'\n",
      " '|    transition1.1.0.0            |    36.864K             |    58.982M |\\n'\n",
      " '|    transition1.1.0.1            |    64                  |    0.102M  |\\n'\n",
      " '|  stage2.0                       |  51.68K                |  0.128G    |\\n'\n",
      " '|   stage2.0.branches             |   46.464K              |   0.119G   |\\n'\n",
      " '|    stage2.0.branches.0          |    9.344K              |    59.802M |\\n'\n",
      " '|    stage2.0.branches.1          |    37.12K              |    59.392M |\\n'\n",
      " '|   stage2.0.fuse_layers          |   5.216K               |   8.448M   |\\n'\n",
      " '|    stage2.0.fuse_layers.0.1     |    0.544K              |    0.973M  |\\n'\n",
      " '|    stage2.0.fuse_layers.1.0.0   |    4.672K              |    7.475M  |\\n'\n",
      " '|  transition2.2.0                |  18.56K                |  7.424M    |\\n'\n",
      " '|   transition2.2.0.0             |   18.432K              |   7.373M   |\\n'\n",
      " '|    transition2.2.0.0.weight     |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   transition2.2.0.1             |   0.128K               |   51.2K    |\\n'\n",
      " '|    transition2.2.0.1.weight     |    (64,)               |            |\\n'\n",
      " '|    transition2.2.0.1.bias       |    (64,)               |            |\\n'\n",
      " '|  stage3.0                       |  0.233M                |  0.203G    |\\n'\n",
      " '|   stage3.0.branches             |   0.194M               |   0.178G   |\\n'\n",
      " '|    stage3.0.branches.0          |    9.344K              |    59.802M |\\n'\n",
      " '|    stage3.0.branches.1          |    37.12K              |    59.392M |\\n'\n",
      " '|    stage3.0.branches.2          |    0.148M              |    59.187M |\\n'\n",
      " '|   stage3.0.fuse_layers          |   38.624K              |   24.768M  |\\n'\n",
      " '|    stage3.0.fuse_layers.0       |    1.6K                |    1.498M  |\\n'\n",
      " '|    stage3.0.fuse_layers.1       |    6.784K              |    8.371M  |\\n'\n",
      " '|    stage3.0.fuse_layers.2       |    30.24K              |    14.899M |\\n'\n",
      " '|  transition3.3.0                |  73.984K               |  7.398M    |\\n'\n",
      " '|   transition3.3.0.0             |   73.728K              |   7.373M   |\\n'\n",
      " '|    transition3.3.0.0.weight     |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   transition3.3.0.1             |   0.256K               |   25.6K    |\\n'\n",
      " '|    transition3.3.0.1.weight     |    (128,)              |            |\\n'\n",
      " '|    transition3.3.0.1.bias       |    (128,)              |            |\\n'\n",
      " '|  stage4.0                       |  0.982M                |  0.285G    |\\n'\n",
      " '|   stage4.0.branches             |   0.785M               |   0.237G   |\\n'\n",
      " '|    stage4.0.branches.0          |    9.344K              |    59.802M |\\n'\n",
      " '|    stage4.0.branches.1          |    37.12K              |    59.392M |\\n'\n",
      " '|    stage4.0.branches.2          |    0.148M              |    59.187M |\\n'\n",
      " '|    stage4.0.branches.3          |    0.591M              |    59.085M |\\n'\n",
      " '|   stage4.0.fuse_layers          |   0.197M               |   47.766M  |\\n'\n",
      " '|    stage4.0.fuse_layers.0       |    3.68K               |    1.808M  |\\n'\n",
      " '|    stage4.0.fuse_layers.1       |    10.944K             |    8.838M  |\\n'\n",
      " '|    stage4.0.fuse_layers.2       |    38.56K              |    15.757M |\\n'\n",
      " '|    stage4.0.fuse_layers.3       |    0.144M              |    21.363M |\\n'\n",
      " '|  incre_modules                  |  1.359M                |  0.414G    |\\n'\n",
      " '|   incre_modules.0.0             |   16.512K              |   0.106G   |\\n'\n",
      " '|    incre_modules.0.0.conv1      |    0.512K              |    3.277M  |\\n'\n",
      " '|    incre_modules.0.0.bn1        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv2      |    9.216K              |    58.982M |\\n'\n",
      " '|    incre_modules.0.0.bn2        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv3      |    4.096K              |    26.214M |\\n'\n",
      " '|    incre_modules.0.0.bn3        |    0.256K              |    1.638M  |\\n'\n",
      " '|    incre_modules.0.0.downsample |    2.304K              |    14.746M |\\n'\n",
      " '|   incre_modules.1.0             |   64.768K              |   0.104G   |\\n'\n",
      " '|    incre_modules.1.0.conv1      |    2.048K              |    3.277M  |\\n'\n",
      " '|    incre_modules.1.0.bn1        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv2      |    36.864K             |    58.982M |\\n'\n",
      " '|    incre_modules.1.0.bn2        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv3      |    16.384K             |    26.214M |\\n'\n",
      " '|    incre_modules.1.0.bn3        |    0.512K              |    0.819M  |\\n'\n",
      " '|    incre_modules.1.0.downsample |    8.704K              |    13.926M |\\n'\n",
      " '|   incre_modules.2.0             |   0.257M               |   0.103G   |\\n'\n",
      " '|    incre_modules.2.0.conv1      |    8.192K              |    3.277M  |\\n'\n",
      " '|    incre_modules.2.0.bn1        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv2      |    0.147M              |    58.982M |\\n'\n",
      " '|    incre_modules.2.0.bn2        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv3      |    65.536K             |    26.214M |\\n'\n",
      " '|    incre_modules.2.0.bn3        |    1.024K              |    0.41M   |\\n'\n",
      " '|    incre_modules.2.0.downsample |    33.792K             |    13.517M |\\n'\n",
      " '|   incre_modules.3.0             |   1.021M               |   0.102G   |\\n'\n",
      " '|    incre_modules.3.0.conv1      |    32.768K             |    3.277M  |\\n'\n",
      " '|    incre_modules.3.0.bn1        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv2      |    0.59M               |    58.982M |\\n'\n",
      " '|    incre_modules.3.0.bn2        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv3      |    0.262M              |    26.214M |\\n'\n",
      " '|    incre_modules.3.0.bn3        |    2.048K              |    0.205M  |\\n'\n",
      " '|    incre_modules.3.0.downsample |    0.133M              |    13.312M |\\n'\n",
      " '|  downsamp_modules               |  6.199M                |  1.417G    |\\n'\n",
      " '|   downsamp_modules.0            |   0.296M               |   0.473G   |\\n'\n",
      " '|    downsamp_modules.0.0         |    0.295M              |    0.472G  |\\n'\n",
      " '|    downsamp_modules.0.1         |    0.512K              |    0.819M  |\\n'\n",
      " '|   downsamp_modules.1            |   1.181M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.1.0         |    1.18M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.1.1         |    1.024K              |    0.41M   |\\n'\n",
      " '|   downsamp_modules.2            |   4.722M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.2.0         |    4.72M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.2.1         |    2.048K              |    0.205M  |\\n'\n",
      " '|  final_layer                    |  2.103M                |  0.21G     |\\n'\n",
      " '|   final_layer.0                 |   2.099M               |   0.21G    |\\n'\n",
      " '|    final_layer.0.weight         |    (2048, 1024, 1, 1)  |            |\\n'\n",
      " '|    final_layer.0.bias           |    (2048,)             |            |\\n'\n",
      " '|   final_layer.1                 |   4.096K               |   0.41M    |\\n'\n",
      " '|    final_layer.1.weight         |    (2048,)             |            |\\n'\n",
      " '|    final_layer.1.bias           |    (2048,)             |            |\\n'\n",
      " '|  classifier                     |  2.049M                |  2.048M    |\\n'\n",
      " '|   classifier.weight             |   (1000, 2048)         |            |\\n'\n",
      " '|   classifier.bias               |   (1000,)              |            |\\n'\n",
      " '|  global_pool.pool               |                        |  0.205M    |')\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = timm.create_model(\"hrnet_w18_small\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 15.597M                | 5.337G     |\\n'\n",
      " '|  conv1                          |  1.728K                |  44.237M   |\\n'\n",
      " '|   conv1.weight                  |   (64, 3, 3, 3)        |            |\\n'\n",
      " '|  bn1                            |  0.128K                |  3.277M    |\\n'\n",
      " '|   bn1.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn1.bias                      |   (64,)                |            |\\n'\n",
      " '|  conv2                          |  36.864K               |  0.236G    |\\n'\n",
      " '|   conv2.weight                  |   (64, 64, 3, 3)       |            |\\n'\n",
      " '|  bn2                            |  0.128K                |  0.819M    |\\n'\n",
      " '|   bn2.weight                    |   (64,)                |            |\\n'\n",
      " '|   bn2.bias                      |   (64,)                |            |\\n'\n",
      " '|  layer1                         |  0.145M                |  0.931G    |\\n'\n",
      " '|   layer1.0                      |   75.008K              |   0.48G    |\\n'\n",
      " '|    layer1.0.conv1               |    4.096K              |    26.214M |\\n'\n",
      " '|    layer1.0.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.0.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.0.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.0.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|    layer1.0.downsample          |    16.896K             |    0.108G  |\\n'\n",
      " '|   layer1.1                      |   70.4K                |   0.451G   |\\n'\n",
      " '|    layer1.1.conv1               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn1                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv2               |    36.864K             |    0.236G  |\\n'\n",
      " '|    layer1.1.bn2                 |    0.128K              |    0.819M  |\\n'\n",
      " '|    layer1.1.conv3               |    16.384K             |    0.105G  |\\n'\n",
      " '|    layer1.1.bn3                 |    0.512K              |    3.277M  |\\n'\n",
      " '|  transition1                    |  0.125M                |  0.398G    |\\n'\n",
      " '|   transition1.0                 |   41.508K              |   0.266G   |\\n'\n",
      " '|    transition1.0.0              |    41.472K             |    0.265G  |\\n'\n",
      " '|    transition1.0.1              |    36                  |    0.23M   |\\n'\n",
      " '|   transition1.1.0               |   83.016K              |   0.133G   |\\n'\n",
      " '|    transition1.1.0.0            |    82.944K             |    0.133G  |\\n'\n",
      " '|    transition1.1.0.1            |    72                  |    0.115M  |\\n'\n",
      " '|  stage2.0                       |  65.34K                |  0.161G    |\\n'\n",
      " '|   stage2.0.branches             |   58.752K              |   0.151G   |\\n'\n",
      " '|    stage2.0.branches.0          |    11.808K             |    75.571M |\\n'\n",
      " '|    stage2.0.branches.1          |    46.944K             |    75.11M  |\\n'\n",
      " '|   stage2.0.fuse_layers          |   6.588K               |   10.656M  |\\n'\n",
      " '|    stage2.0.fuse_layers.0.1     |    0.684K              |    1.21M   |\\n'\n",
      " '|    stage2.0.fuse_layers.1.0.0   |    5.904K              |    9.446M  |\\n'\n",
      " '|  transition2.2.0                |  23.472K               |  9.389M    |\\n'\n",
      " '|   transition2.2.0.0             |   23.328K              |   9.331M   |\\n'\n",
      " '|    transition2.2.0.0.weight     |    (72, 36, 3, 3)      |            |\\n'\n",
      " '|   transition2.2.0.1             |   0.144K               |   57.6K    |\\n'\n",
      " '|    transition2.2.0.1.weight     |    (72,)               |            |\\n'\n",
      " '|    transition2.2.0.1.bias       |    (72,)               |            |\\n'\n",
      " '|  stage3                         |  0.884M                |  0.77G     |\\n'\n",
      " '|   stage3.0                      |   0.295M               |   0.257G   |\\n'\n",
      " '|    stage3.0.branches            |    0.246M              |    0.226G  |\\n'\n",
      " '|    stage3.0.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|   stage3.1                      |   0.295M               |   0.257G   |\\n'\n",
      " '|    stage3.1.branches            |    0.246M              |    0.226G  |\\n'\n",
      " '|    stage3.1.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|   stage3.2                      |   0.295M               |   0.257G   |\\n'\n",
      " '|    stage3.2.branches            |    0.246M              |    0.226G  |\\n'\n",
      " '|    stage3.2.fuse_layers         |    48.816K             |    31.262M |\\n'\n",
      " '|  transition3.3.0                |  93.6K                 |  9.36M     |\\n'\n",
      " '|   transition3.3.0.0             |   93.312K              |   9.331M   |\\n'\n",
      " '|    transition3.3.0.0.weight     |    (144, 72, 3, 3)     |            |\\n'\n",
      " '|   transition3.3.0.1             |   0.288K               |   28.8K    |\\n'\n",
      " '|    transition3.3.0.1.weight     |    (144,)              |            |\\n'\n",
      " '|    transition3.3.0.1.bias       |    (144,)              |            |\\n'\n",
      " '|  stage4                         |  2.485M                |  0.721G    |\\n'\n",
      " '|   stage4.0                      |   1.243M               |   0.361G   |\\n'\n",
      " '|    stage4.0.branches            |    0.994M              |    0.3G    |\\n'\n",
      " '|    stage4.0.fuse_layers         |    0.249M              |    60.318M |\\n'\n",
      " '|   stage4.1                      |   1.243M               |   0.361G   |\\n'\n",
      " '|    stage4.1.branches            |    0.994M              |    0.3G    |\\n'\n",
      " '|    stage4.1.fuse_layers         |    0.249M              |    60.318M |\\n'\n",
      " '|  incre_modules                  |  1.386M                |  0.422G    |\\n'\n",
      " '|   incre_modules.0.0             |   16.832K              |   0.108G   |\\n'\n",
      " '|    incre_modules.0.0.conv1      |    0.576K              |    3.686M  |\\n'\n",
      " '|    incre_modules.0.0.bn1        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv2      |    9.216K              |    58.982M |\\n'\n",
      " '|    incre_modules.0.0.bn2        |    64                  |    0.41M   |\\n'\n",
      " '|    incre_modules.0.0.conv3      |    4.096K              |    26.214M |\\n'\n",
      " '|    incre_modules.0.0.bn3        |    0.256K              |    1.638M  |\\n'\n",
      " '|    incre_modules.0.0.downsample |    2.56K               |    16.384M |\\n'\n",
      " '|   incre_modules.1.0             |   66.048K              |   0.106G   |\\n'\n",
      " '|    incre_modules.1.0.conv1      |    2.304K              |    3.686M  |\\n'\n",
      " '|    incre_modules.1.0.bn1        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv2      |    36.864K             |    58.982M |\\n'\n",
      " '|    incre_modules.1.0.bn2        |    0.128K              |    0.205M  |\\n'\n",
      " '|    incre_modules.1.0.conv3      |    16.384K             |    26.214M |\\n'\n",
      " '|    incre_modules.1.0.bn3        |    0.512K              |    0.819M  |\\n'\n",
      " '|    incre_modules.1.0.downsample |    9.728K              |    15.565M |\\n'\n",
      " '|   incre_modules.2.0             |   0.262M               |   0.105G   |\\n'\n",
      " '|    incre_modules.2.0.conv1      |    9.216K              |    3.686M  |\\n'\n",
      " '|    incre_modules.2.0.bn1        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv2      |    0.147M              |    58.982M |\\n'\n",
      " '|    incre_modules.2.0.bn2        |    0.256K              |    0.102M  |\\n'\n",
      " '|    incre_modules.2.0.conv3      |    65.536K             |    26.214M |\\n'\n",
      " '|    incre_modules.2.0.bn3        |    1.024K              |    0.41M   |\\n'\n",
      " '|    incre_modules.2.0.downsample |    37.888K             |    15.155M |\\n'\n",
      " '|   incre_modules.3.0             |   1.041M               |   0.104G   |\\n'\n",
      " '|    incre_modules.3.0.conv1      |    36.864K             |    3.686M  |\\n'\n",
      " '|    incre_modules.3.0.bn1        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv2      |    0.59M               |    58.982M |\\n'\n",
      " '|    incre_modules.3.0.bn2        |    0.512K              |    51.2K   |\\n'\n",
      " '|    incre_modules.3.0.conv3      |    0.262M              |    26.214M |\\n'\n",
      " '|    incre_modules.3.0.bn3        |    2.048K              |    0.205M  |\\n'\n",
      " '|    incre_modules.3.0.downsample |    0.15M               |    14.95M  |\\n'\n",
      " '|  downsamp_modules               |  6.199M                |  1.417G    |\\n'\n",
      " '|   downsamp_modules.0            |   0.296M               |   0.473G   |\\n'\n",
      " '|    downsamp_modules.0.0         |    0.295M              |    0.472G  |\\n'\n",
      " '|    downsamp_modules.0.1         |    0.512K              |    0.819M  |\\n'\n",
      " '|   downsamp_modules.1            |   1.181M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.1.0         |    1.18M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.1.1         |    1.024K              |    0.41M   |\\n'\n",
      " '|   downsamp_modules.2            |   4.722M               |   0.472G   |\\n'\n",
      " '|    downsamp_modules.2.0         |    4.72M               |    0.472G  |\\n'\n",
      " '|    downsamp_modules.2.1         |    2.048K              |    0.205M  |\\n'\n",
      " '|  final_layer                    |  2.103M                |  0.21G     |\\n'\n",
      " '|   final_layer.0                 |   2.099M               |   0.21G    |\\n'\n",
      " '|    final_layer.0.weight         |    (2048, 1024, 1, 1)  |            |\\n'\n",
      " '|    final_layer.0.bias           |    (2048,)             |            |\\n'\n",
      " '|   final_layer.1                 |   4.096K               |   0.41M    |\\n'\n",
      " '|    final_layer.1.weight         |    (2048,)             |            |\\n'\n",
      " '|    final_layer.1.bias           |    (2048,)             |            |\\n'\n",
      " '|  classifier                     |  2.049M                |  2.048M    |\\n'\n",
      " '|   classifier.weight             |   (1000, 2048)         |            |\\n'\n",
      " '|   classifier.bias               |   (1000,)              |            |\\n'\n",
      " '|  global_pool.pool               |                        |  0.205M    |')\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = timm.create_model(\"hrnet_w18_small_v2\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiteHRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.13M                  | 0.551G     |\\n'\n",
      " '|  backbone                       |  1.13M                 |  0.55G     |\\n'\n",
      " '|   backbone.stem                 |   2.864K               |   47.206M  |\\n'\n",
      " '|    backbone.stem.conv1          |    0.928K              |    23.757M |\\n'\n",
      " '|    backbone.stem.branch1        |    0.464K              |    2.97M   |\\n'\n",
      " '|    backbone.stem.expand_conv    |    0.576K              |    14.746M |\\n'\n",
      " '|    backbone.stem.depthwise_conv |    0.352K              |    2.253M  |\\n'\n",
      " '|    backbone.stem.linear_conv    |    0.544K              |    3.482M  |\\n'\n",
      " '|   backbone.transition0          |   4.784K               |   15.872M  |\\n'\n",
      " '|    backbone.transition0.0       |    1.712K              |    10.957M |\\n'\n",
      " '|    backbone.transition0.1.0     |    3.072K              |    4.915M  |\\n'\n",
      " '|   backbone.stage0               |   24.996K              |   52.062M  |\\n'\n",
      " '|    backbone.stage0.0            |    12.498K             |    26.031M |\\n'\n",
      " '|    backbone.stage0.1            |    12.498K             |    26.031M |\\n'\n",
      " '|   backbone.transition1.2.0      |   14K                  |   5.6M     |\\n'\n",
      " '|    backbone.transition1.2.0.0   |    0.72K               |    0.288M  |\\n'\n",
      " '|    backbone.transition1.2.0.1   |    0.16K               |    64K     |\\n'\n",
      " '|    backbone.transition1.2.0.2   |    12.8K               |    5.12M   |\\n'\n",
      " '|    backbone.transition1.2.0.3   |    0.32K               |    0.128M  |\\n'\n",
      " '|   backbone.stage1               |   0.287M               |   0.217G   |\\n'\n",
      " '|    backbone.stage1.0            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.1            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.2            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.3            |    71.778K             |    54.212M |\\n'\n",
      " '|   backbone.transition2.3.0      |   53.6K                |   5.36M    |\\n'\n",
      " '|    backbone.transition2.3.0.0   |    1.44K               |    0.144M  |\\n'\n",
      " '|    backbone.transition2.3.0.1   |    0.32K               |    32K     |\\n'\n",
      " '|    backbone.transition2.3.0.2   |    51.2K               |    5.12M   |\\n'\n",
      " '|    backbone.transition2.3.0.3   |    0.64K               |    64K     |\\n'\n",
      " '|   backbone.stage2               |   0.667M               |   0.174G   |\\n'\n",
      " '|    backbone.stage2.0            |    0.333M              |    87.001M |\\n'\n",
      " '|    backbone.stage2.1            |    0.333M              |    87.001M |\\n'\n",
      " '|   backbone.head_layer           |   76.04K               |   33.408M  |\\n'\n",
      " '|    backbone.head_layer.projects |    76.04K              |    31.616M |\\n'\n",
      " '|  head                           |  41                    |  0.256M    |\\n'\n",
      " '|   head.weight                   |   (1, 40, 1, 1)        |            |\\n'\n",
      " '|   head.bias                     |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.lite_hrnet import LiteHRNet18\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = LiteHRNet18(n_classes=1)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.763M                 | 0.88G      |\\n'\n",
      " '|  backbone                       |  1.763M                |  0.88G     |\\n'\n",
      " '|   backbone.stem                 |   2.864K               |   47.206M  |\\n'\n",
      " '|    backbone.stem.conv1          |    0.928K              |    23.757M |\\n'\n",
      " '|    backbone.stem.branch1        |    0.464K              |    2.97M   |\\n'\n",
      " '|    backbone.stem.expand_conv    |    0.576K              |    14.746M |\\n'\n",
      " '|    backbone.stem.depthwise_conv |    0.352K              |    2.253M  |\\n'\n",
      " '|    backbone.stem.linear_conv    |    0.544K              |    3.482M  |\\n'\n",
      " '|   backbone.transition0          |   4.784K               |   15.872M  |\\n'\n",
      " '|    backbone.transition0.0       |    1.712K              |    10.957M |\\n'\n",
      " '|    backbone.transition0.1.0     |    3.072K              |    4.915M  |\\n'\n",
      " '|   backbone.stage0               |   37.494K              |   78.092M  |\\n'\n",
      " '|    backbone.stage0.0            |    12.498K             |    26.031M |\\n'\n",
      " '|    backbone.stage0.1            |    12.498K             |    26.031M |\\n'\n",
      " '|    backbone.stage0.2            |    12.498K             |    26.031M |\\n'\n",
      " '|   backbone.transition1.2.0      |   14K                  |   5.6M     |\\n'\n",
      " '|    backbone.transition1.2.0.0   |    0.72K               |    0.288M  |\\n'\n",
      " '|    backbone.transition1.2.0.1   |    0.16K               |    64K     |\\n'\n",
      " '|    backbone.transition1.2.0.2   |    12.8K               |    5.12M   |\\n'\n",
      " '|    backbone.transition1.2.0.3   |    0.32K               |    0.128M  |\\n'\n",
      " '|   backbone.stage1               |   0.574M               |   0.434G   |\\n'\n",
      " '|    backbone.stage1.0            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.1            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.2            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.3            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.4            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.5            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.6            |    71.778K             |    54.212M |\\n'\n",
      " '|    backbone.stage1.7            |    71.778K             |    54.212M |\\n'\n",
      " '|   backbone.transition2.3.0      |   53.6K                |   5.36M    |\\n'\n",
      " '|    backbone.transition2.3.0.0   |    1.44K               |    0.144M  |\\n'\n",
      " '|    backbone.transition2.3.0.1   |    0.32K               |    32K     |\\n'\n",
      " '|    backbone.transition2.3.0.2   |    51.2K               |    5.12M   |\\n'\n",
      " '|    backbone.transition2.3.0.3   |    0.64K               |    64K     |\\n'\n",
      " '|   backbone.stage2               |   1M                   |   0.261G   |\\n'\n",
      " '|    backbone.stage2.0            |    0.333M              |    87.001M |\\n'\n",
      " '|    backbone.stage2.1            |    0.333M              |    87.001M |\\n'\n",
      " '|    backbone.stage2.2            |    0.333M              |    87.001M |\\n'\n",
      " '|   backbone.head_layer           |   76.04K               |   33.408M  |\\n'\n",
      " '|    backbone.head_layer.projects |    76.04K              |    31.616M |\\n'\n",
      " '|  head                           |  41                    |  0.256M    |\\n'\n",
      " '|   head.weight                   |   (1, 40, 1, 1)        |            |\\n'\n",
      " '|   head.bias                     |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.lite_hrnet import LiteHRNet30\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = LiteHRNet30(n_classes=1)\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                        | 17.268M                | 63.129G    |\\n'\n",
      " '|  inc.double_conv                             |  38.848K               |  3.978G    |\\n'\n",
      " '|   inc.double_conv.0                          |   1.728K               |   0.177G   |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   inc.double_conv.1                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (64,)               |            |\\n'\n",
      " '|   inc.double_conv.3                          |   36.864K              |   3.775G   |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   inc.double_conv.4                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (64,)               |            |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  0.222M                |  5.675G    |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   73.728K              |   1.887G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (128,)              |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   0.147M               |   3.775G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (128,)              |            |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  0.886M                |  5.669G    |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   0.295M               |   1.887G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (256,)              |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   0.59M                |   3.775G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (256,)              |            |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  3.541M                |  5.666G    |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   1.18M                |   1.887G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (512,)              |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   2.359M               |   3.775G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (512,)              |            |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  4.721M                |  1.888G    |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   2.359M               |   0.944G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   1.024K               |   0.41M    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (512,)              |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (512,)              |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   2.359M               |   0.944G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   1.024K               |   0.41M    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (512,)              |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (512,)              |            |\\n'\n",
      " '|  up1                                         |  5.9M                  |  9.443G    |\\n'\n",
      " '|   up1.conv.double_conv                       |   5.9M                 |   9.44G    |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    4.719M              |    7.55G   |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    1.024K              |    1.638M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    1.18M               |    1.887G  |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.512K              |    0.819M  |\\n'\n",
      " '|   up1.up                                     |                        |   3.277M   |\\n'\n",
      " '|  up2                                         |  1.475M                |  9.449G    |\\n'\n",
      " '|   up2.conv.double_conv                       |   1.475M               |   9.442G   |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    1.18M               |    7.55G   |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.512K              |    3.277M  |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    0.295M              |    1.887G  |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    0.256K              |    1.638M  |\\n'\n",
      " '|   up2.up                                     |                        |   6.554M   |\\n'\n",
      " '|  up3                                         |  0.369M                |  9.46G     |\\n'\n",
      " '|   up3.conv.double_conv                       |   0.369M               |   9.447G   |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    0.295M              |    7.55G   |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    0.256K              |    6.554M  |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    73.728K             |    1.887G  |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    0.128K              |    3.277M  |\\n'\n",
      " '|   up3.up                                     |                        |   13.107M  |\\n'\n",
      " '|  up4                                         |  0.111M                |  11.377G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   0.111M               |   11.351G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    73.728K             |    7.55G   |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    0.128K              |    13.107M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    36.864K             |    3.775G  |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    0.128K              |    13.107M |\\n'\n",
      " '|   up4.up                                     |                        |   26.214M  |\\n'\n",
      " '|  outc.conv                                   |  5.2K                  |  0.524G    |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 64, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 1\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                        | 31.043M                | 75.879G    |\\n'\n",
      " '|  inc.double_conv                             |  38.848K               |  3.978G    |\\n'\n",
      " '|   inc.double_conv.0                          |   1.728K               |   0.177G   |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   inc.double_conv.1                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (64,)               |            |\\n'\n",
      " '|   inc.double_conv.3                          |   36.864K              |   3.775G   |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   inc.double_conv.4                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (64,)               |            |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  0.222M                |  5.675G    |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   73.728K              |   1.887G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (128,)              |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   0.147M               |   3.775G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (128,)              |            |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  0.886M                |  5.669G    |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   0.295M               |   1.887G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (256,)              |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   0.59M                |   3.775G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (256,)              |            |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  3.541M                |  5.666G    |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   1.18M                |   1.887G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (512,)              |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   2.359M               |   3.775G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (512,)              |            |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  14.16M                |  5.664G    |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   4.719M               |   1.887G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (1024, 512, 3, 3)   |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   2.048K               |   0.819M   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (1024,)             |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (1024,)             |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   9.437M               |   3.775G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (1024, 1024, 3, 3)  |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   2.048K               |   0.819M   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (1024,)             |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (1024,)             |            |\\n'\n",
      " '|  up1                                         |  9.178M                |  12.167G   |\\n'\n",
      " '|   up1.up                                     |   2.098M               |   0.839G   |\\n'\n",
      " '|    up1.up.weight                             |    (1024, 512, 2, 2)   |            |\\n'\n",
      " '|    up1.up.bias                               |    (512,)              |            |\\n'\n",
      " '|   up1.conv.double_conv                       |   7.08M                |   11.328G  |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    4.719M              |    7.55G   |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    1.024K              |    1.638M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    2.359M              |    3.775G  |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    1.024K              |    1.638M  |\\n'\n",
      " '|  up2                                         |  2.295M                |  12.17G    |\\n'\n",
      " '|   up2.up                                     |   0.525M               |   0.839G   |\\n'\n",
      " '|    up2.up.weight                             |    (512, 256, 2, 2)    |            |\\n'\n",
      " '|    up2.up.bias                               |    (256,)              |            |\\n'\n",
      " '|   up2.conv.double_conv                       |   1.77M                |   11.331G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    1.18M               |    7.55G   |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.512K              |    3.277M  |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    0.59M               |    3.775G  |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    0.512K              |    3.277M  |\\n'\n",
      " '|  up3                                         |  0.574M                |  12.177G   |\\n'\n",
      " '|   up3.up                                     |   0.131M               |   0.839G   |\\n'\n",
      " '|    up3.up.weight                             |    (256, 128, 2, 2)    |            |\\n'\n",
      " '|    up3.up.bias                               |    (128,)              |            |\\n'\n",
      " '|   up3.conv.double_conv                       |   0.443M               |   11.338G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    0.295M              |    7.55G   |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    0.256K              |    6.554M  |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    0.147M              |    3.775G  |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    0.256K              |    6.554M  |\\n'\n",
      " '|  up4                                         |  0.144M                |  12.19G    |\\n'\n",
      " '|   up4.up                                     |   32.832K              |   0.839G   |\\n'\n",
      " '|    up4.up.weight                             |    (128, 64, 2, 2)     |            |\\n'\n",
      " '|    up4.up.bias                               |    (64,)               |            |\\n'\n",
      " '|   up4.conv.double_conv                       |   0.111M               |   11.351G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    73.728K             |    7.55G   |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    0.128K              |    13.107M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    36.864K             |    3.775G  |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    0.128K              |    13.107M |\\n'\n",
      " '|  outc.conv                                   |  5.2K                  |  0.524G    |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 64, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 1\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"convtranspose\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                        | 17.268M                | 63.092G    |\\n'\n",
      " '|  inc.double_conv                             |  38.848K               |  3.978G    |\\n'\n",
      " '|   inc.double_conv.0                          |   1.728K               |   0.177G   |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   inc.double_conv.1                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (64,)               |            |\\n'\n",
      " '|   inc.double_conv.3                          |   36.864K              |   3.775G   |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   inc.double_conv.4                          |   0.128K               |   13.107M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (64,)               |            |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (64,)               |            |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  0.222M                |  5.675G    |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   73.728K              |   1.887G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (128,)              |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   0.147M               |   3.775G   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   0.256K               |   6.554M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (128,)              |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (128,)              |            |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  0.886M                |  5.669G    |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   0.295M               |   1.887G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (256, 128, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (256,)              |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   0.59M                |   3.775G   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.512K               |   3.277M   |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (256,)              |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (256,)              |            |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  3.541M                |  5.666G    |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   1.18M                |   1.887G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (512, 256, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (512,)              |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   2.359M               |   3.775G   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   1.024K               |   1.638M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (512,)              |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (512,)              |            |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  4.721M                |  1.888G    |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   2.359M               |   0.944G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   1.024K               |   0.41M    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (512,)              |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (512,)              |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   2.359M               |   0.944G   |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (512, 512, 3, 3)    |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   1.024K               |   0.41M    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (512,)              |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (512,)              |            |\\n'\n",
      " '|  up1                                         |  5.9M                  |  9.44G     |\\n'\n",
      " '|   up1.conv.double_conv                       |   5.9M                 |   9.44G    |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    4.719M              |    7.55G   |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    1.024K              |    1.638M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    1.18M               |    1.887G  |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.512K              |    0.819M  |\\n'\n",
      " '|   up1.up                                     |                        |   0.819M   |\\n'\n",
      " '|  up2                                         |  1.475M                |  9.444G    |\\n'\n",
      " '|   up2.conv.double_conv                       |   1.475M               |   9.442G   |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    1.18M               |    7.55G   |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.512K              |    3.277M  |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    0.295M              |    1.887G  |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    0.256K              |    1.638M  |\\n'\n",
      " '|   up2.up                                     |                        |   1.638M   |\\n'\n",
      " '|  up3                                         |  0.369M                |  9.45G     |\\n'\n",
      " '|   up3.conv.double_conv                       |   0.369M               |   9.447G   |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    0.295M              |    7.55G   |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    0.256K              |    6.554M  |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    73.728K             |    1.887G  |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    0.128K              |    3.277M  |\\n'\n",
      " '|   up3.up                                     |                        |   3.277M   |\\n'\n",
      " '|  up4                                         |  0.111M                |  11.357G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   0.111M               |   11.351G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    73.728K             |    7.55G   |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    0.128K              |    13.107M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    36.864K             |    3.775G  |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    0.128K              |    13.107M |\\n'\n",
      " '|   up4.up                                     |                        |   6.554M   |\\n'\n",
      " '|  outc.conv                                   |  5.2K                  |  0.524G    |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 64, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 1\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"nearest\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 4.321M                 | 15.993G   |\\n'\n",
      " '|  inc.double_conv                             |  10.208K               |  1.045G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.864K               |   88.474M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (32, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   64                   |   6.554M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (32,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (32,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   9.216K               |   0.944G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (32, 32, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   64                   |   6.554M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (32,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (32,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  55.552K               |  1.422G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   18.432K              |   0.472G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (64, 32, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   0.128K               |   3.277M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (64,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (64,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   36.864K              |   0.944G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (64, 64, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   0.128K               |   3.277M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (64,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (64,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  0.222M                |  1.419G   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   73.728K              |   0.472G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.256K               |   1.638M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (128,)              |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (128,)              |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   0.147M               |   0.944G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.256K               |   1.638M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (128,)              |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (128,)              |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.886M                |  1.417G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   0.295M               |   0.472G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (256, 128, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.512K               |   0.819M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (256,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (256,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.59M                |   0.944G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (256, 256, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.512K               |   0.819M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (256,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (256,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  1.181M                |  0.472G   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.59M                |   0.236G  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (256, 256, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.512K               |   0.205M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (256,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (256,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.59M                |   0.236G  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (256, 256, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.512K               |   0.205M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (256,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (256,)              |           |\\n'\n",
      " '|  up1                                         |  1.475M                |  2.362G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   1.475M               |   2.361G  |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    1.18M               |    1.887G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.512K              |    0.819M |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    0.295M              |    0.472G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.256K              |    0.41M  |\\n'\n",
      " '|   up1.up                                     |                        |   1.638M  |\\n'\n",
      " '|  up2                                         |  0.369M                |  2.365G   |\\n'\n",
      " '|   up2.conv.double_conv                       |   0.369M               |   2.362G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    0.295M              |    1.887G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.256K              |    1.638M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    73.728K             |    0.472G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    0.128K              |    0.819M |\\n'\n",
      " '|   up2.up                                     |                        |   3.277M  |\\n'\n",
      " '|  up3                                         |  92.352K               |  2.371G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   92.352K              |   2.364G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    73.728K             |    1.887G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    0.128K              |    3.277M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    18.432K             |    0.472G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    64                  |    1.638M |\\n'\n",
      " '|   up3.up                                     |                        |   6.554M  |\\n'\n",
      " '|  up4                                         |  27.776K               |  2.857G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   27.776K              |   2.844G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    18.432K             |    1.887G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    64                  |    6.554M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    9.216K              |    0.944G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    64                  |    6.554M |\\n'\n",
      " '|   up4.up                                     |                        |   13.107M |\\n'\n",
      " '|  outc.conv                                   |  2.64K                 |  0.262G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 32, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.5\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 2.432M                 | 9.075G    |\\n'\n",
      " '|  inc.double_conv                             |  5.928K                |  0.607G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.648K               |   66.355M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (24, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   48                   |   4.915M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (24,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (24,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   5.184K               |   0.531G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (24, 24, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   48                   |   4.915M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (24,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (24,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  31.296K               |  0.801G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   10.368K              |   0.265G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (48, 24, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   96                   |   2.458M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (48,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (48,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   20.736K              |   0.531G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (48, 48, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   96                   |   2.458M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (48,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (48,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  0.125M                |  0.799G   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   41.472K              |   0.265G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (96, 48, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.192K               |   1.229M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (96,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (96,)               |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   82.944K              |   0.531G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (96, 96, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.192K               |   1.229M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (96,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (96,)               |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.498M                |  0.797G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   0.166M               |   0.265G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (192, 96, 3, 3)     |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.384K               |   0.614M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (192,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (192,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.332M               |   0.531G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (192, 192, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.384K               |   0.614M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (192,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (192,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  0.664M                |  0.266G   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.332M               |   0.133G  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (192, 192, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.384K               |   0.154M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (192,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (192,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.332M               |   0.133G  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (192, 192, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.384K               |   0.154M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (192,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (192,)              |           |\\n'\n",
      " '|  up1                                         |  0.83M                 |  1.329G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   0.83M                |   1.328G  |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    0.664M              |    1.062G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.384K              |    0.614M |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    0.166M              |    0.265G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.192K              |    0.307M |\\n'\n",
      " '|   up1.up                                     |                        |   1.229M  |\\n'\n",
      " '|  up2                                         |  0.208M                |  1.331G   |\\n'\n",
      " '|   up2.conv.double_conv                       |   0.208M               |   1.329G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    0.166M              |    1.062G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.192K              |    1.229M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    41.472K             |    0.265G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    96                  |    0.614M |\\n'\n",
      " '|   up2.up                                     |                        |   2.458M  |\\n'\n",
      " '|  up3                                         |  51.984K               |  1.336G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   51.984K              |   1.331G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    41.472K             |    1.062G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    96                  |    2.458M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    10.368K             |    0.265G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    48                  |    1.229M |\\n'\n",
      " '|   up3.up                                     |                        |   4.915M  |\\n'\n",
      " '|  up4                                         |  15.648K               |  1.612G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   15.648K              |   1.602G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    10.368K             |    1.062G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    48                  |    4.915M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    5.184K              |    0.531G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    48                  |    4.915M |\\n'\n",
      " '|   up4.up                                     |                        |   9.83M   |\\n'\n",
      " '|  outc.conv                                   |  2K                    |  0.197G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 24, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.375\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.28125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 1.369M                 | 5.164G    |\\n'\n",
      " '|  inc.double_conv                             |  3.474K                |  0.356G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.486K               |   49.766M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (18, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   36                   |   3.686M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (18,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (18,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   2.916K               |   0.299G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (18, 18, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   36                   |   3.686M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (18,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (18,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  17.64K                |  0.452G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   5.832K               |   0.149G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (36, 18, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   72                   |   1.843M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (36,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (36,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   11.664K              |   0.299G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (36, 36, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   72                   |   1.843M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (36,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (36,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  70.272K               |  0.45G    |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   23.328K              |   0.149G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (72, 36, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.144K               |   0.922M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (72,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (72,)               |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   46.656K              |   0.299G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (72, 72, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.144K               |   0.922M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (72,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (72,)               |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.281M                |  0.449G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   93.312K              |   0.149G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (144, 72, 3, 3)     |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.288K               |   0.461M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (144,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (144,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.187M               |   0.299G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (144, 144, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.288K               |   0.461M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (144,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (144,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  0.374M                |  0.15G    |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.187M               |   74.65M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (144, 144, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.288K               |   0.115M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (144,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (144,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.187M               |   74.65M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (144, 144, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.288K               |   0.115M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (144,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (144,)              |           |\\n'\n",
      " '|  up1                                         |  0.467M                |  0.748G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   0.467M               |   0.747G  |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    0.373M              |    0.597G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.288K              |    0.461M |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    93.312K             |    0.149G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.144K              |    0.23M  |\\n'\n",
      " '|   up1.up                                     |                        |   0.922M  |\\n'\n",
      " '|  up2                                         |  0.117M                |  0.75G    |\\n'\n",
      " '|   up2.conv.double_conv                       |   0.117M               |   0.748G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    93.312K             |    0.597G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.144K              |    0.922M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    23.328K             |    0.149G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    72                  |    0.461M |\\n'\n",
      " '|   up2.up                                     |                        |   1.843M  |\\n'\n",
      " '|  up3                                         |  29.268K               |  0.753G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   29.268K              |   0.749G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    23.328K             |    0.597G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    72                  |    1.843M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    5.832K              |    0.149G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    36                  |    0.922M |\\n'\n",
      " '|   up3.up                                     |                        |   3.686M  |\\n'\n",
      " '|  up4                                         |  8.82K                 |  0.911G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   8.82K                |   0.903G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    5.832K              |    0.597G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    36                  |    3.686M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    2.916K              |    0.299G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    36                  |    3.686M |\\n'\n",
      " '|   up4.up                                     |                        |   7.373M  |\\n'\n",
      " '|  outc.conv                                   |  1.52K                 |  0.147G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 18, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.28125\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.3125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 1.69M                  | 6.346G    |\\n'\n",
      " '|  inc.double_conv                             |  4.22K                 |  0.432G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.54K                |   55.296M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (20, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   40                   |   4.096M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (20,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (20,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   3.6K                 |   0.369G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (20, 20, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   40                   |   4.096M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (20,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (20,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  21.76K                |  0.557G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   7.2K                 |   0.184G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (40, 20, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   80                   |   2.048M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (40,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (40,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   14.4K                |   0.369G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (40, 40, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   80                   |   2.048M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (40,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (40,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  86.72K                |  0.555G   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   28.8K                |   0.184G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (80, 40, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.16K                |   1.024M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (80,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (80,)               |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   57.6K                |   0.369G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (80, 80, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.16K                |   1.024M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (80,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (80,)               |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.346M                |  0.554G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   0.115M               |   0.184G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (160, 80, 3, 3)     |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.32K                |   0.512M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (160,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (160,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.23M                |   0.369G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (160, 160, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.32K                |   0.512M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (160,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (160,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  0.461M                |  0.185G   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.23M                |   92.16M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (160, 160, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.32K                |   0.128M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (160,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (160,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.23M                |   92.16M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (160, 160, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.32K                |   0.128M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (160,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (160,)              |           |\\n'\n",
      " '|  up1                                         |  0.576M                |  0.923G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   0.576M               |   0.922G  |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    0.461M              |    0.737G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.32K               |    0.512M |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    0.115M              |    0.184G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.16K               |    0.256M |\\n'\n",
      " '|   up1.up                                     |                        |   1.024M  |\\n'\n",
      " '|  up2                                         |  0.144M                |  0.925G   |\\n'\n",
      " '|   up2.conv.double_conv                       |   0.144M               |   0.923G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    0.115M              |    0.737G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.16K               |    1.024M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    28.8K               |    0.184G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    80                  |    0.512M |\\n'\n",
      " '|   up2.up                                     |                        |   2.048M  |\\n'\n",
      " '|  up3                                         |  36.12K                |  0.929G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   36.12K               |   0.925G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    28.8K               |    0.737G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    80                  |    2.048M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    7.2K                |    0.184G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    40                  |    1.024M |\\n'\n",
      " '|   up3.up                                     |                        |   4.096M  |\\n'\n",
      " '|  up4                                         |  10.88K                |  1.122G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   10.88K               |   1.114G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    7.2K                |    0.737G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    40                  |    4.096M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    3.6K                |    0.369G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    40                  |    4.096M |\\n'\n",
      " '|   up4.up                                     |                        |   8.192M  |\\n'\n",
      " '|  outc.conv                                   |  1.68K                 |  0.164G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 20, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.3125\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 1.082M                 | 4.104G    |\\n'\n",
      " '|  inc.double_conv                             |  2.8K                  |  0.287G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.432K               |   44.237M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (16, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   32                   |   3.277M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (16,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (16,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   2.304K               |   0.236G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (16, 16, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   32                   |   3.277M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (16,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (16,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  13.952K               |  0.357G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   4.608K               |   0.118G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (32, 16, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   64                   |   1.638M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (32,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (32,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   9.216K               |   0.236G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (32, 32, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   64                   |   1.638M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (32,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (32,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  55.552K               |  0.356G   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   18.432K              |   0.118G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (64, 32, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.128K               |   0.819M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (64,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (64,)               |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   36.864K              |   0.236G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (64, 64, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.128K               |   0.819M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (64,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (64,)               |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.222M                |  0.355G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   73.728K              |   0.118G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.256K               |   0.41M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (128,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (128,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.147M               |   0.236G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.256K               |   0.41M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (128,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (128,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  0.295M                |  0.118G   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.147M               |   58.982M |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.256K               |   0.102M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (128,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (128,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.147M               |   58.982M |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.256K               |   0.102M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (128,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (128,)              |           |\\n'\n",
      " '|  up1                                         |  0.369M                |  0.591G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   0.369M               |   0.59G   |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    0.295M              |    0.472G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.256K              |    0.41M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    73.728K             |    0.118G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.128K              |    0.205M |\\n'\n",
      " '|   up1.up                                     |                        |   0.819M  |\\n'\n",
      " '|  up2                                         |  92.352K               |  0.593G   |\\n'\n",
      " '|   up2.conv.double_conv                       |   92.352K              |   0.591G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    73.728K             |    0.472G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.128K              |    0.819M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    18.432K             |    0.118G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    64                  |    0.41M  |\\n'\n",
      " '|   up2.up                                     |                        |   1.638M  |\\n'\n",
      " '|  up3                                         |  23.136K               |  0.596G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   23.136K              |   0.592G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    18.432K             |    0.472G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    64                  |    1.638M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    4.608K              |    0.118G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    32                  |    0.819M |\\n'\n",
      " '|   up3.up                                     |                        |   3.277M  |\\n'\n",
      " '|  up4                                         |  6.976K                |  0.721G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   6.976K               |   0.714G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    4.608K              |    0.472G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    32                  |    3.277M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    2.304K              |    0.236G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    32                  |    3.277M |\\n'\n",
      " '|   up4.up                                     |                        |   6.554M  |\\n'\n",
      " '|  outc.conv                                   |  1.36K                 |  0.131G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 16, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.25\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                        | 0.272M                 | 1.079G     |\\n'\n",
      " '|  inc.double_conv                             |  0.824K                |  84.378M   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.216K               |   22.118M  |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (8, 3, 3, 3)        |            |\\n'\n",
      " '|   inc.double_conv.1                          |   16                   |   1.638M   |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (8,)                |            |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (8,)                |            |\\n'\n",
      " '|   inc.double_conv.3                          |   0.576K               |   58.982M  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (8, 8, 3, 3)        |            |\\n'\n",
      " '|   inc.double_conv.4                          |   16                   |   1.638M   |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (8,)                |            |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (8,)                |            |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  3.52K                 |  90.112M   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   1.152K               |   29.491M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (16, 8, 3, 3)       |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   32                   |   0.819M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (16,)               |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (16,)               |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   2.304K               |   58.982M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (16, 16, 3, 3)      |            |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   32                   |   0.819M   |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (16,)               |            |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (16,)               |            |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  13.952K               |  89.293M   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   4.608K               |   29.491M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (32, 16, 3, 3)      |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   64                   |   0.41M    |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (32,)               |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (32,)               |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   9.216K               |   58.982M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (32, 32, 3, 3)      |            |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   64                   |   0.41M    |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (32,)               |            |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (32,)               |            |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  55.552K               |  88.883M   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   18.432K              |   29.491M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (64, 32, 3, 3)      |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.128K               |   0.205M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (64,)               |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (64,)               |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   36.864K              |   58.982M  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.128K               |   0.205M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (64,)               |            |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (64,)               |            |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  73.984K               |  29.594M   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   36.864K              |   14.746M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.128K               |   51.2K    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (64,)               |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (64,)               |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   36.864K              |   14.746M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.128K               |   51.2K    |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (64,)               |            |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (64,)               |            |\\n'\n",
      " '|  up1                                         |  92.352K               |  0.148G    |\\n'\n",
      " '|   up1.conv.double_conv                       |   92.352K              |   0.148G   |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.128K              |    0.205M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    18.432K             |    29.491M |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    64                  |    0.102M  |\\n'\n",
      " '|   up1.up                                     |                        |   0.41M    |\\n'\n",
      " '|  up2                                         |  23.136K               |  0.149G    |\\n'\n",
      " '|   up2.conv.double_conv                       |   23.136K              |   0.148G   |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    64                  |    0.41M   |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    4.608K              |    29.491M |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    32                  |    0.205M  |\\n'\n",
      " '|   up2.up                                     |                        |   0.819M   |\\n'\n",
      " '|  up3                                         |  5.808K                |  0.15G     |\\n'\n",
      " '|   up3.conv.double_conv                       |   5.808K               |   0.149G   |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    4.608K              |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    32                  |    0.819M  |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    1.152K              |    29.491M |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    16                  |    0.41M   |\\n'\n",
      " '|   up3.up                                     |                        |   1.638M   |\\n'\n",
      " '|  up4                                         |  1.76K                 |  0.184G    |\\n'\n",
      " '|   up4.conv.double_conv                       |   1.76K                |   0.18G    |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    1.152K              |    0.118G  |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    16                  |    1.638M  |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    0.576K              |    58.982M |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    16                  |    1.638M  |\\n'\n",
      " '|   up4.up                                     |                        |   3.277M   |\\n'\n",
      " '|  outc.conv                                   |  0.72K                 |  65.536M   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 8, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.125\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### width_scale=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                       | #parameters or shape   | #flops    |\\n'\n",
      " '|:---------------------------------------------|:-----------------------|:----------|\\n'\n",
      " '| model                                        | 1.082M                 | 4.104G    |\\n'\n",
      " '|  inc.double_conv                             |  2.8K                  |  0.287G   |\\n'\n",
      " '|   inc.double_conv.0                          |   0.432K               |   44.237M |\\n'\n",
      " '|    inc.double_conv.0.weight                  |    (16, 3, 3, 3)       |           |\\n'\n",
      " '|   inc.double_conv.1                          |   32                   |   3.277M  |\\n'\n",
      " '|    inc.double_conv.1.weight                  |    (16,)               |           |\\n'\n",
      " '|    inc.double_conv.1.bias                    |    (16,)               |           |\\n'\n",
      " '|   inc.double_conv.3                          |   2.304K               |   0.236G  |\\n'\n",
      " '|    inc.double_conv.3.weight                  |    (16, 16, 3, 3)      |           |\\n'\n",
      " '|   inc.double_conv.4                          |   32                   |   3.277M  |\\n'\n",
      " '|    inc.double_conv.4.weight                  |    (16,)               |           |\\n'\n",
      " '|    inc.double_conv.4.bias                    |    (16,)               |           |\\n'\n",
      " '|  down1.maxpool_conv.1.double_conv            |  13.952K               |  0.357G   |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.0         |   4.608K               |   0.118G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.0.weight |    (32, 16, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.1         |   64                   |   1.638M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.weight |    (32,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.1.bias   |    (32,)               |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.3         |   9.216K               |   0.236G  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.3.weight |    (32, 32, 3, 3)      |           |\\n'\n",
      " '|   down1.maxpool_conv.1.double_conv.4         |   64                   |   1.638M  |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.weight |    (32,)               |           |\\n'\n",
      " '|    down1.maxpool_conv.1.double_conv.4.bias   |    (32,)               |           |\\n'\n",
      " '|  down2.maxpool_conv.1.double_conv            |  55.552K               |  0.356G   |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.0         |   18.432K              |   0.118G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.0.weight |    (64, 32, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.1         |   0.128K               |   0.819M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.weight |    (64,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.1.bias   |    (64,)               |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.3         |   36.864K              |   0.236G  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.3.weight |    (64, 64, 3, 3)      |           |\\n'\n",
      " '|   down2.maxpool_conv.1.double_conv.4         |   0.128K               |   0.819M  |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.weight |    (64,)               |           |\\n'\n",
      " '|    down2.maxpool_conv.1.double_conv.4.bias   |    (64,)               |           |\\n'\n",
      " '|  down3.maxpool_conv.1.double_conv            |  0.222M                |  0.355G   |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.0         |   73.728K              |   0.118G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.0.weight |    (128, 64, 3, 3)     |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.1         |   0.256K               |   0.41M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.weight |    (128,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.1.bias   |    (128,)              |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.3         |   0.147M               |   0.236G  |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down3.maxpool_conv.1.double_conv.4         |   0.256K               |   0.41M   |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.weight |    (128,)              |           |\\n'\n",
      " '|    down3.maxpool_conv.1.double_conv.4.bias   |    (128,)              |           |\\n'\n",
      " '|  down4.maxpool_conv.1.double_conv            |  0.295M                |  0.118G   |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.0         |   0.147M               |   58.982M |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.0.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.1         |   0.256K               |   0.102M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.weight |    (128,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.1.bias   |    (128,)              |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.3         |   0.147M               |   58.982M |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.3.weight |    (128, 128, 3, 3)    |           |\\n'\n",
      " '|   down4.maxpool_conv.1.double_conv.4         |   0.256K               |   0.102M  |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.weight |    (128,)              |           |\\n'\n",
      " '|    down4.maxpool_conv.1.double_conv.4.bias   |    (128,)              |           |\\n'\n",
      " '|  up1                                         |  0.369M                |  0.591G   |\\n'\n",
      " '|   up1.conv.double_conv                       |   0.369M               |   0.59G   |\\n'\n",
      " '|    up1.conv.double_conv.0                    |    0.295M              |    0.472G |\\n'\n",
      " '|    up1.conv.double_conv.1                    |    0.256K              |    0.41M  |\\n'\n",
      " '|    up1.conv.double_conv.3                    |    73.728K             |    0.118G |\\n'\n",
      " '|    up1.conv.double_conv.4                    |    0.128K              |    0.205M |\\n'\n",
      " '|   up1.up                                     |                        |   0.819M  |\\n'\n",
      " '|  up2                                         |  92.352K               |  0.593G   |\\n'\n",
      " '|   up2.conv.double_conv                       |   92.352K              |   0.591G  |\\n'\n",
      " '|    up2.conv.double_conv.0                    |    73.728K             |    0.472G |\\n'\n",
      " '|    up2.conv.double_conv.1                    |    0.128K              |    0.819M |\\n'\n",
      " '|    up2.conv.double_conv.3                    |    18.432K             |    0.118G |\\n'\n",
      " '|    up2.conv.double_conv.4                    |    64                  |    0.41M  |\\n'\n",
      " '|   up2.up                                     |                        |   1.638M  |\\n'\n",
      " '|  up3                                         |  23.136K               |  0.596G   |\\n'\n",
      " '|   up3.conv.double_conv                       |   23.136K              |   0.592G  |\\n'\n",
      " '|    up3.conv.double_conv.0                    |    18.432K             |    0.472G |\\n'\n",
      " '|    up3.conv.double_conv.1                    |    64                  |    1.638M |\\n'\n",
      " '|    up3.conv.double_conv.3                    |    4.608K              |    0.118G |\\n'\n",
      " '|    up3.conv.double_conv.4                    |    32                  |    0.819M |\\n'\n",
      " '|   up3.up                                     |                        |   3.277M  |\\n'\n",
      " '|  up4                                         |  6.976K                |  0.721G   |\\n'\n",
      " '|   up4.conv.double_conv                       |   6.976K               |   0.714G  |\\n'\n",
      " '|    up4.conv.double_conv.0                    |    4.608K              |    0.472G |\\n'\n",
      " '|    up4.conv.double_conv.1                    |    32                  |    3.277M |\\n'\n",
      " '|    up4.conv.double_conv.3                    |    2.304K              |    0.236G |\\n'\n",
      " '|    up4.conv.double_conv.4                    |    32                  |    3.277M |\\n'\n",
      " '|   up4.up                                     |                        |   6.554M  |\\n'\n",
      " '|  outc.conv                                   |  1.36K                 |  0.131G   |\\n'\n",
      " '|   outc.conv.weight                           |   (80, 16, 1, 1)       |           |\\n'\n",
      " '|   outc.conv.bias                             |   (80,)                |           |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_SCALE = 0.25\n",
    "\n",
    "model = UNet(n_classes=80, mode=\"bilinear\", width_scale=WIDTH_SCALE, in_channels=3)\n",
    "model.eval()\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientvitFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                                | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                                 | 15.345M                | 3.834G     |\\n'\n",
      " '|  backbone                             |  14.977M               |  3.164G    |\\n'\n",
      " '|   backbone.stem_in_conv               |   0.696K               |   17.818M  |\\n'\n",
      " '|    backbone.stem_in_conv.conv         |    0.648K              |    16.589M |\\n'\n",
      " '|    backbone.stem_in_conv.norm         |    48                  |    1.229M  |\\n'\n",
      " '|   backbone.stem_res0.main             |   0.888K               |   22.733M  |\\n'\n",
      " '|    backbone.stem_res0.main.depth_conv |    0.264K              |    6.758M  |\\n'\n",
      " '|    backbone.stem_res0.main.point_conv |    0.624K              |    15.974M |\\n'\n",
      " '|   backbone.stages_0.blocks            |   50.304K              |   0.37G    |\\n'\n",
      " '|    backbone.stages_0.blocks.0.main    |    8.256K              |    0.101G  |\\n'\n",
      " '|    backbone.stages_0.blocks.1.main    |    21.024K             |    0.135G  |\\n'\n",
      " '|    backbone.stages_0.blocks.2.main    |    21.024K             |    0.135G  |\\n'\n",
      " '|   backbone.stages_1.blocks            |   0.267M               |   0.473G   |\\n'\n",
      " '|    backbone.stages_1.blocks.0.main    |    30.336K             |    94.618M |\\n'\n",
      " '|    backbone.stages_1.blocks.1.main    |    78.912K             |    0.126G  |\\n'\n",
      " '|    backbone.stages_1.blocks.2.main    |    78.912K             |    0.126G  |\\n'\n",
      " '|    backbone.stages_1.blocks.3.main    |    78.912K             |    0.126G  |\\n'\n",
      " '|   backbone.stages_2.blocks            |   2.2M                 |   0.962G   |\\n'\n",
      " '|    backbone.stages_2.blocks.0.main    |    0.115M              |    90.01M  |\\n'\n",
      " '|    backbone.stages_2.blocks.1         |    0.521M              |    0.218G  |\\n'\n",
      " '|    backbone.stages_2.blocks.2         |    0.521M              |    0.218G  |\\n'\n",
      " '|    backbone.stages_2.blocks.3         |    0.521M              |    0.218G  |\\n'\n",
      " '|    backbone.stages_2.blocks.4         |    0.521M              |    0.218G  |\\n'\n",
      " '|   backbone.stages_3.blocks            |   12.458M              |   1.318G   |\\n'\n",
      " '|    backbone.stages_3.blocks.0.main    |    0.452M              |    89.242M |\\n'\n",
      " '|    backbone.stages_3.blocks.1         |    2.001M              |    0.205G  |\\n'\n",
      " '|    backbone.stages_3.blocks.2         |    2.001M              |    0.205G  |\\n'\n",
      " '|    backbone.stages_3.blocks.3         |    2.001M              |    0.205G  |\\n'\n",
      " '|    backbone.stages_3.blocks.4         |    2.001M              |    0.205G  |\\n'\n",
      " '|    backbone.stages_3.blocks.5         |    2.001M              |    0.205G  |\\n'\n",
      " '|    backbone.stages_3.blocks.6         |    2.001M              |    0.205G  |\\n'\n",
      " '|  neck                                 |  0.194M                |  0.351G    |\\n'\n",
      " '|   neck.lateral_convs                  |   46.336K              |   36.864M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv          |    3.136K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv          |    6.208K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv          |    12.352K             |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv          |    24.64K              |    2.458M  |\\n'\n",
      " '|   neck.fpn_convs                      |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv              |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv              |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv              |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv              |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                                 |  0.174M                |  0.319G    |\\n'\n",
      " '|   head.conv_seg                       |   49                   |   0.307M   |\\n'\n",
      " '|    head.conv_seg.weight               |    (1, 48, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias                 |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads                    |   0.173M               |   0.315G   |\\n'\n",
      " '|    head.scale_heads.0.0               |    27.744K             |    0.178G  |\\n'\n",
      " '|    head.scale_heads.1                 |    27.744K             |    45.619M |\\n'\n",
      " '|    head.scale_heads.2                 |    48.576K             |    45.965M |\\n'\n",
      " '|    head.scale_heads.3                 |    69.408K             |    46.051M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientvit_b2.r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRNetFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 3.686M                 | 3.13G      |\\n'\n",
      " '|  backbone                        |  2.837M                |  1.661G    |\\n'\n",
      " '|   backbone.conv1                 |   1.728K               |   44.237M  |\\n'\n",
      " '|    backbone.conv1.weight         |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                   |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.conv2                 |   36.864K              |   0.236G   |\\n'\n",
      " '|    backbone.conv2.weight         |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   backbone.bn2                   |   0.128K               |   0.819M   |\\n'\n",
      " '|    backbone.bn2.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn2.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1.0              |   24.192K              |   0.155G   |\\n'\n",
      " '|    backbone.layer1.0.conv1       |    2.048K              |    13.107M |\\n'\n",
      " '|    backbone.layer1.0.bn1         |    64                  |    0.41M   |\\n'\n",
      " '|    backbone.layer1.0.conv2       |    9.216K              |    58.982M |\\n'\n",
      " '|    backbone.layer1.0.bn2         |    64                  |    0.41M   |\\n'\n",
      " '|    backbone.layer1.0.conv3       |    4.096K              |    26.214M |\\n'\n",
      " '|    backbone.layer1.0.bn3         |    0.256K              |    1.638M  |\\n'\n",
      " '|    backbone.layer1.0.downsample  |    8.448K              |    54.067M |\\n'\n",
      " '|   backbone.transition1           |   55.392K              |   0.177G   |\\n'\n",
      " '|    backbone.transition1.0        |    18.464K             |    0.118G  |\\n'\n",
      " '|    backbone.transition1.1.0      |    36.928K             |    59.085M |\\n'\n",
      " '|   backbone.stage2.0              |   51.68K               |   0.128G   |\\n'\n",
      " '|    backbone.stage2.0.branches    |    46.464K             |    0.119G  |\\n'\n",
      " '|    backbone.stage2.0.fuse_layers |    5.216K              |    8.448M  |\\n'\n",
      " '|   backbone.transition2.2.0       |   18.56K               |   7.424M   |\\n'\n",
      " '|    backbone.transition2.2.0.0    |    18.432K             |    7.373M  |\\n'\n",
      " '|    backbone.transition2.2.0.1    |    0.128K              |    51.2K   |\\n'\n",
      " '|   backbone.stage3.0              |   0.233M               |   0.203G   |\\n'\n",
      " '|    backbone.stage3.0.branches    |    0.194M              |    0.178G  |\\n'\n",
      " '|    backbone.stage3.0.fuse_layers |    38.624K             |    24.768M |\\n'\n",
      " '|   backbone.transition3.3.0       |   73.984K              |   7.398M   |\\n'\n",
      " '|    backbone.transition3.3.0.0    |    73.728K             |    7.373M  |\\n'\n",
      " '|    backbone.transition3.3.0.1    |    0.256K              |    25.6K   |\\n'\n",
      " '|   backbone.stage4.0              |   0.982M               |   0.285G   |\\n'\n",
      " '|    backbone.stage4.0.branches    |    0.785M              |    0.237G  |\\n'\n",
      " '|    backbone.stage4.0.fuse_layers |    0.197M              |    47.766M |\\n'\n",
      " '|   backbone.incre_modules         |   1.359M               |   0.414G   |\\n'\n",
      " '|    backbone.incre_modules.0.0    |    16.512K             |    0.106G  |\\n'\n",
      " '|    backbone.incre_modules.1.0    |    64.768K             |    0.104G  |\\n'\n",
      " '|    backbone.incre_modules.2.0    |    0.257M              |    0.103G  |\\n'\n",
      " '|    backbone.incre_modules.3.0    |    1.021M              |    0.102G  |\\n'\n",
      " '|  neck                            |  0.517M                |  0.853G    |\\n'\n",
      " '|   neck.lateral_convs             |   0.185M               |   0.147G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv     |    12.384K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv     |    24.672K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv     |    49.248K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv     |    98.4K               |    9.83M   |\\n'\n",
      " '|   neck.fpn_convs                 |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv         |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv         |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv         |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv         |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                            |  0.333M                |  0.615G    |\\n'\n",
      " '|   head.conv_seg                  |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight          |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias            |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads               |   0.333M               |   0.61G    |\\n'\n",
      " '|    head.scale_heads.0.0          |    55.424K             |    0.355G  |\\n'\n",
      " '|    head.scale_heads.1            |    55.424K             |    90.317M |\\n'\n",
      " '|    head.scale_heads.2            |    92.416K             |    83.405M |\\n'\n",
      " '|    head.scale_heads.3            |    0.129M              |    81.677M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"hrnet_w18_small\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 12.191M                | 9.403G     |\\n'\n",
      " '|  backbone                        |  10.948M               |  7.18G     |\\n'\n",
      " '|   backbone.conv1                 |   1.728K               |   44.237M  |\\n'\n",
      " '|    backbone.conv1.weight         |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                   |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.conv2                 |   36.864K              |   0.236G   |\\n'\n",
      " '|    backbone.conv2.weight         |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   backbone.bn2                   |   0.128K               |   0.819M   |\\n'\n",
      " '|    backbone.bn2.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn2.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1                |   0.286M               |   1.832G   |\\n'\n",
      " '|    backbone.layer1.0             |    75.008K             |    0.48G   |\\n'\n",
      " '|    backbone.layer1.1             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.2             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.3             |    70.4K               |    0.451G  |\\n'\n",
      " '|   backbone.transition1           |   0.125M               |   0.398G   |\\n'\n",
      " '|    backbone.transition1.0        |    41.508K             |    0.266G  |\\n'\n",
      " '|    backbone.transition1.1.0      |    83.016K             |    0.133G  |\\n'\n",
      " '|   backbone.stage2.0              |   0.124M               |   0.312G   |\\n'\n",
      " '|    backbone.stage2.0.branches    |    0.118M              |    0.301G  |\\n'\n",
      " '|    backbone.stage2.0.fuse_layers |    6.588K              |    10.656M |\\n'\n",
      " '|   backbone.transition2.2.0       |   23.472K              |   9.389M   |\\n'\n",
      " '|    backbone.transition2.2.0.0    |    23.328K             |    9.331M  |\\n'\n",
      " '|    backbone.transition2.2.0.1    |    0.144K              |    57.6K   |\\n'\n",
      " '|   backbone.stage3                |   2.163M               |   1.93G    |\\n'\n",
      " '|    backbone.stage3.0             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.1             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.2             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.3             |    0.541M              |    0.482G  |\\n'\n",
      " '|   backbone.transition3.3.0       |   93.6K                |   9.36M    |\\n'\n",
      " '|    backbone.transition3.3.0.0    |    93.312K             |    9.331M  |\\n'\n",
      " '|    backbone.transition3.3.0.1    |    0.288K              |    28.8K   |\\n'\n",
      " '|   backbone.stage4                |   6.709M               |   1.983G   |\\n'\n",
      " '|    backbone.stage4.0             |    2.236M              |    0.661G  |\\n'\n",
      " '|    backbone.stage4.1             |    2.236M              |    0.661G  |\\n'\n",
      " '|    backbone.stage4.2             |    2.236M              |    0.661G  |\\n'\n",
      " '|   backbone.incre_modules         |   1.386M               |   0.422G   |\\n'\n",
      " '|    backbone.incre_modules.0.0    |    16.832K             |    0.108G  |\\n'\n",
      " '|    backbone.incre_modules.1.0    |    66.048K             |    0.106G  |\\n'\n",
      " '|    backbone.incre_modules.2.0    |    0.262M              |    0.105G  |\\n'\n",
      " '|    backbone.incre_modules.3.0    |    1.041M              |    0.104G  |\\n'\n",
      " '|  neck                            |  0.837M                |  1.451G    |\\n'\n",
      " '|   neck.lateral_convs             |   0.246M               |   0.197G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv     |    16.512K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv     |    32.896K             |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.2.conv     |    65.664K             |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.3.conv     |    0.131M              |    13.107M |\\n'\n",
      " '|   neck.fpn_convs                 |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv         |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv         |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv         |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv         |    0.148M              |    14.746M |\\n'\n",
      " '|  head                            |  0.406M                |  0.772G    |\\n'\n",
      " '|   head.conv_seg                  |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight          |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias            |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads               |   0.406M               |   0.767G   |\\n'\n",
      " '|    head.scale_heads.0.0          |    73.856K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1            |    73.856K             |    0.12G   |\\n'\n",
      " '|    head.scale_heads.2            |    0.111M              |    90.778M |\\n'\n",
      " '|    head.scale_heads.3            |    0.148M              |    83.52M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"hrnet_w18\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 3.81M                  | 3.366G     |\\n'\n",
      " '|  backbone                        |  2.837M                |  1.661G    |\\n'\n",
      " '|   backbone.conv1                 |   1.728K               |   44.237M  |\\n'\n",
      " '|    backbone.conv1.weight         |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                   |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.conv2                 |   36.864K              |   0.236G   |\\n'\n",
      " '|    backbone.conv2.weight         |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   backbone.bn2                   |   0.128K               |   0.819M   |\\n'\n",
      " '|    backbone.bn2.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn2.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1.0              |   24.192K              |   0.155G   |\\n'\n",
      " '|    backbone.layer1.0.conv1       |    2.048K              |    13.107M |\\n'\n",
      " '|    backbone.layer1.0.bn1         |    64                  |    0.41M   |\\n'\n",
      " '|    backbone.layer1.0.conv2       |    9.216K              |    58.982M |\\n'\n",
      " '|    backbone.layer1.0.bn2         |    64                  |    0.41M   |\\n'\n",
      " '|    backbone.layer1.0.conv3       |    4.096K              |    26.214M |\\n'\n",
      " '|    backbone.layer1.0.bn3         |    0.256K              |    1.638M  |\\n'\n",
      " '|    backbone.layer1.0.downsample  |    8.448K              |    54.067M |\\n'\n",
      " '|   backbone.transition1           |   55.392K              |   0.177G   |\\n'\n",
      " '|    backbone.transition1.0        |    18.464K             |    0.118G  |\\n'\n",
      " '|    backbone.transition1.1.0      |    36.928K             |    59.085M |\\n'\n",
      " '|   backbone.stage2.0              |   51.68K               |   0.128G   |\\n'\n",
      " '|    backbone.stage2.0.branches    |    46.464K             |    0.119G  |\\n'\n",
      " '|    backbone.stage2.0.fuse_layers |    5.216K              |    8.448M  |\\n'\n",
      " '|   backbone.transition2.2.0       |   18.56K               |   7.424M   |\\n'\n",
      " '|    backbone.transition2.2.0.0    |    18.432K             |    7.373M  |\\n'\n",
      " '|    backbone.transition2.2.0.1    |    0.128K              |    51.2K   |\\n'\n",
      " '|   backbone.stage3.0              |   0.233M               |   0.203G   |\\n'\n",
      " '|    backbone.stage3.0.branches    |    0.194M              |    0.178G  |\\n'\n",
      " '|    backbone.stage3.0.fuse_layers |    38.624K             |    24.768M |\\n'\n",
      " '|   backbone.transition3.3.0       |   73.984K              |   7.398M   |\\n'\n",
      " '|    backbone.transition3.3.0.0    |    73.728K             |    7.373M  |\\n'\n",
      " '|    backbone.transition3.3.0.1    |    0.256K              |    25.6K   |\\n'\n",
      " '|   backbone.stage4.0              |   0.982M               |   0.285G   |\\n'\n",
      " '|    backbone.stage4.0.branches    |    0.785M              |    0.237G  |\\n'\n",
      " '|    backbone.stage4.0.fuse_layers |    0.197M              |    47.766M |\\n'\n",
      " '|   backbone.incre_modules         |   1.359M               |   0.414G   |\\n'\n",
      " '|    backbone.incre_modules.0.0    |    16.512K             |    0.106G  |\\n'\n",
      " '|    backbone.incre_modules.1.0    |    64.768K             |    0.104G  |\\n'\n",
      " '|    backbone.incre_modules.2.0    |    0.257M              |    0.103G  |\\n'\n",
      " '|    backbone.incre_modules.3.0    |    1.021M              |    0.102G  |\\n'\n",
      " '|  neck                            |  0.517M                |  0.853G    |\\n'\n",
      " '|   neck.lateral_convs             |   0.185M               |   0.147G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv     |    12.384K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv     |    24.672K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv     |    49.248K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv     |    98.4K               |    9.83M   |\\n'\n",
      " '|   neck.fpn_convs                 |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv         |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv         |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv         |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv         |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                            |  0.457M                |  0.851G    |\\n'\n",
      " '|   head.conv_seg                  |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight          |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias            |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads               |   0.45M                |   0.804G   |\\n'\n",
      " '|    head.scale_heads.0.0          |    69.28K              |    0.443G  |\\n'\n",
      " '|    head.scale_heads.1            |    69.28K              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.2            |    0.127M              |    0.123G  |\\n'\n",
      " '|    head.scale_heads.3            |    0.185M              |    0.125G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"hrnet_w18_small\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 12.334M                | 9.678G     |\\n'\n",
      " '|  backbone                        |  10.948M               |  7.18G     |\\n'\n",
      " '|   backbone.conv1                 |   1.728K               |   44.237M  |\\n'\n",
      " '|    backbone.conv1.weight         |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                   |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.conv2                 |   36.864K              |   0.236G   |\\n'\n",
      " '|    backbone.conv2.weight         |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   backbone.bn2                   |   0.128K               |   0.819M   |\\n'\n",
      " '|    backbone.bn2.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn2.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1                |   0.286M               |   1.832G   |\\n'\n",
      " '|    backbone.layer1.0             |    75.008K             |    0.48G   |\\n'\n",
      " '|    backbone.layer1.1             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.2             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.3             |    70.4K               |    0.451G  |\\n'\n",
      " '|   backbone.transition1           |   0.125M               |   0.398G   |\\n'\n",
      " '|    backbone.transition1.0        |    41.508K             |    0.266G  |\\n'\n",
      " '|    backbone.transition1.1.0      |    83.016K             |    0.133G  |\\n'\n",
      " '|   backbone.stage2.0              |   0.124M               |   0.312G   |\\n'\n",
      " '|    backbone.stage2.0.branches    |    0.118M              |    0.301G  |\\n'\n",
      " '|    backbone.stage2.0.fuse_layers |    6.588K              |    10.656M |\\n'\n",
      " '|   backbone.transition2.2.0       |   23.472K              |   9.389M   |\\n'\n",
      " '|    backbone.transition2.2.0.0    |    23.328K             |    9.331M  |\\n'\n",
      " '|    backbone.transition2.2.0.1    |    0.144K              |    57.6K   |\\n'\n",
      " '|   backbone.stage3                |   2.163M               |   1.93G    |\\n'\n",
      " '|    backbone.stage3.0             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.1             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.2             |    0.541M              |    0.482G  |\\n'\n",
      " '|    backbone.stage3.3             |    0.541M              |    0.482G  |\\n'\n",
      " '|   backbone.transition3.3.0       |   93.6K                |   9.36M    |\\n'\n",
      " '|    backbone.transition3.3.0.0    |    93.312K             |    9.331M  |\\n'\n",
      " '|    backbone.transition3.3.0.1    |    0.288K              |    28.8K   |\\n'\n",
      " '|   backbone.stage4                |   6.709M               |   1.983G   |\\n'\n",
      " '|    backbone.stage4.0             |    2.236M              |    0.661G  |\\n'\n",
      " '|    backbone.stage4.1             |    2.236M              |    0.661G  |\\n'\n",
      " '|    backbone.stage4.2             |    2.236M              |    0.661G  |\\n'\n",
      " '|   backbone.incre_modules         |   1.386M               |   0.422G   |\\n'\n",
      " '|    backbone.incre_modules.0.0    |    16.832K             |    0.108G  |\\n'\n",
      " '|    backbone.incre_modules.1.0    |    66.048K             |    0.106G  |\\n'\n",
      " '|    backbone.incre_modules.2.0    |    0.262M              |    0.105G  |\\n'\n",
      " '|    backbone.incre_modules.3.0    |    1.041M              |    0.104G  |\\n'\n",
      " '|  neck                            |  0.837M                |  1.451G    |\\n'\n",
      " '|   neck.lateral_convs             |   0.246M               |   0.197G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv     |    16.512K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv     |    32.896K             |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.2.conv     |    65.664K             |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.3.conv     |    0.131M              |    13.107M |\\n'\n",
      " '|   neck.fpn_convs                 |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv         |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv         |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv         |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv         |    0.148M              |    14.746M |\\n'\n",
      " '|  head                            |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg                  |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight          |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias            |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads               |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0          |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1            |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2            |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3            |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"hrnet_w18\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                           | #parameters or shape   | #flops     |\\n'\n",
      " '|:---------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                            | 28.747M                | 17.5G      |\\n'\n",
      " '|  backbone                        |  27.361M               |  15.002G   |\\n'\n",
      " '|   backbone.conv1                 |   1.728K               |   44.237M  |\\n'\n",
      " '|    backbone.conv1.weight         |    (64, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                   |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.conv2                 |   36.864K              |   0.236G   |\\n'\n",
      " '|    backbone.conv2.weight         |    (64, 64, 3, 3)      |            |\\n'\n",
      " '|   backbone.bn2                   |   0.128K               |   0.819M   |\\n'\n",
      " '|    backbone.bn2.weight           |    (64,)               |            |\\n'\n",
      " '|    backbone.bn2.bias             |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1                |   0.286M               |   1.832G   |\\n'\n",
      " '|    backbone.layer1.0             |    75.008K             |    0.48G   |\\n'\n",
      " '|    backbone.layer1.1             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.2             |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.3             |    70.4K               |    0.451G  |\\n'\n",
      " '|   backbone.transition1           |   0.208M               |   0.664G   |\\n'\n",
      " '|    backbone.transition1.0        |    69.18K              |    0.443G  |\\n'\n",
      " '|    backbone.transition1.1.0      |    0.138M              |    0.221G  |\\n'\n",
      " '|   backbone.stage2.0              |   0.344M               |   0.863G   |\\n'\n",
      " '|    backbone.stage2.0.branches    |    0.325M              |    0.834G  |\\n'\n",
      " '|    backbone.stage2.0.fuse_layers |    18.18K              |    29.28M  |\\n'\n",
      " '|   backbone.transition2.2.0       |   65.04K               |   26.016M  |\\n'\n",
      " '|    backbone.transition2.2.0.0    |    64.8K               |    25.92M  |\\n'\n",
      " '|    backbone.transition2.2.0.1    |    0.24K               |    96K     |\\n'\n",
      " '|   backbone.stage3                |   5.997M               |   5.342G   |\\n'\n",
      " '|    backbone.stage3.0             |    1.499M              |    1.336G  |\\n'\n",
      " '|    backbone.stage3.1             |    1.499M              |    1.336G  |\\n'\n",
      " '|    backbone.stage3.2             |    1.499M              |    1.336G  |\\n'\n",
      " '|    backbone.stage3.3             |    1.499M              |    1.336G  |\\n'\n",
      " '|   backbone.transition3.3.0       |   0.26M                |   25.968M  |\\n'\n",
      " '|    backbone.transition3.3.0.0    |    0.259M              |    25.92M  |\\n'\n",
      " '|    backbone.transition3.3.0.1    |    0.48K               |    48K     |\\n'\n",
      " '|   backbone.stage4                |   18.615M              |   5.493G   |\\n'\n",
      " '|    backbone.stage4.0             |    6.205M              |    1.831G  |\\n'\n",
      " '|    backbone.stage4.1             |    6.205M              |    1.831G  |\\n'\n",
      " '|    backbone.stage4.2             |    6.205M              |    1.831G  |\\n'\n",
      " '|   backbone.incre_modules         |   1.549M               |   0.471G   |\\n'\n",
      " '|    backbone.incre_modules.0.0    |    18.752K             |    0.12G   |\\n'\n",
      " '|    backbone.incre_modules.1.0    |    73.728K             |    0.118G  |\\n'\n",
      " '|    backbone.incre_modules.2.0    |    0.292M              |    0.117G  |\\n'\n",
      " '|    backbone.incre_modules.3.0    |    1.164M              |    0.116G  |\\n'\n",
      " '|  neck                            |  0.837M                |  1.451G    |\\n'\n",
      " '|   neck.lateral_convs             |   0.246M               |   0.197G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv     |    16.512K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv     |    32.896K             |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.2.conv     |    65.664K             |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.3.conv     |    0.131M              |    13.107M |\\n'\n",
      " '|   neck.fpn_convs                 |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv         |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv         |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv         |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv         |    0.148M              |    14.746M |\\n'\n",
      " '|  head                            |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg                  |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight          |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias            |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads               |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0          |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1            |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2            |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3            |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"hrnet_w30\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 3.674M                 | 0.909G     |\\n'\n",
      " '|  backbone                    |  3.595M                |  0.77G     |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   3.594M               |   0.747G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    1.448K              |    22.938M |\\n'\n",
      " '|    backbone.blocks.1         |    16.714K             |    0.123G  |\\n'\n",
      " '|    backbone.blocks.2         |    46.64K              |    81.517M |\\n'\n",
      " '|    backbone.blocks.3         |    0.243M              |    91.531M |\\n'\n",
      " '|    backbone.blocks.4         |    0.543M              |    0.179G  |\\n'\n",
      " '|    backbone.blocks.5         |    2.026M              |    0.189G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.717M              |    60.655M |\\n'\n",
      " '|  neck                        |  52.992K               |  88.026M   |\\n'\n",
      " '|   neck.lateral_convs         |   16K                  |   9.421M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.312K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.616K              |    1.434M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    10.272K             |    1.024M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  25.585K               |  50.64M    |\\n'\n",
      " '|   head.conv_seg              |   17                   |   0.102M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   25.568K              |   49.309M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    4.64K               |    29.696M |\\n'\n",
      " '|    head.scale_heads.1        |    4.64K               |    7.834M  |\\n'\n",
      " '|    head.scale_heads.2        |    6.976K              |    6.106M  |\\n'\n",
      " '|    head.scale_heads.3        |    9.312K              |    5.674M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 10.592M                | 2.895G     |\\n'\n",
      " '|  backbone                    |  10.103M               |  1.953G    |\\n'\n",
      " '|   backbone.conv_stem         |   1.08K                |   27.648M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (40, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   80                   |   2.048M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (40,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (40,)               |            |\\n'\n",
      " '|   backbone.blocks            |   10.102M              |   1.924G   |\\n'\n",
      " '|    backbone.blocks.0         |    3.504K              |    59.803M |\\n'\n",
      " '|    backbone.blocks.1         |    48.118K             |    0.326G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.111M              |    0.18G   |\\n'\n",
      " '|    backbone.blocks.3         |    0.639M              |    0.225G  |\\n'\n",
      " '|    backbone.blocks.4         |    1.388M              |    0.454G  |\\n'\n",
      " '|    backbone.blocks.5         |    4.629M              |    0.41G   |\\n'\n",
      " '|    backbone.blocks.6         |    3.284M              |    0.268G  |\\n'\n",
      " '|  neck                        |  0.39M                 |  0.742G    |\\n'\n",
      " '|   neck.lateral_convs         |   57.984K              |   35.942M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.704K              |    7.373M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    13.152K             |    5.222M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    36.96K              |    3.686M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  98.857K               |  0.2G      |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   98.832K              |   0.198G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    20.784K             |    0.133G  |\\n'\n",
      " '|    head.scale_heads.1        |    20.784K             |    33.869M |\\n'\n",
      " '|    head.scale_heads.2        |    26.016K             |    17.453M |\\n'\n",
      " '|    head.scale_heads.3        |    31.248K             |    13.349M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b3\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 28.107M                | 6.364G     |\\n'\n",
      " '|  backbone                    |  27.288M               |  4.79G     |\\n'\n",
      " '|   backbone.conv_stem         |   1.296K               |   33.178M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   96                   |   2.458M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (48,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (48,)               |            |\\n'\n",
      " '|   backbone.blocks            |   27.287M              |   4.754G   |\\n'\n",
      " '|    backbone.blocks.0         |    5.352K              |    89.704M |\\n'\n",
      " '|    backbone.blocks.1         |    0.123M              |    0.717G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.33M               |    0.486G  |\\n'\n",
      " '|    backbone.blocks.3         |    1.632M              |    0.559G  |\\n'\n",
      " '|    backbone.blocks.4         |    3.286M              |    1.069G  |\\n'\n",
      " '|    backbone.blocks.5         |    12.165M             |    1.043G  |\\n'\n",
      " '|    backbone.blocks.6         |    9.745M              |    0.79G   |\\n'\n",
      " '|  neck                        |  0.692M                |  1.316G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.102M               |   61.44M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    5.248K              |    32.768M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    8.32K               |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    22.656K             |    9.011M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    65.664K             |    6.554M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.127M                |  0.258G    |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.126M               |   0.256G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.696K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.696K             |    44.928M |\\n'\n",
      " '|    head.scale_heads.2        |    32.928K             |    20.218M |\\n'\n",
      " '|    head.scale_heads.3        |    38.16K              |    14.04M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b5\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 3.921M                 | 1.318G     |\\n'\n",
      " '|  backbone                    |  3.595M                |  0.77G     |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   3.594M               |   0.747G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    1.448K              |    22.938M |\\n'\n",
      " '|    backbone.blocks.1         |    16.714K             |    0.123G  |\\n'\n",
      " '|    backbone.blocks.2         |    46.64K              |    81.517M |\\n'\n",
      " '|    backbone.blocks.3         |    0.243M              |    91.531M |\\n'\n",
      " '|    backbone.blocks.4         |    0.543M              |    0.179G  |\\n'\n",
      " '|    backbone.blocks.5         |    2.026M              |    0.189G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.717M              |    60.655M |\\n'\n",
      " '|  neck                        |  52.992K               |  88.026M   |\\n'\n",
      " '|   neck.lateral_convs         |   16K                  |   9.421M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.312K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.616K              |    1.434M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    10.272K             |    1.024M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  0.273M                |  0.46G     |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.266M               |   0.412G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    23.2K               |    0.148G  |\\n'\n",
      " '|    head.scale_heads.1        |    23.2K               |    39.168M |\\n'\n",
      " '|    head.scale_heads.2        |    80.96K              |    0.104G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.139M              |    0.121G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 10.95M                 | 3.546G     |\\n'\n",
      " '|  backbone                    |  10.103M               |  1.953G    |\\n'\n",
      " '|   backbone.conv_stem         |   1.08K                |   27.648M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (40, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   80                   |   2.048M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (40,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (40,)               |            |\\n'\n",
      " '|   backbone.blocks            |   10.102M              |   1.924G   |\\n'\n",
      " '|    backbone.blocks.0         |    3.504K              |    59.803M |\\n'\n",
      " '|    backbone.blocks.1         |    48.118K             |    0.326G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.111M              |    0.18G   |\\n'\n",
      " '|    backbone.blocks.3         |    0.639M              |    0.225G  |\\n'\n",
      " '|    backbone.blocks.4         |    1.388M              |    0.454G  |\\n'\n",
      " '|    backbone.blocks.5         |    4.629M              |    0.41G   |\\n'\n",
      " '|    backbone.blocks.6         |    3.284M              |    0.268G  |\\n'\n",
      " '|  neck                        |  0.39M                 |  0.742G    |\\n'\n",
      " '|   neck.lateral_convs         |   57.984K              |   35.942M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.704K              |    7.373M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    13.152K             |    5.222M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    36.96K              |    3.686M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.457M                |  0.851G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.45M                |   0.804G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    69.28K              |    0.443G  |\\n'\n",
      " '|    head.scale_heads.1        |    69.28K              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.127M              |    0.123G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.185M              |    0.125G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b3\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 28.529M                | 7.153G     |\\n'\n",
      " '|  backbone                    |  27.288M               |  4.79G     |\\n'\n",
      " '|   backbone.conv_stem         |   1.296K               |   33.178M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   96                   |   2.458M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (48,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (48,)               |            |\\n'\n",
      " '|   backbone.blocks            |   27.287M              |   4.754G   |\\n'\n",
      " '|    backbone.blocks.0         |    5.352K              |    89.704M |\\n'\n",
      " '|    backbone.blocks.1         |    0.123M              |    0.717G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.33M               |    0.486G  |\\n'\n",
      " '|    backbone.blocks.3         |    1.632M              |    0.559G  |\\n'\n",
      " '|    backbone.blocks.4         |    3.286M              |    1.069G  |\\n'\n",
      " '|    backbone.blocks.5         |    12.165M             |    1.043G  |\\n'\n",
      " '|    backbone.blocks.6         |    9.745M              |    0.79G   |\\n'\n",
      " '|  neck                        |  0.692M                |  1.316G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.102M               |   61.44M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    5.248K              |    32.768M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    8.32K               |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    22.656K             |    9.011M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    65.664K             |    6.554M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0      |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1        |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnet_b5\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetV2FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 12.504M                | 4.092G     |\\n'\n",
      " '|  backbone                    |  12.409M               |  3.918G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   12.409M              |   3.901G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.464K             |    0.268G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.218M              |    1.396G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.344M              |    0.55G   |\\n'\n",
      " '|    backbone.blocks.3         |    0.608M              |    0.209G  |\\n'\n",
      " '|    backbone.blocks.4         |    2.241M              |    0.724G  |\\n'\n",
      " '|    backbone.blocks.5         |    8.988M              |    0.755G  |\\n'\n",
      " '|  neck                        |  50.688K               |  91.558M   |\\n'\n",
      " '|   neck.lateral_convs         |   13.696K              |   12.954M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.312K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    4.128K              |    1.638M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.688K              |    0.666M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  43.561K               |  82.181M   |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   43.536K              |   80.184M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    6.96K               |    44.544M |\\n'\n",
      " '|    head.scale_heads.1        |    6.96K               |    11.75M  |\\n'\n",
      " '|    head.scale_heads.2        |    12.192K             |    11.923M |\\n'\n",
      " '|    head.scale_heads.3        |    17.424K             |    11.966M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnetv2_rw_t\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 21.911M                | 6.491G     |\\n'\n",
      " '|  backbone                    |  21.657M               |  6.004G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   21.657M              |   5.986G   |\\n'\n",
      " '|    backbone.blocks.0         |    11.712K             |    0.3G    |\\n'\n",
      " '|    backbone.blocks.1         |    0.304M              |    1.943G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.589M              |    0.943G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.918M              |    0.318G  |\\n'\n",
      " '|    backbone.blocks.4         |    3.464M              |    1.117G  |\\n'\n",
      " '|    backbone.blocks.5         |    16.371M             |    1.366G  |\\n'\n",
      " '|  neck                        |  0.183M                |  0.346G    |\\n'\n",
      " '|   neck.lateral_convs         |   35.072K              |   32.051M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.136K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    10.304K             |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    17.472K             |    1.741M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  71.209K               |  0.141G    |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   71.184K              |   0.139G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    13.872K             |    88.781M |\\n'\n",
      " '|    head.scale_heads.1        |    13.872K             |    22.81M  |\\n'\n",
      " '|    head.scale_heads.2        |    19.104K             |    14.688M |\\n'\n",
      " '|    head.scale_heads.3        |    24.336K             |    12.658M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnetv2_rw_s\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 12.733M                | 4.469G     |\\n'\n",
      " '|  backbone                    |  12.409M               |  3.918G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   12.409M              |   3.901G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.464K             |    0.268G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.218M              |    1.396G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.344M              |    0.55G   |\\n'\n",
      " '|    backbone.blocks.3         |    0.608M              |    0.209G  |\\n'\n",
      " '|    backbone.blocks.4         |    2.241M              |    0.724G  |\\n'\n",
      " '|    backbone.blocks.5         |    8.988M              |    0.755G  |\\n'\n",
      " '|  neck                        |  50.688K               |  91.558M   |\\n'\n",
      " '|   neck.lateral_convs         |   13.696K              |   12.954M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.312K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    4.128K              |    1.638M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.688K              |    0.666M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  0.273M                |  0.46G     |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.266M               |   0.412G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    23.2K               |    0.148G  |\\n'\n",
      " '|    head.scale_heads.1        |    23.2K               |    39.168M |\\n'\n",
      " '|    head.scale_heads.2        |    80.96K              |    0.104G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.139M              |    0.121G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnetv2_rw_t\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 22.205M                | 7.005G     |\\n'\n",
      " '|  backbone                    |  21.657M               |  6.004G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   21.657M              |   5.986G   |\\n'\n",
      " '|    backbone.blocks.0         |    11.712K             |    0.3G    |\\n'\n",
      " '|    backbone.blocks.1         |    0.304M              |    1.943G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.589M              |    0.943G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.918M              |    0.318G  |\\n'\n",
      " '|    backbone.blocks.4         |    3.464M              |    1.117G  |\\n'\n",
      " '|    backbone.blocks.5         |    16.371M             |    1.366G  |\\n'\n",
      " '|  neck                        |  0.183M                |  0.346G    |\\n'\n",
      " '|   neck.lateral_convs         |   35.072K              |   32.051M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.136K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    10.304K             |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    17.472K             |    1.741M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"efficientnetv2_rw_s\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RepVGGFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.035M                 | 3.404G     |\\n'\n",
      " '|  backbone                       |  7.828M                |  3.102G    |\\n'\n",
      " '|   backbone.stem                 |   1.632K               |   41.779M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.392K              |    35.635M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.24K               |    6.144M  |\\n'\n",
      " '|   backbone.stages_0             |   46.56K               |   0.298G   |\\n'\n",
      " '|    backbone.stages_0.0          |    23.232K             |    0.149G  |\\n'\n",
      " '|    backbone.stages_0.1          |    23.328K             |    0.149G  |\\n'\n",
      " '|   backbone.stages_1             |   0.325M               |   0.519G   |\\n'\n",
      " '|    backbone.stages_1.0          |    46.464K             |    74.342M |\\n'\n",
      " '|    backbone.stages_1.1          |    92.736K             |    0.148G  |\\n'\n",
      " '|    backbone.stages_1.2          |    92.736K             |    0.148G  |\\n'\n",
      " '|    backbone.stages_1.3          |    92.736K             |    0.148G  |\\n'\n",
      " '|   backbone.stages_2             |   4.992M               |   1.997G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.185M              |    74.035M |\\n'\n",
      " '|    backbone.stages_2.1          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.2          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.4          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.6          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.8          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.10         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.12         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.37M               |    0.148G  |\\n'\n",
      " '|   backbone.stages_3.0           |   2.463M               |   0.246G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    2.214M              |    0.221G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.248M              |    24.832M |\\n'\n",
      " '|  neck                           |  88.832K               |  99.904M   |\\n'\n",
      " '|   neck.lateral_convs            |   51.84K               |   21.299M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    40.992K             |    4.096M  |\\n'\n",
      " '|   neck.fpn_convs                |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.118M                |  0.202G    |\\n'\n",
      " '|   head.conv_seg                 |   49                   |   0.307M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 48, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.118M               |   0.198G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    13.92K              |    89.088M |\\n'\n",
      " '|    head.scale_heads.1           |    13.92K              |    23.501M |\\n'\n",
      " '|    head.scale_heads.2           |    34.752K             |    40.435M |\\n'\n",
      " '|    head.scale_heads.3           |    55.584K             |    44.669M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 13.642M                | 6.784G     |\\n'\n",
      " '|  backbone                       |  12.811M               |  5.382G    |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   82.56K               |   0.528G   |\\n'\n",
      " '|    backbone.stages_0.0          |    41.216K             |    0.264G  |\\n'\n",
      " '|    backbone.stages_0.1          |    41.344K             |    0.265G  |\\n'\n",
      " '|   backbone.stages_1             |   0.576M               |   0.922G   |\\n'\n",
      " '|    backbone.stages_1.0          |    82.432K             |    0.132G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.165M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.165M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.165M              |    0.263G  |\\n'\n",
      " '|   backbone.stages_2             |   8.868M               |   3.547G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.329M              |    0.131G  |\\n'\n",
      " '|    backbone.stages_2.1          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.2          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.4          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.6          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.8          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.10         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.12         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.657M              |    0.263G  |\\n'\n",
      " '|   backbone.stages_3.0           |   3.282M               |   0.328G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    2.952M              |    0.295G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.33M               |    33.024M |\\n'\n",
      " '|  neck                           |  0.498M                |  0.787G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    6.24K               |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    12.384K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    24.672K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.333M                |  0.615G    |\\n'\n",
      " '|   head.conv_seg                 |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.333M               |   0.61G    |\\n'\n",
      " '|    head.scale_heads.0.0         |    55.424K             |    0.355G  |\\n'\n",
      " '|    head.scale_heads.1           |    55.424K             |    90.317M |\\n'\n",
      " '|    head.scale_heads.2           |    92.416K             |    83.405M |\\n'\n",
      " '|    head.scale_heads.3           |    0.129M              |    81.677M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a1\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 28.065M                | 13.815G    |\\n'\n",
      " '|  backbone                       |  26.802M               |  11.632G   |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   0.155M               |   0.989G   |\\n'\n",
      " '|    backbone.stages_0.0          |    61.824K             |    0.396G  |\\n'\n",
      " '|    backbone.stages_0.1          |    92.736K             |    0.594G  |\\n'\n",
      " '|   backbone.stages_1             |   1.294M               |   2.071G   |\\n'\n",
      " '|    backbone.stages_1.0          |    0.185M              |    0.296G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.37M               |    0.592G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.37M               |    0.592G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.37M               |    0.592G  |\\n'\n",
      " '|   backbone.stages_2             |   19.938M              |   7.975G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.739M              |    0.296G  |\\n'\n",
      " '|    backbone.stages_2.1          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.2          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.3          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.4          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.5          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.6          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.7          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.8          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.9          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.10         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.11         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.12         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.13         |    1.477M              |    0.591G  |\\n'\n",
      " '|   backbone.stages_3.0           |   5.412M               |   0.541G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    4.869M              |    0.487G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.543M              |    54.349M |\\n'\n",
      " '|  neck                           |  0.857M                |  1.41G     |\\n'\n",
      " '|   neck.lateral_convs            |   0.267M               |   0.156G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    12.416K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    24.704K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    49.28K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.18M               |    18.022M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.406M                |  0.772G    |\\n'\n",
      " '|   head.conv_seg                 |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.406M               |   0.767G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    73.856K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1           |    73.856K             |    0.12G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    90.778M |\\n'\n",
      " '|    head.scale_heads.3           |    0.148M              |    83.52M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a2\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 39.291M                | 18.859G    |\\n'\n",
      " '|  backbone                       |  37.917M               |  16.623G   |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   0.33M                |   2.115G   |\\n'\n",
      " '|    backbone.stages_0.0          |    82.432K             |    0.528G  |\\n'\n",
      " '|    backbone.stages_0.1          |    41.728K             |    0.267G  |\\n'\n",
      " '|    backbone.stages_0.2          |    0.165M              |    1.053G  |\\n'\n",
      " '|    backbone.stages_0.3          |    41.728K             |    0.267G  |\\n'\n",
      " '|   backbone.stages_1             |   2.139M               |   3.422G   |\\n'\n",
      " '|    backbone.stages_1.0          |    0.329M              |    0.526G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.165M              |    0.265G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.165M              |    0.265G  |\\n'\n",
      " '|    backbone.stages_1.4          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.5          |    0.165M              |    0.265G  |\\n'\n",
      " '|   backbone.stages_2             |   24.952M              |   9.981G   |\\n'\n",
      " '|    backbone.stages_2.0          |    1.313M              |    0.525G  |\\n'\n",
      " '|    backbone.stages_2.1          |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.2          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.3          |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.4          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.5          |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.6          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.7          |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.8          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.9          |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.10         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.11         |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.12         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.13         |    0.658M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.14         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.15         |    0.658M              |    0.263G  |\\n'\n",
      " '|   backbone.stages_3.0           |   10.494M              |   1.049G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    9.441M              |    0.944G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    1.053M              |    0.105G  |\\n'\n",
      " '|  neck                           |  0.968M                |  1.464G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.377M               |   0.21G    |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    16.512K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    32.896K             |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    65.664K             |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.262M              |    26.214M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.406M                |  0.772G    |\\n'\n",
      " '|   head.conv_seg                 |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.406M               |   0.767G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    73.856K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1           |    73.856K             |    0.12G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    90.778M |\\n'\n",
      " '|    head.scale_heads.3           |    0.148M              |    83.52M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_b1g4\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 56.74M                 | 29.083G    |\\n'\n",
      " '|  backbone                       |  55.366M               |  26.846G   |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   0.576M               |   3.688G   |\\n'\n",
      " '|    backbone.stages_0.0          |    82.432K             |    0.528G  |\\n'\n",
      " '|    backbone.stages_0.1          |    0.165M              |    1.053G  |\\n'\n",
      " '|    backbone.stages_0.2          |    0.165M              |    1.053G  |\\n'\n",
      " '|    backbone.stages_0.3          |    0.165M              |    1.053G  |\\n'\n",
      " '|   backbone.stages_1             |   3.613M               |   5.781G   |\\n'\n",
      " '|    backbone.stages_1.0          |    0.329M              |    0.526G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.4          |    0.657M              |    1.051G  |\\n'\n",
      " '|    backbone.stages_1.5          |    0.657M              |    1.051G  |\\n'\n",
      " '|   backbone.stages_2             |   40.68M               |   16.272G  |\\n'\n",
      " '|    backbone.stages_2.0          |    1.313M              |    0.525G  |\\n'\n",
      " '|    backbone.stages_2.1          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.2          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.3          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.4          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.5          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.6          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.7          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.8          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.9          |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.10         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.11         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.12         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.13         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.14         |    2.625M              |    1.05G   |\\n'\n",
      " '|    backbone.stages_2.15         |    2.625M              |    1.05G   |\\n'\n",
      " '|   backbone.stages_3.0           |   10.494M              |   1.049G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    9.441M              |    0.944G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    1.053M              |    0.105G  |\\n'\n",
      " '|  neck                           |  0.968M                |  1.464G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.377M               |   0.21G    |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    16.512K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    32.896K             |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    65.664K             |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.262M              |    26.214M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.406M                |  0.772G    |\\n'\n",
      " '|   head.conv_seg                 |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.406M               |   0.767G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    73.856K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1           |    73.856K             |    0.12G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    90.778M |\\n'\n",
      " '|    head.scale_heads.3           |    0.148M              |    83.52M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_b1\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.189M                 | 3.662G     |\\n'\n",
      " '|  backbone                       |  7.828M                |  3.102G    |\\n'\n",
      " '|   backbone.stem                 |   1.632K               |   41.779M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.392K              |    35.635M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.24K               |    6.144M  |\\n'\n",
      " '|   backbone.stages_0             |   46.56K               |   0.298G   |\\n'\n",
      " '|    backbone.stages_0.0          |    23.232K             |    0.149G  |\\n'\n",
      " '|    backbone.stages_0.1          |    23.328K             |    0.149G  |\\n'\n",
      " '|   backbone.stages_1             |   0.325M               |   0.519G   |\\n'\n",
      " '|    backbone.stages_1.0          |    46.464K             |    74.342M |\\n'\n",
      " '|    backbone.stages_1.1          |    92.736K             |    0.148G  |\\n'\n",
      " '|    backbone.stages_1.2          |    92.736K             |    0.148G  |\\n'\n",
      " '|    backbone.stages_1.3          |    92.736K             |    0.148G  |\\n'\n",
      " '|   backbone.stages_2             |   4.992M               |   1.997G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.185M              |    74.035M |\\n'\n",
      " '|    backbone.stages_2.1          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.2          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.4          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.6          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.8          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.10         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.12         |    0.37M               |    0.148G  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.37M               |    0.148G  |\\n'\n",
      " '|   backbone.stages_3.0           |   2.463M               |   0.246G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    2.214M              |    0.221G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.248M              |    24.832M |\\n'\n",
      " '|  neck                           |  88.832K               |  99.904M   |\\n'\n",
      " '|   neck.lateral_convs            |   51.84K               |   21.299M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    40.992K             |    4.096M  |\\n'\n",
      " '|   neck.fpn_convs                |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.273M                |  0.46G     |\\n'\n",
      " '|   head.conv_seg                 |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.266M               |   0.412G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    23.2K               |    0.148G  |\\n'\n",
      " '|    head.scale_heads.1           |    23.2K               |    39.168M |\\n'\n",
      " '|    head.scale_heads.2           |    80.96K              |    0.104G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.139M              |    0.121G  |')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 13.767M                | 7.02G      |\\n'\n",
      " '|  backbone                       |  12.811M               |  5.382G    |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   82.56K               |   0.528G   |\\n'\n",
      " '|    backbone.stages_0.0          |    41.216K             |    0.264G  |\\n'\n",
      " '|    backbone.stages_0.1          |    41.344K             |    0.265G  |\\n'\n",
      " '|   backbone.stages_1             |   0.576M               |   0.922G   |\\n'\n",
      " '|    backbone.stages_1.0          |    82.432K             |    0.132G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.165M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.165M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.165M              |    0.263G  |\\n'\n",
      " '|   backbone.stages_2             |   8.868M               |   3.547G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.329M              |    0.131G  |\\n'\n",
      " '|    backbone.stages_2.1          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.2          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.4          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.6          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.8          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.10         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.12         |    0.657M              |    0.263G  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.657M              |    0.263G  |\\n'\n",
      " '|   backbone.stages_3.0           |   3.282M               |   0.328G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    2.952M              |    0.295G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.33M               |    33.024M |\\n'\n",
      " '|  neck                           |  0.498M                |  0.787G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    6.24K               |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    12.384K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    24.672K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.457M                |  0.851G    |\\n'\n",
      " '|   head.conv_seg                 |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.45M                |   0.804G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    69.28K              |    0.443G  |\\n'\n",
      " '|    head.scale_heads.1           |    69.28K              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.127M              |    0.123G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.185M              |    0.125G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a1\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 28.208M                | 14.09G     |\\n'\n",
      " '|  backbone                       |  26.802M               |  11.632G   |\\n'\n",
      " '|   backbone.stem                 |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_1x1       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0             |   0.155M               |   0.989G   |\\n'\n",
      " '|    backbone.stages_0.0          |    61.824K             |    0.396G  |\\n'\n",
      " '|    backbone.stages_0.1          |    92.736K             |    0.594G  |\\n'\n",
      " '|   backbone.stages_1             |   1.294M               |   2.071G   |\\n'\n",
      " '|    backbone.stages_1.0          |    0.185M              |    0.296G  |\\n'\n",
      " '|    backbone.stages_1.1          |    0.37M               |    0.592G  |\\n'\n",
      " '|    backbone.stages_1.2          |    0.37M               |    0.592G  |\\n'\n",
      " '|    backbone.stages_1.3          |    0.37M               |    0.592G  |\\n'\n",
      " '|   backbone.stages_2             |   19.938M              |   7.975G   |\\n'\n",
      " '|    backbone.stages_2.0          |    0.739M              |    0.296G  |\\n'\n",
      " '|    backbone.stages_2.1          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.2          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.3          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.4          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.5          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.6          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.7          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.8          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.9          |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.10         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.11         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.12         |    1.477M              |    0.591G  |\\n'\n",
      " '|    backbone.stages_2.13         |    1.477M              |    0.591G  |\\n'\n",
      " '|   backbone.stages_3.0           |   5.412M               |   0.541G   |\\n'\n",
      " '|    backbone.stages_3.0.conv_kxk |    4.869M              |    0.487G  |\\n'\n",
      " '|    backbone.stages_3.0.conv_1x1 |    0.543M              |    54.349M |\\n'\n",
      " '|  neck                           |  0.857M                |  1.41G     |\\n'\n",
      " '|   neck.lateral_convs            |   0.267M               |   0.156G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    12.416K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    24.704K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    49.28K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.18M               |    18.022M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg                 |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0         |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1           |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"repvgg_a2\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 11.517M                | 4.274G     |\\n'\n",
      " '|  backbone                    |  11.177M               |  3.711G    |\\n'\n",
      " '|   backbone.conv1             |   9.408K               |   0.241G   |\\n'\n",
      " '|    backbone.conv1.weight     |    (64, 3, 7, 7)       |            |\\n'\n",
      " '|   backbone.bn1               |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1            |   0.148M               |   0.947G   |\\n'\n",
      " '|    backbone.layer1.0         |    73.984K             |    0.473G  |\\n'\n",
      " '|    backbone.layer1.1         |    73.984K             |    0.473G  |\\n'\n",
      " '|   backbone.layer2            |   0.526M               |   0.841G   |\\n'\n",
      " '|    backbone.layer2.0         |    0.23M               |    0.368G  |\\n'\n",
      " '|    backbone.layer2.1         |    0.295M              |    0.473G  |\\n'\n",
      " '|   backbone.layer3            |   2.1M                 |   0.84G    |\\n'\n",
      " '|    backbone.layer3.0         |    0.919M              |    0.368G  |\\n'\n",
      " '|    backbone.layer3.1         |    1.181M              |    0.472G  |\\n'\n",
      " '|   backbone.layer4            |   8.394M               |   0.839G   |\\n'\n",
      " '|    backbone.layer4.0         |    3.673M              |    0.367G  |\\n'\n",
      " '|    backbone.layer4.1         |    4.721M              |    0.472G  |\\n'\n",
      " '|  neck                        |  67.84K                |  0.103G    |\\n'\n",
      " '|   neck.lateral_convs         |   30.848K              |   24.576M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.08K               |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.128K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    8.224K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    16.416K             |    1.638M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  0.273M                |  0.46G     |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.266M               |   0.412G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    23.2K               |    0.148G  |\\n'\n",
      " '|    head.scale_heads.1        |    23.2K               |    39.168M |\\n'\n",
      " '|    head.scale_heads.2        |    80.96K              |    0.104G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.139M              |    0.121G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"resnet18\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 21.859M                | 8.51G      |\\n'\n",
      " '|  backbone                    |  21.285M               |  7.491G    |\\n'\n",
      " '|   backbone.conv1             |   9.408K               |   0.241G   |\\n'\n",
      " '|    backbone.conv1.weight     |    (64, 3, 7, 7)       |            |\\n'\n",
      " '|   backbone.bn1               |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1            |   0.222M               |   1.42G    |\\n'\n",
      " '|    backbone.layer1.0         |    73.984K             |    0.473G  |\\n'\n",
      " '|    backbone.layer1.1         |    73.984K             |    0.473G  |\\n'\n",
      " '|    backbone.layer1.2         |    73.984K             |    0.473G  |\\n'\n",
      " '|   backbone.layer2            |   1.116M               |   1.786G   |\\n'\n",
      " '|    backbone.layer2.0         |    0.23M               |    0.368G  |\\n'\n",
      " '|    backbone.layer2.1         |    0.295M              |    0.473G  |\\n'\n",
      " '|    backbone.layer2.2         |    0.295M              |    0.473G  |\\n'\n",
      " '|    backbone.layer2.3         |    0.295M              |    0.473G  |\\n'\n",
      " '|   backbone.layer3            |   6.822M               |   2.729G   |\\n'\n",
      " '|    backbone.layer3.0         |    0.919M              |    0.368G  |\\n'\n",
      " '|    backbone.layer3.1         |    1.181M              |    0.472G  |\\n'\n",
      " '|    backbone.layer3.2         |    1.181M              |    0.472G  |\\n'\n",
      " '|    backbone.layer3.3         |    1.181M              |    0.472G  |\\n'\n",
      " '|    backbone.layer3.4         |    1.181M              |    0.472G  |\\n'\n",
      " '|    backbone.layer3.5         |    1.181M              |    0.472G  |\\n'\n",
      " '|   backbone.layer4            |   13.114M              |   1.311G   |\\n'\n",
      " '|    backbone.layer4.0         |    3.673M              |    0.367G  |\\n'\n",
      " '|    backbone.layer4.1         |    4.721M              |    0.472G  |\\n'\n",
      " '|    backbone.layer4.2         |    4.721M              |    0.472G  |\\n'\n",
      " '|  neck                        |  0.209M                |  0.363G    |\\n'\n",
      " '|   neck.lateral_convs         |   61.696K              |   49.152M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.16K               |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    8.256K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    16.448K             |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    32.832K             |    3.277M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"resnet34\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 25.139M                | 11.081G    |\\n'\n",
      " '|  backbone                    |  23.508M               |  8.386G    |\\n'\n",
      " '|   backbone.conv1             |   9.408K               |   0.241G   |\\n'\n",
      " '|    backbone.conv1.weight     |    (64, 3, 7, 7)       |            |\\n'\n",
      " '|   backbone.bn1               |   0.128K               |   3.277M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (64,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (64,)               |            |\\n'\n",
      " '|   backbone.layer1            |   0.216M               |   1.381G   |\\n'\n",
      " '|    backbone.layer1.0         |    75.008K             |    0.48G   |\\n'\n",
      " '|    backbone.layer1.1         |    70.4K               |    0.451G  |\\n'\n",
      " '|    backbone.layer1.2         |    70.4K               |    0.451G  |\\n'\n",
      " '|   backbone.layer2            |   1.22M                |   2.11G    |\\n'\n",
      " '|    backbone.layer2.0         |    0.379M              |    0.766G  |\\n'\n",
      " '|    backbone.layer2.1         |    0.28M               |    0.448G  |\\n'\n",
      " '|    backbone.layer2.2         |    0.28M               |    0.448G  |\\n'\n",
      " '|    backbone.layer2.3         |    0.28M               |    0.448G  |\\n'\n",
      " '|   backbone.layer3            |   7.098M               |   2.997G   |\\n'\n",
      " '|    backbone.layer3.0         |    1.512M              |    0.763G  |\\n'\n",
      " '|    backbone.layer3.1         |    1.117M              |    0.447G  |\\n'\n",
      " '|    backbone.layer3.2         |    1.117M              |    0.447G  |\\n'\n",
      " '|    backbone.layer3.3         |    1.117M              |    0.447G  |\\n'\n",
      " '|    backbone.layer3.4         |    1.117M              |    0.447G  |\\n'\n",
      " '|    backbone.layer3.5         |    1.117M              |    0.447G  |\\n'\n",
      " '|   backbone.layer4            |   14.965M              |   1.654G   |\\n'\n",
      " '|    backbone.layer4.0         |    6.04M               |    0.762G  |\\n'\n",
      " '|    backbone.layer4.1         |    4.463M              |    0.446G  |\\n'\n",
      " '|    backbone.layer4.2         |    4.463M              |    0.446G  |\\n'\n",
      " '|  neck                        |  1.082M                |  1.648G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.492M               |   0.393G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    32.896K             |    0.21G   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    65.664K             |    0.105G  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    0.131M              |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.262M              |    26.214M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0      |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1        |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"resnet50\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNextFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee448bd00f61433f837a016beccfb12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 29.143M                | 11.571G    |\\n'\n",
      " '|  backbone                       |  27.819M               |  9.122G    |\\n'\n",
      " '|   backbone.stem_0               |   4.704K               |   29.491M  |\\n'\n",
      " '|    backbone.stem_0.weight       |    (96, 3, 4, 4)       |            |\\n'\n",
      " '|    backbone.stem_0.bias         |    (96,)               |            |\\n'\n",
      " '|   backbone.stem_1               |   0.192K               |   3.072M   |\\n'\n",
      " '|    backbone.stem_1.weight       |    (96,)               |            |\\n'\n",
      " '|    backbone.stem_1.bias         |    (96,)               |            |\\n'\n",
      " '|   backbone.stages_0.blocks      |   0.238M               |   1.515G   |\\n'\n",
      " '|    backbone.stages_0.blocks.0   |    79.296K             |    0.505G  |\\n'\n",
      " '|    backbone.stages_0.blocks.1   |    79.296K             |    0.505G  |\\n'\n",
      " '|    backbone.stages_0.blocks.2   |    79.296K             |    0.505G  |\\n'\n",
      " '|   backbone.stages_1             |   0.992M               |   1.586G   |\\n'\n",
      " '|    backbone.stages_1.downsample |    74.112K             |    0.121G  |\\n'\n",
      " '|    backbone.stages_1.blocks     |    0.918M              |    1.465G  |\\n'\n",
      " '|   backbone.stages_2             |   11.113M              |   4.441G   |\\n'\n",
      " '|    backbone.stages_2.downsample |    0.296M              |    0.12G   |\\n'\n",
      " '|    backbone.stages_2.blocks     |    10.817M             |    4.321G  |\\n'\n",
      " '|   backbone.stages_3             |   15.471M              |   1.547G   |\\n'\n",
      " '|    backbone.stages_3.downsample |    1.181M              |    0.119G  |\\n'\n",
      " '|    backbone.stages_3.blocks     |    14.289M             |    1.428G  |\\n'\n",
      " '|  neck                           |  0.775M                |  1.402G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.185M               |   0.147G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    12.416K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    24.704K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    49.28K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    98.432K             |    9.83M   |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg                 |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0         |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1           |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"convnext_tiny\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetOneFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 4.817M                 | 3.145G     |\\n'\n",
      " '|  backbone                       |  4.268M                |  2.219G    |\\n'\n",
      " '|   backbone.stem                 |   1.632K               |   41.779M  |\\n'\n",
      " '|    backbone.stem.conv_kxk.0     |    1.392K              |    35.635M |\\n'\n",
      " '|    backbone.stem.conv_scale     |    0.24K               |    6.144M  |\\n'\n",
      " '|   backbone.stages_0             |   24K                  |   0.154G   |\\n'\n",
      " '|    backbone.stages_0.0          |    2.256K              |    14.438M |\\n'\n",
      " '|    backbone.stages_0.1          |    9.696K              |    62.054M |\\n'\n",
      " '|    backbone.stages_0.2          |    2.352K              |    15.053M |\\n'\n",
      " '|    backbone.stages_0.3          |    9.696K              |    62.054M |\\n'\n",
      " '|   backbone.stages_1             |   0.539M               |   0.863G   |\\n'\n",
      " '|    backbone.stages_1.0          |    2.256K              |    3.61M   |\\n'\n",
      " '|    backbone.stages_1.1.conv_kxk |    25.6K               |    40.96M  |\\n'\n",
      " '|    backbone.stages_1.2          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.3          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.4          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.5          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.6          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.7          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.8          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.9          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.10         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.11         |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.12         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.13         |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.14         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.15         |    66.816K             |    0.107G  |\\n'\n",
      " '|   backbone.stages_2             |   2.634M               |   1.054G   |\\n'\n",
      " '|    backbone.stages_2.0          |    6.016K              |    2.406M  |\\n'\n",
      " '|    backbone.stages_2.1.conv_kxk |    0.133M              |    53.248M |\\n'\n",
      " '|    backbone.stages_2.2          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.4          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.6          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.8          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.10         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.12         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.14         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.15         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.16         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.17         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.18         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.19         |    0.265M              |    0.106G  |\\n'\n",
      " '|   backbone.stages_3             |   1.069M               |   0.107G   |\\n'\n",
      " '|    backbone.stages_3.0          |    12.032K             |    1.203M  |\\n'\n",
      " '|    backbone.stages_3.1.conv_kxk |    1.057M              |    0.106G  |\\n'\n",
      " '|  neck                           |  0.348M                |  0.548G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.117M               |   57.344M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    3.92K               |    24.576M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    10.32K              |    16.384M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    20.56K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    82K                 |    8.192M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.231M               |   0.49G    |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    57.68K              |    0.369G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    57.68K              |    92.16M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    57.68K              |    23.04M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    57.68K              |    5.76M   |\\n'\n",
      " '|  head                           |  0.201M                |  0.378G    |\\n'\n",
      " '|   head.conv_seg                 |   49                   |   0.307M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 48, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.201M               |   0.374G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    34.656K             |    0.222G  |\\n'\n",
      " '|    head.scale_heads.1           |    34.656K             |    56.678M |\\n'\n",
      " '|    head.scale_heads.2           |    55.488K             |    48.73M  |\\n'\n",
      " '|    head.scale_heads.3           |    76.32K              |    46.742M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobileone_s0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 80\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                            | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                             | 14.358M                | 8.548G     |\\n'\n",
      " '|  backbone                         |  12.902M               |  6.2G      |\\n'\n",
      " '|   backbone.stem                   |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk.0       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_scale       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0               |   54.272K              |   0.347G   |\\n'\n",
      " '|    backbone.stages_0.0            |    0.896K              |    5.734M  |\\n'\n",
      " '|    backbone.stages_0.1.conv_kxk.0 |    12.672K             |    81.101M |\\n'\n",
      " '|    backbone.stages_0.2            |    3.072K              |    19.661M |\\n'\n",
      " '|    backbone.stages_0.3            |    37.632K             |    0.241G  |\\n'\n",
      " '|   backbone.stages_1               |   1.557M               |   2.492G   |\\n'\n",
      " '|    backbone.stages_1.0            |    2.688K              |    4.301M  |\\n'\n",
      " '|    backbone.stages_1.1.conv_kxk.0 |    86.912K             |    0.139G  |\\n'\n",
      " '|    backbone.stages_1.2            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.3            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.4            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.5            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.6            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.7            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.8            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.9            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.10           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.11           |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.12           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.13           |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.14           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.15           |    0.202M              |    0.324G  |\\n'\n",
      " '|   backbone.stages_2               |   8.809M               |   3.119G   |\\n'\n",
      " '|    backbone.stages_2.0            |    6.272K              |    2.509M  |\\n'\n",
      " '|    backbone.stages_2.1.conv_kxk.0 |    0.403M              |    0.161G  |\\n'\n",
      " '|    backbone.stages_2.2            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.3            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.4            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.5            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.6            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.7            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.8            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.9            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.10           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.11           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.12           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.13           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.14           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.15           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.16           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.17           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.18           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.19           |    0.908M              |    0.323G  |\\n'\n",
      " '|   backbone.stages_3               |   2.479M               |   0.186G   |\\n'\n",
      " '|    backbone.stages_3.0            |    0.114M              |    1.355M  |\\n'\n",
      " '|    backbone.stages_3.1            |    2.366M              |    0.184G  |\\n'\n",
      " '|  neck                             |  1.05M                 |  1.576G    |\\n'\n",
      " '|   neck.lateral_convs              |   0.459M               |   0.321G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv      |    24.704K             |    0.157G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv      |    57.472K             |    91.75M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv      |    0.115M              |    45.875M |\\n'\n",
      " '|    neck.lateral_convs.3.conv      |    0.262M              |    26.214M |\\n'\n",
      " '|   neck.fpn_convs                  |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv          |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv          |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv          |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv          |    0.148M              |    14.746M |\\n'\n",
      " '|  head                             |  0.406M                |  0.772G    |\\n'\n",
      " '|   head.conv_seg                   |   65                   |   0.41M    |\\n'\n",
      " '|    head.conv_seg.weight           |    (1, 64, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias             |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads                |   0.406M               |   0.767G   |\\n'\n",
      " '|    head.scale_heads.0.0           |    73.856K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1             |    73.856K             |    0.12G   |\\n'\n",
      " '|    head.scale_heads.2             |    0.111M              |    90.778M |\\n'\n",
      " '|    head.scale_heads.3             |    0.148M              |    83.52M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobileone_s4\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 5.027M                 | 3.52G      |\\n'\n",
      " '|  backbone                       |  4.268M                |  2.219G    |\\n'\n",
      " '|   backbone.stem                 |   1.632K               |   41.779M  |\\n'\n",
      " '|    backbone.stem.conv_kxk.0     |    1.392K              |    35.635M |\\n'\n",
      " '|    backbone.stem.conv_scale     |    0.24K               |    6.144M  |\\n'\n",
      " '|   backbone.stages_0             |   24K                  |   0.154G   |\\n'\n",
      " '|    backbone.stages_0.0          |    2.256K              |    14.438M |\\n'\n",
      " '|    backbone.stages_0.1          |    9.696K              |    62.054M |\\n'\n",
      " '|    backbone.stages_0.2          |    2.352K              |    15.053M |\\n'\n",
      " '|    backbone.stages_0.3          |    9.696K              |    62.054M |\\n'\n",
      " '|   backbone.stages_1             |   0.539M               |   0.863G   |\\n'\n",
      " '|    backbone.stages_1.0          |    2.256K              |    3.61M   |\\n'\n",
      " '|    backbone.stages_1.1.conv_kxk |    25.6K               |    40.96M  |\\n'\n",
      " '|    backbone.stages_1.2          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.3          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.4          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.5          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.6          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.7          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.8          |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.9          |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.10         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.11         |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.12         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.13         |    66.816K             |    0.107G  |\\n'\n",
      " '|    backbone.stages_1.14         |    6.272K              |    10.035M |\\n'\n",
      " '|    backbone.stages_1.15         |    66.816K             |    0.107G  |\\n'\n",
      " '|   backbone.stages_2             |   2.634M               |   1.054G   |\\n'\n",
      " '|    backbone.stages_2.0          |    6.016K              |    2.406M  |\\n'\n",
      " '|    backbone.stages_2.1.conv_kxk |    0.133M              |    53.248M |\\n'\n",
      " '|    backbone.stages_2.2          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.3          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.4          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.5          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.6          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.7          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.8          |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.9          |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.10         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.11         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.12         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.13         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.14         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.15         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.16         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.17         |    0.265M              |    0.106G  |\\n'\n",
      " '|    backbone.stages_2.18         |    12.544K             |    5.018M  |\\n'\n",
      " '|    backbone.stages_2.19         |    0.265M              |    0.106G  |\\n'\n",
      " '|   backbone.stages_3             |   1.069M               |   0.107G   |\\n'\n",
      " '|    backbone.stages_3.0          |    12.032K             |    1.203M  |\\n'\n",
      " '|    backbone.stages_3.1.conv_kxk |    1.057M              |    0.106G  |\\n'\n",
      " '|  neck                           |  0.348M                |  0.548G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.117M               |   57.344M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    3.92K               |    24.576M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    10.32K              |    16.384M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    20.56K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    82K                 |    8.192M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.231M               |   0.49G    |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    57.68K              |    0.369G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    57.68K              |    92.16M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    57.68K              |    23.04M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    57.68K              |    5.76M   |\\n'\n",
      " '|  head                           |  0.411M                |  0.753G    |\\n'\n",
      " '|   head.conv_seg                 |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.404M               |   0.706G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    57.76K              |    0.37G   |\\n'\n",
      " '|    head.scale_heads.1           |    57.76K              |    94.464M |\\n'\n",
      " '|    head.scale_heads.2           |    0.116M              |    0.118G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.173M              |    0.124G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobileone_s0\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 80\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                            | #parameters or shape   | #flops     |\\n'\n",
      " '|:----------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                             | 14.501M                | 8.823G     |\\n'\n",
      " '|  backbone                         |  12.902M               |  6.2G      |\\n'\n",
      " '|   backbone.stem                   |   2.176K               |   55.706M  |\\n'\n",
      " '|    backbone.stem.conv_kxk.0       |    1.856K              |    47.514M |\\n'\n",
      " '|    backbone.stem.conv_scale       |    0.32K               |    8.192M  |\\n'\n",
      " '|   backbone.stages_0               |   54.272K              |   0.347G   |\\n'\n",
      " '|    backbone.stages_0.0            |    0.896K              |    5.734M  |\\n'\n",
      " '|    backbone.stages_0.1.conv_kxk.0 |    12.672K             |    81.101M |\\n'\n",
      " '|    backbone.stages_0.2            |    3.072K              |    19.661M |\\n'\n",
      " '|    backbone.stages_0.3            |    37.632K             |    0.241G  |\\n'\n",
      " '|   backbone.stages_1               |   1.557M               |   2.492G   |\\n'\n",
      " '|    backbone.stages_1.0            |    2.688K              |    4.301M  |\\n'\n",
      " '|    backbone.stages_1.1.conv_kxk.0 |    86.912K             |    0.139G  |\\n'\n",
      " '|    backbone.stages_1.2            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.3            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.4            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.5            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.6            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.7            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.8            |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.9            |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.10           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.11           |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.12           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.13           |    0.202M              |    0.324G  |\\n'\n",
      " '|    backbone.stages_1.14           |    7.168K              |    11.469M |\\n'\n",
      " '|    backbone.stages_1.15           |    0.202M              |    0.324G  |\\n'\n",
      " '|   backbone.stages_2               |   8.809M               |   3.119G   |\\n'\n",
      " '|    backbone.stages_2.0            |    6.272K              |    2.509M  |\\n'\n",
      " '|    backbone.stages_2.1.conv_kxk.0 |    0.403M              |    0.161G  |\\n'\n",
      " '|    backbone.stages_2.2            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.3            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.4            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.5            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.6            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.7            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.8            |    14.336K             |    5.734M  |\\n'\n",
      " '|    backbone.stages_2.9            |    0.806M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.10           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.11           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.12           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.13           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.14           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.15           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.16           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.17           |    0.908M              |    0.323G  |\\n'\n",
      " '|    backbone.stages_2.18           |    0.116M              |    5.835M  |\\n'\n",
      " '|    backbone.stages_2.19           |    0.908M              |    0.323G  |\\n'\n",
      " '|   backbone.stages_3               |   2.479M               |   0.186G   |\\n'\n",
      " '|    backbone.stages_3.0            |    0.114M              |    1.355M  |\\n'\n",
      " '|    backbone.stages_3.1            |    2.366M              |    0.184G  |\\n'\n",
      " '|  neck                             |  1.05M                 |  1.576G    |\\n'\n",
      " '|   neck.lateral_convs              |   0.459M               |   0.321G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv      |    24.704K             |    0.157G  |\\n'\n",
      " '|    neck.lateral_convs.1.conv      |    57.472K             |    91.75M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv      |    0.115M              |    45.875M |\\n'\n",
      " '|    neck.lateral_convs.3.conv      |    0.262M              |    26.214M |\\n'\n",
      " '|   neck.fpn_convs                  |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv          |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv          |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv          |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv          |    0.148M              |    14.746M |\\n'\n",
      " '|  head                             |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg                   |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight           |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias             |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads                |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0           |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1             |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2             |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3             |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobileone_s4\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV1FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 3.474M                 | 1.585G     |\\n'\n",
      " '|  backbone                    |  3.207M                |  1.179G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   3.206M               |   1.155G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    2.528K              |    64.717M |\\n'\n",
      " '|    backbone.blocks.1         |    27.2K               |    0.174G  |\\n'\n",
      " '|    backbone.blocks.2         |    0.104M              |    0.166G  |\\n'\n",
      " '|    backbone.blocks.3         |    1.479M              |    0.592G  |\\n'\n",
      " '|    backbone.blocks.4         |    1.594M              |    0.159G  |\\n'\n",
      " '|  neck                        |  40.064K               |  44.294M   |\\n'\n",
      " '|   neck.lateral_convs         |   30.784K              |   24.576M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.064K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.112K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    8.208K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    16.4K               |    1.638M  |\\n'\n",
      " '|   neck.fpn_convs             |   9.28K                |   19.584M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    2.32K               |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    2.32K               |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    2.32K               |    0.922M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    2.32K               |    0.23M   |\\n'\n",
      " '|  head                        |  0.226M                |  0.362G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.22M                |   0.315G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.68K              |    74.752M |\\n'\n",
      " '|    head.scale_heads.1        |    11.68K              |    20.736M |\\n'\n",
      " '|    head.scale_heads.2        |    69.44K              |    99.648M |\\n'\n",
      " '|    head.scale_heads.3        |    0.127M              |    0.119G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv1_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 32\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV2FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 0.664M                 | 0.557G     |\\n'\n",
      " '|  backbone                    |  0.48M                 |  0.19G     |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   0.48M                |   0.178G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.32K               |    8.192M  |\\n'\n",
      " '|    backbone.blocks.1         |    6.16K               |    48.64M  |\\n'\n",
      " '|    backbone.blocks.2         |    13.056K             |    29.184M |\\n'\n",
      " '|    backbone.blocks.3         |    50.464K             |    22.259M |\\n'\n",
      " '|    backbone.blocks.4         |    80.928K             |    32.371M |\\n'\n",
      " '|    backbone.blocks.5         |    0.207M              |    25.037M |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.122M              |    12.176M |\\n'\n",
      " '|  neck                        |  0.163M                |  0.324G    |\\n'\n",
      " '|   neck.lateral_convs         |   15.616K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.088K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.088K              |    1.638M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.136K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    10.304K             |    1.024M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  20.281K               |  42.83M    |\\n'\n",
      " '|   head.conv_seg              |   9                    |   51.2K    |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 8, 1, 1)        |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   20.272K              |   42.165M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    4.624K              |    29.594M |\\n'\n",
      " '|    head.scale_heads.1        |    4.624K              |    7.603M  |\\n'\n",
      " '|    head.scale_heads.2        |    5.216K              |    3.053M  |\\n'\n",
      " '|    head.scale_heads.3        |    5.808K              |    1.915M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_050\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.034M                 | 1.019G     |\\n'\n",
      " '|  backbone                    |  1.812M                |  0.597G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.811M               |   0.573G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.896K              |    22.938M |\\n'\n",
      " '|    backbone.blocks.1         |    13.968K             |    0.123G  |\\n'\n",
      " '|    backbone.blocks.2         |    39.696K             |    81.485M |\\n'\n",
      " '|    backbone.blocks.3         |    0.184M              |    81.382M |\\n'\n",
      " '|    backbone.blocks.4         |    0.303M              |    0.121G  |\\n'\n",
      " '|    backbone.blocks.5         |    0.795M              |    96.461M |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.474M              |    47.392M |\\n'\n",
      " '|  neck                        |  0.178M                |  0.331G    |\\n'\n",
      " '|   neck.lateral_convs         |   30.464K              |   17.613M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.6K                |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    20.544K             |    2.048M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  44.017K               |  89.808M   |\\n'\n",
      " '|   head.conv_seg              |   17                   |   0.102M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   44K                  |   88.477M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.248K              |    59.187M |\\n'\n",
      " '|    head.scale_heads.1        |    9.248K              |    15.206M |\\n'\n",
      " '|    head.scale_heads.2        |    11.584K             |    7.949M  |\\n'\n",
      " '|    head.scale_heads.3        |    13.92K              |    6.134M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 4.312M                 | 2.705G     |\\n'\n",
      " '|  backbone                    |  3.509M                |  1.143G    |\\n'\n",
      " '|   backbone.conv_stem         |   1.296K               |   33.178M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   96                   |   2.458M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (48,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (48,)               |            |\\n'\n",
      " '|   backbone.blocks            |   3.508M               |   1.107G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    1.728K              |    44.237M |\\n'\n",
      " '|    backbone.blocks.1         |    24.848K             |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    80.928K             |    0.161G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.343M              |    0.154G  |\\n'\n",
      " '|    backbone.blocks.4         |    0.591M              |    0.236G  |\\n'\n",
      " '|    backbone.blocks.5         |    1.545M              |    0.188G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.922M              |    92.154M |\\n'\n",
      " '|  neck                        |  0.676M                |  1.303G    |\\n'\n",
      " '|   neck.lateral_convs         |   85.504K              |   48.742M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.224K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.272K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    17.536K             |    6.963M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    57.472K             |    5.734M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.127M                |  0.258G    |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.126M               |   0.256G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.696K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.696K             |    44.928M |\\n'\n",
      " '|    head.scale_heads.2        |    32.928K             |    20.218M |\\n'\n",
      " '|    head.scale_heads.3        |    38.16K              |    14.04M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_140\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.008M                 | 1.169G     |\\n'\n",
      " '|  backbone                    |  0.48M                 |  0.19G     |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   0.48M                |   0.178G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.32K               |    8.192M  |\\n'\n",
      " '|    backbone.blocks.1         |    6.16K               |    48.64M  |\\n'\n",
      " '|    backbone.blocks.2         |    13.056K             |    29.184M |\\n'\n",
      " '|    backbone.blocks.3         |    50.464K             |    22.259M |\\n'\n",
      " '|    backbone.blocks.4         |    80.928K             |    32.371M |\\n'\n",
      " '|    backbone.blocks.5         |    0.207M              |    25.037M |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.122M              |    12.176M |\\n'\n",
      " '|  neck                        |  0.163M                |  0.324G    |\\n'\n",
      " '|   neck.lateral_convs         |   15.616K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.088K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.088K              |    1.638M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.136K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    10.304K             |    1.024M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_050\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.355M                 | 1.584G     |\\n'\n",
      " '|  backbone                    |  1.812M                |  0.597G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.811M               |   0.573G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.896K              |    22.938M |\\n'\n",
      " '|    backbone.blocks.1         |    13.968K             |    0.123G  |\\n'\n",
      " '|    backbone.blocks.2         |    39.696K             |    81.485M |\\n'\n",
      " '|    backbone.blocks.3         |    0.184M              |    81.382M |\\n'\n",
      " '|    backbone.blocks.4         |    0.303M              |    0.121G  |\\n'\n",
      " '|    backbone.blocks.5         |    0.795M              |    96.461M |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.474M              |    47.392M |\\n'\n",
      " '|  neck                        |  0.178M                |  0.331G    |\\n'\n",
      " '|   neck.lateral_convs         |   30.464K              |   17.613M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.6K                |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    20.544K             |    2.048M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 4.734M                 | 3.493G     |\\n'\n",
      " '|  backbone                    |  3.509M                |  1.143G    |\\n'\n",
      " '|   backbone.conv_stem         |   1.296K               |   33.178M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (48, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   96                   |   2.458M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (48,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (48,)               |            |\\n'\n",
      " '|   backbone.blocks            |   3.508M               |   1.107G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    1.728K              |    44.237M |\\n'\n",
      " '|    backbone.blocks.1         |    24.848K             |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    80.928K             |    0.161G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.343M              |    0.154G  |\\n'\n",
      " '|    backbone.blocks.4         |    0.591M              |    0.236G  |\\n'\n",
      " '|    backbone.blocks.5         |    1.545M              |    0.188G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.922M              |    92.154M |\\n'\n",
      " '|  neck                        |  0.676M                |  1.303G    |\\n'\n",
      " '|   neck.lateral_convs         |   85.504K              |   48.742M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.224K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.272K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    17.536K             |    6.963M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    57.472K             |    5.734M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0      |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1        |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv2_140\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2FPN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                             | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                              | 1.598M                 | 0.887G     |\\n'\n",
      " '|  backbone                          |  1.355M                |  0.417G    |\\n'\n",
      " '|   backbone.conv_stem               |   1.376K               |   35.226M  |\\n'\n",
      " '|    backbone.conv_stem.first_conv   |    0.696K              |    17.818M |\\n'\n",
      " '|    backbone.conv_stem.conv_3x3     |    0.264K              |    6.758M  |\\n'\n",
      " '|    backbone.conv_stem.reduce_1x1   |    0.416K              |    10.65M  |\\n'\n",
      " '|   backbone.layer                   |   1.044M               |   0.382G   |\\n'\n",
      " '|    backbone.layer.0                |    5.136K              |    66.048M |\\n'\n",
      " '|    backbone.layer.1                |    8.832K              |    56.525M |\\n'\n",
      " '|    backbone.layer.2                |    8.832K              |    32.102M |\\n'\n",
      " '|    backbone.layer.3                |    8.832K              |    14.131M |\\n'\n",
      " '|    backbone.layer.4                |    8.832K              |    14.131M |\\n'\n",
      " '|    backbone.layer.5                |    12.336K             |    9.427M  |\\n'\n",
      " '|    backbone.layer.6                |    31.488K             |    12.595M |\\n'\n",
      " '|    backbone.layer.7                |    31.488K             |    12.595M |\\n'\n",
      " '|    backbone.layer.8                |    31.488K             |    12.595M |\\n'\n",
      " '|    backbone.layer.9                |    38.448K             |    15.379M |\\n'\n",
      " '|    backbone.layer.10               |    67.968K             |    27.187M |\\n'\n",
      " '|    backbone.layer.11               |    67.968K             |    27.187M |\\n'\n",
      " '|    backbone.layer.12               |    88.8K               |    18.47M  |\\n'\n",
      " '|    backbone.layer.13               |    0.182M              |    18.24M  |\\n'\n",
      " '|    backbone.layer.14               |    0.182M              |    18.24M  |\\n'\n",
      " '|    backbone.layer.15               |    0.269M              |    26.904M |\\n'\n",
      " '|   backbone.conv_1x1                |   0.31M                |            |\\n'\n",
      " '|    backbone.conv_1x1.convolution   |    0.307M              |            |\\n'\n",
      " '|    backbone.conv_1x1.normalization |    2.56K               |            |\\n'\n",
      " '|  neck                              |  0.171M                |  0.33G     |\\n'\n",
      " '|   neck.lateral_convs               |   23.296K              |   15.667M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv       |    1.6K                |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv       |    1.6K                |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv       |    4.672K              |    1.843M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv       |    15.424K             |    1.536M  |\\n'\n",
      " '|   neck.fpn_convs                   |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv           |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv           |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv           |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv           |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                              |  71.209K               |  0.141G    |\\n'\n",
      " '|   head.conv_seg                    |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight            |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias              |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads                 |   71.184K              |   0.139G   |\\n'\n",
      " '|    head.scale_heads.0.0            |    13.872K             |    88.781M |\\n'\n",
      " '|    head.scale_heads.1              |    13.872K             |    22.81M  |\\n'\n",
      " '|    head.scale_heads.2              |    19.104K             |    14.688M |\\n'\n",
      " '|    head.scale_heads.3              |    24.336K             |    12.658M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import MobileNetV2FPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "WIDTH_MULTIPLIER = 0.75\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = MobileNetV2FPN(\n",
    "    width_multiplier=WIDTH_MULTIPLIER,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV3FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.161M                 | 0.535G     |\\n'\n",
      " '|  backbone                    |  0.927M                |  0.117G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   0.927M               |   0.105G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.744K              |    2.97M   |\\n'\n",
      " '|    backbone.blocks.1         |    9.28K               |    21.069M |\\n'\n",
      " '|    backbone.blocks.2         |    0.128M              |    27.656M |\\n'\n",
      " '|    backbone.blocks.3         |    51.768K             |    12.912M |\\n'\n",
      " '|    backbone.blocks.4         |    0.68M               |    35.192M |\\n'\n",
      " '|    backbone.blocks.5.0       |    56.448K             |    5.645M  |\\n'\n",
      " '|  neck                        |  0.19M                 |  0.328G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.752K              |   13.926M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.088K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.6K                |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.136K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  44.017K               |  89.808M   |\\n'\n",
      " '|   head.conv_seg              |   17                   |   0.102M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   44K                  |   88.477M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.248K              |    59.187M |\\n'\n",
      " '|    head.scale_heads.1        |    9.248K              |    15.206M |\\n'\n",
      " '|    head.scale_heads.2        |    11.584K             |    7.949M  |\\n'\n",
      " '|    head.scale_heads.3        |    13.92K              |    6.134M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv3_small_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.037M                 | 0.75G      |\\n'\n",
      " '|  backbone                    |  1.79M                 |  0.326G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.789M               |   0.314G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.464K              |    11.878M |\\n'\n",
      " '|    backbone.blocks.1         |    7.88K               |    72.55M  |\\n'\n",
      " '|    backbone.blocks.2         |    37.176K             |    47.667M |\\n'\n",
      " '|    backbone.blocks.3         |    84.608K             |    41.677M |\\n'\n",
      " '|    backbone.blocks.4         |    0.382M              |    65.619M |\\n'\n",
      " '|    backbone.blocks.5         |    1.189M              |    66.251M |\\n'\n",
      " '|    backbone.blocks.6.0       |    87.84K              |    8.784M  |\\n'\n",
      " '|  neck                        |  0.203M                |  0.334G    |\\n'\n",
      " '|   neck.lateral_convs         |   55.552K              |   19.968M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.6K                |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.696K              |    2.253M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    46.144K             |    4.608M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  44.017K               |  89.808M   |\\n'\n",
      " '|   head.conv_seg              |   17                   |   0.102M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   44K                  |   88.477M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.248K              |    59.187M |\\n'\n",
      " '|    head.scale_heads.1        |    9.248K              |    15.206M |\\n'\n",
      " '|    head.scale_heads.2        |    11.584K             |    7.949M  |\\n'\n",
      " '|    head.scale_heads.3        |    13.92K              |    6.134M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv3_large_075\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 3.789M                 | 1.922G     |\\n'\n",
      " '|  backbone                    |  2.972M                |  0.453G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   2.971M               |   0.441G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.464K              |    11.878M |\\n'\n",
      " '|    backbone.blocks.1         |    7.88K               |    72.55M  |\\n'\n",
      " '|    backbone.blocks.2         |    52.312K             |    61.958M |\\n'\n",
      " '|    backbone.blocks.3         |    0.131M              |    64.426M |\\n'\n",
      " '|    backbone.blocks.4         |    0.601M              |    0.104G  |\\n'\n",
      " '|    backbone.blocks.5         |    2.024M              |    0.111G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.156M              |    15.552M |\\n'\n",
      " '|  neck                        |  0.736M                |  1.3G      |\\n'\n",
      " '|   neck.lateral_convs         |   0.146M               |   45.875M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.2K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.248K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    14.464K             |    5.734M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  80.881K               |  0.168G    |\\n'\n",
      " '|   head.conv_seg              |   17                   |   0.102M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 16, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   80.864K              |   0.167G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.464K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.464K             |    29.952M |\\n'\n",
      " '|    head.scale_heads.2        |    20.8K               |    11.635M |\\n'\n",
      " '|    head.scale_heads.3        |    23.136K             |    7.056M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv3_large_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.482M                 | 1.101G     |\\n'\n",
      " '|  backbone                    |  0.927M                |  0.117G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   0.927M               |   0.105G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.744K              |    2.97M   |\\n'\n",
      " '|    backbone.blocks.1         |    9.28K               |    21.069M |\\n'\n",
      " '|    backbone.blocks.2         |    0.128M              |    27.656M |\\n'\n",
      " '|    backbone.blocks.3         |    51.768K             |    12.912M |\\n'\n",
      " '|    backbone.blocks.4         |    0.68M               |    35.192M |\\n'\n",
      " '|    backbone.blocks.5.0       |    56.448K             |    5.645M  |\\n'\n",
      " '|  neck                        |  0.19M                 |  0.328G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.752K              |   13.926M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.088K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.6K                |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.136K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv3_small_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.358M                 | 1.316G     |\\n'\n",
      " '|  backbone                    |  1.79M                 |  0.326G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.789M               |   0.314G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.464K              |    11.878M |\\n'\n",
      " '|    backbone.blocks.1         |    7.88K               |    72.55M  |\\n'\n",
      " '|    backbone.blocks.2         |    37.176K             |    47.667M |\\n'\n",
      " '|    backbone.blocks.3         |    84.608K             |    41.677M |\\n'\n",
      " '|    backbone.blocks.4         |    0.382M              |    65.619M |\\n'\n",
      " '|    backbone.blocks.5         |    1.189M              |    66.251M |\\n'\n",
      " '|    backbone.blocks.6.0       |    87.84K              |    8.784M  |\\n'\n",
      " '|  neck                        |  0.203M                |  0.334G    |\\n'\n",
      " '|   neck.lateral_convs         |   55.552K              |   19.968M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.6K                |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.696K              |    2.253M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    46.144K             |    4.608M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.365M                |  0.655G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.358M               |   0.608G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    46.24K              |    0.296G  |\\n'\n",
      " '|    head.scale_heads.1        |    46.24K              |    76.032M |\\n'\n",
      " '|    head.scale_heads.2        |    0.104M              |    0.113G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.162M              |    0.123G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"tf_mobilenetv3_large_075\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 4.257M                 | 2.801G     |\\n'\n",
      " '|  backbone                    |  2.972M                |  0.453G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.432K               |   11.059M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (16, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   32                   |   0.819M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (16,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (16,)               |            |\\n'\n",
      " '|   backbone.blocks            |   2.971M               |   0.441G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    0.464K              |    11.878M |\\n'\n",
      " '|    backbone.blocks.1         |    7.88K               |    72.55M  |\\n'\n",
      " '|    backbone.blocks.2         |    52.312K             |    61.958M |\\n'\n",
      " '|    backbone.blocks.3         |    0.131M              |    64.426M |\\n'\n",
      " '|    backbone.blocks.4         |    0.601M              |    0.104G  |\\n'\n",
      " '|    backbone.blocks.5         |    2.024M              |    0.111G  |\\n'\n",
      " '|    backbone.blocks.6.0       |    0.156M              |    15.552M |\\n'\n",
      " '|  neck                        |  0.736M                |  1.3G      |\\n'\n",
      " '|   neck.lateral_convs         |   0.146M               |   45.875M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.2K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.248K              |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    14.464K             |    5.734M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.549M                |  1.047G    |\\n'\n",
      " '|   head.conv_seg              |   6.48K                |   40.96M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 80, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.543M               |   1G       |\\n'\n",
      " '|    head.scale_heads.0.0      |    92.32K              |    0.591G  |\\n'\n",
      " '|    head.scale_heads.1        |    92.32K              |    0.15G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.15M               |    0.132G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.208M              |    0.127G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv3_large_100\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV4FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.671M                 | 2.595G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.261M                |  1.34G     |\\n'\n",
      " '|   neck.lateral_convs         |   76.096K              |   80.691M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.185M               |   1.257G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.148M                |  0.872G    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.819M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.148M               |   0.858G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    0.122G  |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    93.082M |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    85.939M |\\n'\n",
      " '|    head.scale_heads.4        |    46.336K             |    84.154M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.585M                 | 0.921G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.222M                |  0.342G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.102M                |  0.196G    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.509M                 | 0.519G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.183M                |  92.698M   |\\n'\n",
      " '|   neck.lateral_convs         |   71.872K              |   15.155M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  64.801K               |  43.475M   |\\n'\n",
      " '|   head.conv_seg              |   33                   |   51.2K    |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   64.768K              |   43.014M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    29.594M |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    7.603M  |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    5.818M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.44M                  | 0.419G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.142M                |  27.059M   |\\n'\n",
      " '|   neck.lateral_convs         |   67.712K              |   8.602M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   73.856K              |   18.432M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  37.025K               |  9.363M    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   12.8K    |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   36.992K              |   9.299M   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    7.398M  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    1.901M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 2\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### other fpn_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.486M                 | 0.722G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.15M                 |  0.189G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   75.52K               |   0.16G    |\\n'\n",
      " '|    neck.fpn_convs.0          |    18.88K              |    0.121G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    18.88K              |    30.208M |\\n'\n",
      " '|    neck.fpn_convs.2          |    18.88K              |    7.552M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    18.88K              |    1.888M  |\\n'\n",
      " '|  head                        |  74.945K               |  0.15G     |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   74.912K              |   0.147G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    14.72K              |    94.208M |\\n'\n",
      " '|    head.scale_heads.1        |    14.72K              |    24.371M |\\n'\n",
      " '|    head.scale_heads.2        |    20.064K             |    15.462M |\\n'\n",
      " '|    head.scale_heads.3        |    25.408K             |    13.235M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.479M                 | 0.708G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.147M                |  0.183G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   72.704K              |   0.154G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    18.176K             |    0.116G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    18.176K             |    29.082M |\\n'\n",
      " '|    neck.fpn_convs.2          |    18.176K             |    7.27M   |\\n'\n",
      " '|    neck.fpn_convs.3          |    18.176K             |    1.818M  |\\n'\n",
      " '|  head                        |  71.073K               |  0.143G    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   71.04K               |   0.14G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    14.016K             |    89.702M |\\n'\n",
      " '|    head.scale_heads.1        |    14.016K             |    23.245M |\\n'\n",
      " '|    head.scale_heads.2        |    19.008K             |    14.618M |\\n'\n",
      " '|    head.scale_heads.3        |    24K                 |    12.461M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.62M                  | 0.86G      |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.292M                |  0.342G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.218M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.5          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.6          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.7          |    17.472K             |            |\\n'\n",
      " '|  head                        |  67.201K               |  0.135G    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   67.168K              |   0.133G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    13.312K             |    85.197M |\\n'\n",
      " '|    head.scale_heads.1        |    13.312K             |    22.118M |\\n'\n",
      " '|    head.scale_heads.2        |    17.952K             |    13.773M |\\n'\n",
      " '|    head.scale_heads.3        |    22.592K             |    11.686M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.664M                 | 9.69G      |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.539M                |  2.967G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.123M               |   0.136G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.415M               |   2.828G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    2.123G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.922M                |  5.014G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.914M               |   4.779G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    2.128G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    0.542G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    0.677G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.249M              |    0.711G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.333M              |    0.72G   |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.794M                 | 2.745G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.452M                |  0.763G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.139M                |  0.275G    |\\n'\n",
      " '|   head.conv_seg              |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.139M               |   0.272G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.712K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.712K             |    45.158M |\\n'\n",
      " '|    head.scale_heads.2        |    36.992K             |    26.957M |\\n'\n",
      " '|    head.scale_heads.3        |    46.272K             |    22.406M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.908M                 | 2.132G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.365M                |  0.202G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.115M               |   27.648M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.34M                 |  0.223G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.333M               |   0.209G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    0.133G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    33.869M |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    42.336M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.156M                | 10.743G    |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.908M                |  5.192G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.17M                |   0.16G    |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.2K                |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.738M               |   5.028G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    3.775G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.17M                 |  1.086G    |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.614M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.17M                |   1.076G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.696K             |    0.709G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.696K             |    0.18G   |\\n'\n",
      " '|    head.scale_heads.2        |    32.928K             |    80.87M  |\\n'\n",
      " '|    head.scale_heads.3        |    38.16K              |    56.16M  |\\n'\n",
      " '|    head.scale_heads.4        |    43.392K             |    49.982M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.962M                | 6.058G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.757M                |  1.336G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.127M                |  0.258G    |\\n'\n",
      " '|   head.conv_seg              |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   0.126M               |   0.256G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.696K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.696K             |    44.928M |\\n'\n",
      " '|    head.scale_heads.2        |    32.928K             |    20.218M |\\n'\n",
      " '|    head.scale_heads.3        |    38.16K              |    14.04M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.77M                 | 4.877G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.603M                |  0.352G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.16M                |   41.779M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  88.345K               |  60.946M   |\\n'\n",
      " '|   head.conv_seg              |   25                   |   38.4K    |\\n'\n",
      " '|    head.conv_seg.weight      |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads           |   88.32K               |   60.6M    |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.696K             |    44.314M |\\n'\n",
      " '|    head.scale_heads.1        |    27.696K             |    11.232M |\\n'\n",
      " '|    head.scale_heads.2        |    32.928K             |    5.054M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.673M                 | 2.659G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.261M                |  1.34G     |\\n'\n",
      " '|   neck.lateral_convs         |   76.096K              |   80.691M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.185M               |   1.257G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.151M                |  0.937G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.148M               |   0.858G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    0.122G  |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    93.082M |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    85.939M |\\n'\n",
      " '|    head.scale_heads.4        |    46.336K             |    84.154M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.486M                 | 0.754G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.139M                |  0.198G    |\\n'\n",
      " '|   neck.lateral_convs         |   55.488K              |   21.197M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.584K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.12K               |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    4.656K              |    1.843M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    46.128K             |    4.608M  |\\n'\n",
      " '|   neck.fpn_convs             |   83.136K              |   0.176G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    20.784K             |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    20.784K             |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    20.784K             |    8.294M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    20.784K             |    2.074M  |\\n'\n",
      " '|  head                        |  86.032K               |  0.173G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   83.392K              |   0.154G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    13.888K             |    88.883M |\\n'\n",
      " '|    head.scale_heads.1        |    13.888K             |    23.04M  |\\n'\n",
      " '|    head.scale_heads.2        |    23.168K             |    21.427M |\\n'\n",
      " '|    head.scale_heads.3        |    32.448K             |    21.024M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 48\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.588M                 | 0.937G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.222M                |  0.342G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  0.104M                |  0.212G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.846M                 | 1.421G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.443M                |  0.748G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.111M               |   42.394M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.24K               |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    9.312K              |    3.686M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.141M                |  0.291G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.139M               |   0.272G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.712K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.712K             |    45.158M |\\n'\n",
      " '|    head.scale_heads.2        |    36.992K             |    26.957M |\\n'\n",
      " '|    head.scale_heads.3        |    46.272K             |    22.406M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.178M                 | 2.063G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.738M                |  1.311G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.148M               |   56.525M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.224K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    8.32K               |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    12.416K             |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.178M                |  0.369G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.176M               |   0.35G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    36.928K             |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1        |    36.928K             |    59.904M |\\n'\n",
      " '|    head.scale_heads.2        |    46.208K             |    30.643M |\\n'\n",
      " '|    head.scale_heads.3        |    55.488K             |    23.328M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.512M                 | 0.535G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.395G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   4.096M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.368G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    67.584M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    55.347M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.131G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    0.102G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.768M |\\n'\n",
      " '|  neck                        |  0.183M                |  92.698M   |\\n'\n",
      " '|   neck.lateral_convs         |   71.872K              |   15.155M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                        |  67.408K               |  47.76M    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   64.768K              |   43.254M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    29.747M |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    7.642M  |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    5.866M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.664M                 | 9.69G      |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.539M                |  2.967G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.123M               |   0.136G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.415M               |   2.828G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    2.123G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.922M                |  5.014G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.914M               |   4.779G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    2.128G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    0.542G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    0.677G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.249M              |    0.711G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.333M              |    0.72G   |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.649M                 | 2.407G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  77.056K               |  97.651M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  0.369M                |  0.601G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.361M               |   0.545G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    0.178G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    47.002M |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    0.147G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.194M              |    0.172G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.245M                 | 3.542G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.452M                |  0.763G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.59M                 |  1.071G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.582M               |   1.015G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    0.532G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    0.135G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    0.169G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.249M              |    0.178G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.654M                 | 4.345G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.751M                |  1.331G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.16M                |   76.186M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    10.368K             |    16.384M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    20.608K             |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.7M                  |  1.306G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.693M               |   1.25G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.111M              |    0.709G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.111M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.194M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.3        |    0.277M              |    0.181G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.908M                 | 2.132G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.365M                |  0.202G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.115M               |   27.648M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                        |  0.34M                 |  0.223G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.333M               |   0.209G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    0.133G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    33.869M |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    42.336M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.249M                | 9.832G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  88.64K                |  0.355G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  1.082M                |  5.012G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.072M               |   4.698G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    0.95G   |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    0.251G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    1.021G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.333M              |    1.214G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.48M               |    1.262G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.759M                | 5.497G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  78.592K               |  98.88M    |\\n'\n",
      " '|   neck.lateral_convs         |   41.6K                |   20.275M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                        |  0.602M                |  0.934G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.592M               |   0.859G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    62.669M |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    0.255G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.333M              |    0.303G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 34.406M                | 12.77G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  2.693M                |  5.178G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.333M               |   0.162G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    12.544K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    24.832K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    49.408K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.246M              |    24.576M |\\n'\n",
      " '|   neck.fpn_convs             |   2.36M                |   5.014G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.59M               |    3.775G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.59M               |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.59M               |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.59M               |    58.982M |\\n'\n",
      " '|  head                        |  1.634M                |  3.128G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.624M               |   3.052G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.295M              |    1.889G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.295M              |    0.476G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.443M              |    0.359G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.591M              |    0.329G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 256\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.88M                 | 7.674G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.757M                |  1.336G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  1.044M                |  1.874G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.034M               |   1.799G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.148M              |    0.945G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.148M              |    0.24G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.295M              |    0.3G    |\\n'\n",
      " '|    head.scale_heads.3        |    0.443M              |    0.314G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.283M                | 5.205G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.603M                |  0.352G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.16M                |   41.779M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|  head                        |  0.601M                |  0.389G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.591M               |   0.371G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.148M              |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.148M              |    59.904M |\\n'\n",
      " '|    head.scale_heads.2        |    0.295M              |    74.88M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.388M                 | 1.005G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  64.768K               |  0.224G    |\\n'\n",
      " '|   neck.lateral_convs         |   38.048K              |   40.346M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   26.72K               |   0.182G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    0.137G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  61.424K               |  0.399G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   58.784K              |   0.32G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    5.344K              |    0.137G  |\\n'\n",
      " '|    head.scale_heads.1        |    5.344K              |    37.478M |\\n'\n",
      " '|    head.scale_heads.2        |    10.688K             |    46.848M |\\n'\n",
      " '|    head.scale_heads.3        |    16.032K             |    49.19M  |\\n'\n",
      " '|    head.scale_heads.4        |    21.376K             |    49.776M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.36M                  | 0.529G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  58.368K               |  59.824M   |\\n'\n",
      " '|   neck.lateral_convs         |   36.992K              |   14.131M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   21.376K              |   45.424M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  40.048K               |  86.422M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   37.408K              |   67.581M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    5.344K              |    34.202M |\\n'\n",
      " '|    head.scale_heads.1        |    5.344K              |    9.37M   |\\n'\n",
      " '|    head.scale_heads.2        |    10.688K             |    11.712M |\\n'\n",
      " '|    head.scale_heads.3        |    16.032K             |    12.298M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.489M                 | 0.738G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.15M                 |  0.189G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   75.52K               |   0.16G    |\\n'\n",
      " '|    neck.fpn_convs.0          |    18.88K              |    0.121G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    18.88K              |    30.208M |\\n'\n",
      " '|    neck.fpn_convs.2          |    18.88K              |    7.552M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    18.88K              |    1.888M  |\\n'\n",
      " '|  head                        |  77.552K               |  0.166G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   74.912K              |   0.147G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    14.72K              |    94.208M |\\n'\n",
      " '|    head.scale_heads.1        |    14.72K              |    24.371M |\\n'\n",
      " '|    head.scale_heads.2        |    20.064K             |    15.462M |\\n'\n",
      " '|    head.scale_heads.3        |    25.408K             |    13.235M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.667M                 | 1.051G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.273M                |  0.388G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.111M               |   42.394M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.24K               |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    9.312K              |    3.686M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.162M               |   0.345G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    40.608K             |    0.26G   |\\n'\n",
      " '|    neck.fpn_convs.1          |    40.608K             |    64.973M |\\n'\n",
      " '|    neck.fpn_convs.2          |    40.608K             |    16.243M |\\n'\n",
      " '|    neck.fpn_convs.3          |    40.608K             |    4.061M  |\\n'\n",
      " '|  head                        |  0.131M                |  0.281G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.129M               |   0.262G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    28.192K             |    0.18G   |\\n'\n",
      " '|    head.scale_heads.1        |    28.192K             |    45.926M |\\n'\n",
      " '|    head.scale_heads.2        |    33.536K             |    20.851M |\\n'\n",
      " '|    head.scale_heads.3        |    38.88K              |    14.582M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.338M                 | 0.42G      |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  51.968K               |  18.864M   |\\n'\n",
      " '|   neck.lateral_convs         |   35.936K              |   7.578M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   16.032K              |   11.222M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  24.016K               |  18.326M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   21.376K              |   13.821M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    5.344K              |    8.55M   |\\n'\n",
      " '|    head.scale_heads.1        |    5.344K              |    2.342M  |\\n'\n",
      " '|    head.scale_heads.2        |    10.688K             |    2.928M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.57M                  | 3.472G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  67.84K                |  0.229G    |\\n'\n",
      " '|   neck.lateral_convs         |   41.12K               |   45.261M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   26.72K               |   0.182G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    0.137G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  0.299M                |  1.536G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.291M               |   1.3G     |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.568K              |    0.245G  |\\n'\n",
      " '|    head.scale_heads.1        |    9.568K              |    71.066M |\\n'\n",
      " '|    head.scale_heads.2        |    50.176K             |    0.287G  |\\n'\n",
      " '|    head.scale_heads.3        |    90.784K             |    0.342G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.131M              |    0.355G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.432M                 | 2.065G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  61.44K                |  64.739M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   21.376K              |   45.424M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  0.168M                |  0.293G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.16M                |   0.236G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.568K              |    61.235M |\\n'\n",
      " '|    head.scale_heads.1        |    9.568K              |    17.766M |\\n'\n",
      " '|    head.scale_heads.2        |    50.176K             |    71.872M |\\n'\n",
      " '|    head.scale_heads.3        |    90.784K             |    85.398M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.778M                 | 2.667G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.283M                |  0.403G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.162M               |   0.345G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    40.608K             |    0.26G   |\\n'\n",
      " '|    neck.fpn_convs.1          |    40.608K             |    64.973M |\\n'\n",
      " '|    neck.fpn_convs.2          |    40.608K             |    16.243M |\\n'\n",
      " '|    neck.fpn_convs.3          |    40.608K             |    4.061M  |\\n'\n",
      " '|  head                        |  0.292M                |  0.557G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.284M               |   0.5G     |\\n'\n",
      " '|    head.scale_heads.0.0      |    40.608K             |    0.26G   |\\n'\n",
      " '|    head.scale_heads.1        |    40.608K             |    67.43M  |\\n'\n",
      " '|    head.scale_heads.2        |    81.216K             |    84.288M |\\n'\n",
      " '|    head.scale_heads.3        |    0.122M              |    88.502M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.335M                 | 1.779G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  54.528K               |  20.502M   |\\n'\n",
      " '|   neck.lateral_convs         |   38.496K              |   9.216M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   16.032K              |   11.222M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  77.072K               |  51.235M   |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   69.312K              |   37.718M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.568K              |    15.309M |\\n'\n",
      " '|    head.scale_heads.1        |    9.568K              |    4.442M  |\\n'\n",
      " '|    head.scale_heads.2        |    50.176K             |    17.968M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.64M                 | 7.072G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  69.12K                |  0.223G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   26.72K               |   0.182G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    0.137G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  0.492M                |  2.385G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.482M               |   2.07G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.68K              |    0.299G  |\\n'\n",
      " '|    head.scale_heads.1        |    11.68K              |    87.859M |\\n'\n",
      " '|    head.scale_heads.2        |    82.208K             |    0.486G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.153M              |    0.586G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.223M              |    0.611G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.41M                 | 4.97G      |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  62.976K               |  65.968M   |\\n'\n",
      " '|   neck.lateral_convs         |   41.6K                |   20.275M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   21.376K              |   45.424M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  0.269M                |  0.44G     |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.258M               |   0.365G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.68K              |    74.752M |\\n'\n",
      " '|    head.scale_heads.1        |    11.68K              |    21.965M |\\n'\n",
      " '|    head.scale_heads.2        |    82.208K             |    0.122G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.153M              |    0.147G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.031M                | 6.086G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.449M                |  0.682G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.282M               |   0.599G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    70.528K             |    0.451G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    70.528K             |    0.113G  |\\n'\n",
      " '|    neck.fpn_convs.2          |    70.528K             |    28.211M |\\n'\n",
      " '|    neck.fpn_convs.3          |    70.528K             |    7.053M  |\\n'\n",
      " '|  head                        |  0.504M                |  0.94G     |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.494M               |   0.865G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    70.528K             |    0.451G  |\\n'\n",
      " '|    head.scale_heads.1        |    70.528K             |    0.116G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.141M              |    0.145G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.212M              |    0.152G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.25M                 | 4.558G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  56.064K               |  21.731M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.032K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   16.032K              |   11.222M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.fpn_convs.1          |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    5.344K              |    0.534M  |\\n'\n",
      " '|  head                        |  0.116M                |  72.605M   |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.106M               |   54.582M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.68K              |    18.688M |\\n'\n",
      " '|    head.scale_heads.1        |    11.68K              |    5.491M  |\\n'\n",
      " '|    head.scale_heads.2        |    82.208K             |    30.403M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: ib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.382M                 | 0.973G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  63.008K               |  0.212G    |\\n'\n",
      " '|   neck.lateral_convs         |   38.048K              |   40.346M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   24.96K               |   0.17G    |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    0.128G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  57.552K               |  0.379G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   54.912K              |   0.3G     |\\n'\n",
      " '|    head.scale_heads.0.0      |    4.992K              |    0.128G  |\\n'\n",
      " '|    head.scale_heads.1        |    4.992K              |    35.226M |\\n'\n",
      " '|    head.scale_heads.2        |    9.984K              |    44.032M |\\n'\n",
      " '|    head.scale_heads.3        |    14.976K             |    46.234M |\\n'\n",
      " '|    head.scale_heads.4        |    19.968K             |    46.784M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.356M                 | 0.521G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  56.96K                |  56.832M   |\\n'\n",
      " '|   neck.lateral_convs         |   36.992K              |   14.131M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   19.968K              |   42.432M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  37.584K               |  82.163M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   34.944K              |   63.322M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    4.992K              |    31.949M |\\n'\n",
      " '|    head.scale_heads.1        |    4.992K              |    8.806M  |\\n'\n",
      " '|    head.scale_heads.2        |    9.984K              |    11.008M |\\n'\n",
      " '|    head.scale_heads.3        |    14.976K             |    11.558M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.482M                 | 0.725G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.147M                |  0.183G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   72.704K              |   0.154G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    18.176K             |    0.116G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    18.176K             |    29.082M |\\n'\n",
      " '|    neck.fpn_convs.2          |    18.176K             |    7.27M   |\\n'\n",
      " '|    neck.fpn_convs.3          |    18.176K             |    1.818M  |\\n'\n",
      " '|  head                        |  73.68K                |  0.159G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   71.04K               |   0.14G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    14.016K             |    89.702M |\\n'\n",
      " '|    head.scale_heads.1        |    14.016K             |    23.245M |\\n'\n",
      " '|    head.scale_heads.2        |    19.008K             |    14.618M |\\n'\n",
      " '|    head.scale_heads.3        |    24K                 |    12.461M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.657M                 | 1.032G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.269M                |  0.379G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.111M               |   42.394M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.24K               |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    9.312K              |    3.686M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.158M               |   0.336G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    39.552K             |    0.253G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    39.552K             |    63.283M |\\n'\n",
      " '|    neck.fpn_convs.2          |    39.552K             |    15.821M |\\n'\n",
      " '|    neck.fpn_convs.3          |    39.552K             |    3.955M  |\\n'\n",
      " '|  head                        |  0.126M                |  0.27G     |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.124M               |   0.252G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.136K             |    0.174G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.136K             |    44.237M |\\n'\n",
      " '|    head.scale_heads.2        |    32.128K             |    19.866M |\\n'\n",
      " '|    head.scale_heads.3        |    37.12K              |    13.773M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.335M                 | 0.418G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  50.912K               |  18.125M   |\\n'\n",
      " '|   neck.lateral_convs         |   35.936K              |   7.578M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   14.976K              |   10.483M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  22.608K               |  17.446M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   19.968K              |   12.941M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    4.992K              |    7.987M  |\\n'\n",
      " '|    head.scale_heads.1        |    4.992K              |    2.202M  |\\n'\n",
      " '|    head.scale_heads.2        |    9.984K              |    2.752M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.56M                  | 3.424G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  66.08K                |  0.217G    |\\n'\n",
      " '|   neck.lateral_convs         |   41.12K               |   45.261M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   24.96K               |   0.17G    |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    0.128G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  0.291M                |  1.5G      |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.283M               |   1.264G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.216K              |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1        |    9.216K              |    68.813M |\\n'\n",
      " '|    head.scale_heads.2        |    48.768K             |    0.28G   |\\n'\n",
      " '|    head.scale_heads.3        |    88.32K              |    0.333G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.128M              |    0.346G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.426M                 | 2.055G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  60.032K               |  61.747M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   19.968K              |   42.432M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  0.163M                |  0.286G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.156M               |   0.229G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.216K              |    58.982M |\\n'\n",
      " '|    head.scale_heads.1        |    9.216K              |    17.203M |\\n'\n",
      " '|    head.scale_heads.2        |    48.768K             |    70.042M |\\n'\n",
      " '|    head.scale_heads.3        |    88.32K              |    83.251M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.766M                 | 2.646G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.278M                |  0.394G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.158M               |   0.336G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    39.552K             |    0.253G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    39.552K             |    63.283M |\\n'\n",
      " '|    neck.fpn_convs.2          |    39.552K             |    15.821M |\\n'\n",
      " '|    neck.fpn_convs.3          |    39.552K             |    3.955M  |\\n'\n",
      " '|  head                        |  0.285M                |  0.544G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.277M               |   0.487G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    39.552K             |    0.253G  |\\n'\n",
      " '|    head.scale_heads.1        |    39.552K             |    65.741M |\\n'\n",
      " '|    head.scale_heads.2        |    79.104K             |    82.176M |\\n'\n",
      " '|    head.scale_heads.3        |    0.119M              |    86.285M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.332M                 | 1.777G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  53.472K               |  19.763M   |\\n'\n",
      " '|   neck.lateral_convs         |   38.496K              |   9.216M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   14.976K              |   10.483M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  74.96K                |  50.074M   |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   67.2K                |   36.557M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.216K              |    14.746M |\\n'\n",
      " '|    head.scale_heads.1        |    9.216K              |    4.301M  |\\n'\n",
      " '|    head.scale_heads.2        |    48.768K             |    17.51M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.628M                | 7.016G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  67.36K                |  0.211G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   24.96K               |   0.17G    |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    0.128G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  0.482M                |  2.341G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.471M               |   2.026G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.328K             |    0.29G   |\\n'\n",
      " '|    head.scale_heads.1        |    11.328K             |    85.606M |\\n'\n",
      " '|    head.scale_heads.2        |    80.448K             |    0.477G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.15M               |    0.575G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.219M              |    0.599G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.403M                | 4.959G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  61.568K               |  62.976M   |\\n'\n",
      " '|   neck.lateral_convs         |   41.6K                |   20.275M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   19.968K              |   42.432M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.3          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  0.263M                |  0.432G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.253M               |   0.357G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.328K             |    72.499M |\\n'\n",
      " '|    head.scale_heads.1        |    11.328K             |    21.402M |\\n'\n",
      " '|    head.scale_heads.2        |    80.448K             |    0.119G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.15M               |    0.144G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.016M                | 6.057G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.443M                |  0.67G     |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.276M               |   0.588G   |\\n'\n",
      " '|    neck.fpn_convs.0          |    69.12K              |    0.442G  |\\n'\n",
      " '|    neck.fpn_convs.1          |    69.12K              |    0.111G  |\\n'\n",
      " '|    neck.fpn_convs.2          |    69.12K              |    27.648M |\\n'\n",
      " '|    neck.fpn_convs.3          |    69.12K              |    6.912M  |\\n'\n",
      " '|  head                        |  0.494M                |  0.923G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.484M               |   0.848G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    69.12K              |    0.442G  |\\n'\n",
      " '|    head.scale_heads.1        |    69.12K              |    0.114G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.138M              |    0.142G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.207M              |    0.149G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.247M                | 4.556G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  55.008K               |  20.992M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.032K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   14.976K              |   10.483M  |\\n'\n",
      " '|    neck.fpn_convs.0          |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.fpn_convs.1          |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.fpn_convs.2          |    4.992K              |    0.499M  |\\n'\n",
      " '|  head                        |  0.113M                |  71.302M   |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.103M               |   53.28M   |\\n'\n",
      " '|    head.scale_heads.0.0      |    11.328K             |    18.125M |\\n'\n",
      " '|    head.scale_heads.1        |    11.328K             |    5.35M   |\\n'\n",
      " '|    head.scale_heads.2        |    80.448K             |    29.805M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: convnext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.623M                 | 0.876G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.292M                |  0.342G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.218M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.5          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.6          |    17.472K             |            |\\n'\n",
      " '|    neck.fpn_convs.7          |    17.472K             |            |\\n'\n",
      " '|  head                        |  69.808K               |  0.152G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   67.168K              |   0.133G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    13.312K             |    85.197M |\\n'\n",
      " '|    head.scale_heads.1        |    13.312K             |    22.118M |\\n'\n",
      " '|    head.scale_heads.2        |    17.952K             |    13.773M |\\n'\n",
      " '|    head.scale_heads.3        |    22.592K             |    11.686M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.087M                 | 3.002G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.606M                |  0.763G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.486M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|    neck.fpn_convs.4          |    38.496K             |            |\\n'\n",
      " '|    neck.fpn_convs.5          |    38.496K             |            |\\n'\n",
      " '|    neck.fpn_convs.6          |    38.496K             |            |\\n'\n",
      " '|    neck.fpn_convs.7          |    38.496K             |            |\\n'\n",
      " '|  head                        |  0.277M                |  0.531G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.269M               |   0.475G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    38.496K             |    0.246G  |\\n'\n",
      " '|    head.scale_heads.1        |    38.496K             |    64.051M |\\n'\n",
      " '|    head.scale_heads.2        |    76.992K             |    80.064M |\\n'\n",
      " '|    head.scale_heads.3        |    0.115M              |    84.067M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.59M                 | 6.706G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  1.028M                |  1.336G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.861M               |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.4          |    67.712K             |            |\\n'\n",
      " '|    neck.fpn_convs.5          |    67.712K             |            |\\n'\n",
      " '|    neck.fpn_convs.6          |    67.712K             |            |\\n'\n",
      " '|    neck.fpn_convs.7          |    67.712K             |            |\\n'\n",
      " '|  head                        |  0.484M                |  0.906G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.474M               |   0.831G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    67.712K             |    0.433G  |\\n'\n",
      " '|    head.scale_heads.1        |    67.712K             |    0.112G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.135M              |    0.14G   |\\n'\n",
      " '|    head.scale_heads.3        |    0.203M              |    0.146G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV4PAFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.966M                 | 3.221G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.556M                |  1.967G    |\\n'\n",
      " '|   neck.lateral_convs            |   76.096K              |   80.691M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    2.112K              |    52.429M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.185M               |   1.257G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    36.928K             |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                           |  0.148M                |  0.872G    |\\n'\n",
      " '|   head.conv_seg                 |   33                   |   0.819M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.148M               |   0.858G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    18.496K             |    0.473G  |\\n'\n",
      " '|    head.scale_heads.1           |    18.496K             |    0.122G  |\\n'\n",
      " '|    head.scale_heads.2           |    27.776K             |    93.082M |\\n'\n",
      " '|    head.scale_heads.3           |    37.056K             |    85.939M |\\n'\n",
      " '|    head.scale_heads.4           |    46.336K             |    84.154M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.807M                 | 1.076G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.443M                |  0.497G    |\\n'\n",
      " '|   neck.lateral_convs            |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                           |  0.102M                |  0.196G    |\\n'\n",
      " '|   head.conv_seg                 |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1           |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2           |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3           |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.657M                 | 0.556G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.33M                 |  0.13G     |\\n'\n",
      " '|   neck.lateral_convs            |   71.872K              |   15.155M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs         |   73.856K              |   18.432M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.pafpn_convs              |   73.856K              |   18.432M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                           |  64.801K               |  43.475M   |\\n'\n",
      " '|   head.conv_seg                 |   33                   |   51.2K    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   64.768K              |   43.014M  |\\n'\n",
      " '|    head.scale_heads.0.0         |    18.496K             |    29.594M |\\n'\n",
      " '|    head.scale_heads.1           |    18.496K             |    7.603M  |\\n'\n",
      " '|    head.scale_heads.2           |    27.776K             |    5.818M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 9.328M                 | 11.1G      |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  1.203M                |  4.377G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.123M               |   0.136G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    3.168K              |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.415M               |   2.828G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    2.123G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.922M                |  5.014G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.914M               |   4.779G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    83.136K             |    2.128G  |\\n'\n",
      " '|    head.scale_heads.1           |    83.136K             |    0.542G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.166M              |    0.677G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.249M              |    0.711G  |\\n'\n",
      " '|    head.scale_heads.4           |    0.333M              |    0.72G   |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.292M                 | 3.094G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.951M                |  1.111G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.139M                |  0.275G    |\\n'\n",
      " '|   head.conv_seg                 |   33                   |   0.205M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 32, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.139M               |   0.272G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.712K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1           |    27.712K             |    45.158M |\\n'\n",
      " '|    head.scale_heads.2           |    36.992K             |    26.957M |\\n'\n",
      " '|    head.scale_heads.3           |    46.272K             |    22.406M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.24M                  | 2.215G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.697M                |  0.285G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.115M               |   27.648M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.166M               |   41.472M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.166M               |   41.472M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.34M                 |  0.223G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.333M               |   0.209G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    83.136K             |    0.133G  |\\n'\n",
      " '|    head.scale_heads.1           |    83.136K             |    33.869M |\\n'\n",
      " '|    head.scale_heads.2           |    0.166M              |    42.336M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 32.337M                | 13.249G    |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  2.088M                |  7.699G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.17M                |   0.16G    |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    3.2K                |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.738M               |   5.028G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    3.775G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.17M                 |  1.086G    |\\n'\n",
      " '|   head.conv_seg                 |   25                   |   0.614M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.17M                |   1.076G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.696K             |    0.709G  |\\n'\n",
      " '|    head.scale_heads.1           |    27.696K             |    0.18G   |\\n'\n",
      " '|    head.scale_heads.2           |    32.928K             |    80.87M  |\\n'\n",
      " '|    head.scale_heads.3           |    38.16K              |    56.16M  |\\n'\n",
      " '|    head.scale_heads.4           |    43.392K             |    49.982M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 31.847M                | 6.677G     |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  1.642M                |  1.955G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.127M                |  0.258G    |\\n'\n",
      " '|   head.conv_seg                 |   25                   |   0.154M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   0.126M               |   0.256G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.696K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1           |    27.696K             |    44.928M |\\n'\n",
      " '|    head.scale_heads.2           |    32.928K             |    20.218M |\\n'\n",
      " '|    head.scale_heads.3           |    38.16K              |    14.04M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/decode_heads/decode_head.py:137: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 31.36M                 | 5.024G     |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  1.193M                |  0.499G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.16M                |   41.779M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.295M               |   73.728M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.295M               |   73.728M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  88.345K               |  60.946M   |\\n'\n",
      " '|   head.conv_seg                 |   25                   |   38.4K    |\\n'\n",
      " '|    head.conv_seg.weight         |    (1, 24, 1, 1)       |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (1,)                |            |\\n'\n",
      " '|   head.scale_heads              |   88.32K               |   60.6M    |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.696K             |    44.314M |\\n'\n",
      " '|    head.scale_heads.1           |    27.696K             |    11.232M |\\n'\n",
      " '|    head.scale_heads.2           |    32.928K             |    5.054M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=1,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.525M                 | 1.518G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.158M                |  0.512G    |\\n'\n",
      " '|   neck.lateral_convs            |   38.048K              |   40.346M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.105M                |  0.623G    |\\n'\n",
      " '|   head.conv_seg                 |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.102M               |   0.544G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    9.28K               |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1           |    9.28K               |    62.669M |\\n'\n",
      " '|    head.scale_heads.2           |    18.56K              |    78.336M |\\n'\n",
      " '|    head.scale_heads.3           |    27.84K              |    82.253M |\\n'\n",
      " '|    head.scale_heads.4           |    37.12K              |    83.232M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.459M                 | 0.648G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.129M                |  0.131G    |\\n'\n",
      " '|   neck.lateral_convs            |   36.992K              |   14.131M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  67.6K                 |  0.134G    |\\n'\n",
      " '|   head.conv_seg                 |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   64.96K               |   0.115G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    9.28K               |    59.392M |\\n'\n",
      " '|    head.scale_heads.1           |    9.28K               |    15.667M |\\n'\n",
      " '|    head.scale_heads.2           |    18.56K              |    19.584M |\\n'\n",
      " '|    head.scale_heads.3           |    27.84K              |    20.563M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.809M                 | 1.092G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.443M                |  0.497G    |\\n'\n",
      " '|   neck.lateral_convs            |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.111M               |   77.414M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    36.928K             |    3.686M  |\\n'\n",
      " '|  head                           |  0.104M                |  0.212G    |\\n'\n",
      " '|   head.conv_seg                 |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1           |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2           |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3           |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 3.064M                 | 2.682G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  1.624M                |  1.93G     |\\n'\n",
      " '|   neck.lateral_convs            |   0.148M               |   56.525M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    4.224K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    8.32K               |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    12.416K             |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.178M                |  0.369G    |\\n'\n",
      " '|   head.conv_seg                 |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.176M               |   0.35G    |\\n'\n",
      " '|    head.scale_heads.0.0         |    36.928K             |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1           |    36.928K             |    59.904M |\\n'\n",
      " '|    head.scale_heads.2           |    46.208K             |    30.643M |\\n'\n",
      " '|    head.scale_heads.3           |    55.488K             |    23.328M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 1.402M                 | 0.447G     |\\n'\n",
      " '|  backbone                       |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0            |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1            |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2            |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3            |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                           |  0.101M                |  36.211M   |\\n'\n",
      " '|   neck.lateral_convs            |   35.936K              |   7.578M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  39.76K                |  28.166M   |\\n'\n",
      " '|   head.conv_seg                 |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   37.12K               |   23.661M  |\\n'\n",
      " '|    head.scale_heads.0.0         |    9.28K               |    14.848M |\\n'\n",
      " '|    head.scale_heads.1           |    9.28K               |    3.917M  |\\n'\n",
      " '|    head.scale_heads.2           |    18.56K              |    4.896M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.01M                  | 5.354G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.161M                |  0.517G    |\\n'\n",
      " '|   neck.lateral_convs            |   41.12K               |   45.261M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.646M                |  3.129G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.638M               |   2.893G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.84K              |    0.713G  |\\n'\n",
      " '|    head.scale_heads.1           |    27.84K              |    0.188G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    0.589G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.194M              |    0.689G  |\\n'\n",
      " '|    head.scale_heads.4           |    0.277M              |    0.714G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 7.704M                 | 2.445G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.133M                |  0.136G    |\\n'\n",
      " '|   neck.lateral_convs            |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.369M                |  0.601G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.361M               |   0.545G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.84K              |    0.178G  |\\n'\n",
      " '|    head.scale_heads.1           |    27.84K              |    47.002M |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    0.147G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.194M              |    0.172G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 8.743M                 | 3.89G      |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.951M                |  1.111G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs                |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs         |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.pafpn_convs              |   0.249M               |   0.174G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    83.04K              |    8.294M  |\\n'\n",
      " '|  head                           |  0.59M                 |  1.071G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.582M               |   1.015G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    83.136K             |    0.532G  |\\n'\n",
      " '|    head.scale_heads.1           |    83.136K             |    0.135G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.166M              |    0.169G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.249M              |    0.178G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 9.54M                  | 4.964G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  1.636M                |  1.95G     |\\n'\n",
      " '|   neck.lateral_convs            |   0.16M                |   76.186M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    10.368K             |    16.384M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    20.608K             |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  0.7M                  |  1.306G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.693M               |   1.25G    |\\n'\n",
      " '|    head.scale_heads.0.0         |    0.111M              |    0.709G  |\\n'\n",
      " '|    head.scale_heads.1           |    0.111M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.194M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.3           |    0.277M              |    0.181G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 7.481M                 | 1.852G     |\\n'\n",
      " '|  backbone                       |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks               |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1            |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2            |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3            |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                           |  0.103M                |  37.85M    |\\n'\n",
      " '|   neck.lateral_convs            |   38.496K              |   9.216M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.174M                |  0.107G    |\\n'\n",
      " '|   head.conv_seg                 |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.167M               |   93.101M  |\\n'\n",
      " '|    head.scale_heads.0.0         |    27.84K              |    44.544M |\\n'\n",
      " '|    head.scale_heads.1           |    27.84K              |    11.75M  |\\n'\n",
      " '|    head.scale_heads.2           |    0.111M              |    36.806M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 31.323M                | 9.988G     |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  0.163M                |  0.512G    |\\n'\n",
      " '|   neck.lateral_convs            |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.3.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.3.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  1.082M                |  5.012G    |\\n'\n",
      " '|   head.conv_seg                 |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   1.072M               |   4.698G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    37.12K              |    0.95G   |\\n'\n",
      " '|    head.scale_heads.1           |    37.12K              |    0.251G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.185M              |    1.021G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.333M              |    1.214G  |\\n'\n",
      " '|    head.scale_heads.4           |    0.48M               |    1.262G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 30.815M                | 5.536G     |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  0.134M                |  0.138G    |\\n'\n",
      " '|   neck.lateral_convs            |   41.6K                |   20.275M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.602M                |  0.934G    |\\n'\n",
      " '|   head.conv_seg                 |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.592M               |   0.859G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    37.12K              |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1           |    37.12K              |    62.669M |\\n'\n",
      " '|    head.scale_heads.2           |    0.185M              |    0.255G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.333M              |    0.303G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 32.765M                | 8.293G     |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  1.642M                |  1.955G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs                |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs         |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.pafpn_convs              |   0.443M               |   0.31G    |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.148M              |    14.746M |\\n'\n",
      " '|  head                           |  1.044M                |  1.874G    |\\n'\n",
      " '|   head.conv_seg                 |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   1.034M               |   1.799G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    0.148M              |    0.945G  |\\n'\n",
      " '|    head.scale_heads.1           |    0.148M              |    0.24G   |\\n'\n",
      " '|    head.scale_heads.2           |    0.295M              |    0.3G    |\\n'\n",
      " '|    head.scale_heads.3           |    0.443M              |    0.314G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 37.946M                | 15.247G    |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  6.234M                |  7.655G    |\\n'\n",
      " '|   neck.lateral_convs            |   0.333M               |   0.162G   |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    12.544K             |    78.643M |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    24.832K             |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    49.408K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.3.conv    |    0.246M              |    24.576M |\\n'\n",
      " '|   neck.fpn_convs                |   2.36M                |   5.014G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    0.59M               |    3.775G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    0.59M               |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    0.59M               |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.3.conv        |    0.59M               |    58.982M |\\n'\n",
      " '|   neck.downsample_convs         |   1.77M                |   1.239G   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    0.59M               |    0.944G  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    0.59M               |    0.236G  |\\n'\n",
      " '|    neck.downsample_convs.2.conv |    0.59M               |    58.982M |\\n'\n",
      " '|   neck.pafpn_convs              |   1.77M                |   1.239G   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    0.59M               |    0.944G  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    0.59M               |    0.236G  |\\n'\n",
      " '|    neck.pafpn_convs.2.conv      |    0.59M               |    58.982M |\\n'\n",
      " '|  head                           |  1.634M                |  3.128G    |\\n'\n",
      " '|   head.conv_seg                 |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   1.624M               |   3.052G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    0.295M              |    1.889G  |\\n'\n",
      " '|    head.scale_heads.1           |    0.295M              |    0.476G  |\\n'\n",
      " '|    head.scale_heads.2           |    0.443M              |    0.359G  |\\n'\n",
      " '|    head.scale_heads.3           |    0.591M              |    0.329G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 256\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                          | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                           | 30.453M                | 4.66G      |\\n'\n",
      " '|  backbone                       |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem            |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight    |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1                  |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight          |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias            |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks               |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0          |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1            |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2            |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3            |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0          |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                           |  0.105M                |  39.078M   |\\n'\n",
      " '|   neck.lateral_convs            |   40.032K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv    |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv    |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv    |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs                |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv        |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv        |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv        |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs         |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.downsample_convs.0.conv |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.downsample_convs.1.conv |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.pafpn_convs              |   18.496K              |   4.608M   |\\n'\n",
      " '|    neck.pafpn_convs.0.conv      |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.pafpn_convs.1.conv      |    9.248K              |    0.922M  |\\n'\n",
      " '|  head                           |  0.269M                |  0.157G    |\\n'\n",
      " '|   head.conv_seg                 |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight         |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias           |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads              |   0.259M               |   0.139G   |\\n'\n",
      " '|    head.scale_heads.0.0         |    37.12K              |    59.392M |\\n'\n",
      " '|    head.scale_heads.1           |    37.12K              |    15.667M |\\n'\n",
      " '|    head.scale_heads.2           |    0.185M              |    63.821M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: extra_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.483M                 | 1.431G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.116M                |  0.426G    |\\n'\n",
      " '|   neck.lateral_convs         |   38.048K              |   40.346M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   5.16K                |   24.684M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    18.586M |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.4   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   26.72K               |   45.424M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.105M                |  0.623G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.544G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    62.669M |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    78.336M |\\n'\n",
      " '|    head.scale_heads.3        |    27.84K              |    82.253M |\\n'\n",
      " '|    head.scale_heads.4        |    37.12K              |    83.232M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.429M                 | 0.627G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  99.488K               |  0.11G     |\\n'\n",
      " '|   neck.lateral_convs         |   36.992K              |   14.131M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   4.128K               |   6.098M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   21.376K              |   11.222M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |            |\\n'\n",
      " '|  head                        |  67.6K                 |  0.134G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   64.96K               |   0.115G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    59.392M |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    15.667M |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    19.584M |\\n'\n",
      " '|    head.scale_heads.3        |    27.84K              |    20.563M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.671M                 | 0.989G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.305M                |  0.394G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs      |   7.84K                |   11.878M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.96K               |    9.05M   |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.96K               |    2.262M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.96K               |    0.566M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.96K               |            |\\n'\n",
      " '|   neck.pafpn_convs           |   75.52K               |   39.648M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    18.88K              |    30.208M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    18.88K              |    7.552M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    18.88K              |    1.888M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    18.88K              |            |\\n'\n",
      " '|  head                        |  0.104M                |  0.212G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.02M                  | 1.524G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.617M                |  0.851G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.111M               |   42.394M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.168K              |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.24K               |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    9.312K              |    3.686M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs      |   11.552K              |   17.657M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    2.888K              |    13.453M |\\n'\n",
      " '|    neck.downsample_convs.1   |    2.888K              |    3.363M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    2.888K              |    0.841M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    2.888K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.162M               |   85.277M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    40.608K             |    64.973M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    40.608K             |    16.243M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    40.608K             |    4.061M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    40.608K             |            |\\n'\n",
      " '|  head                        |  0.141M                |  0.291G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.139M               |   0.272G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.712K             |    0.177G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.712K             |    45.158M |\\n'\n",
      " '|    head.scale_heads.2        |    36.992K             |    26.957M |\\n'\n",
      " '|    head.scale_heads.3        |    46.272K             |    22.406M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.384M                 | 0.442G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  82.808K               |  31.119M   |\\n'\n",
      " '|   neck.lateral_convs         |   35.936K              |   7.578M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   3.096K               |   1.452M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   16.032K              |   2.672M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |            |\\n'\n",
      " '|  head                        |  39.76K                |  28.166M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   37.12K               |   23.661M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    14.848M |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    3.917M  |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    4.896M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.968M                 | 5.267G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.119M                |  0.431G    |\\n'\n",
      " '|   neck.lateral_convs         |   41.12K               |   45.261M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   5.16K                |   24.684M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    18.586M |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.4   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   26.72K               |   45.424M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.646M                |  3.129G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.638M               |   2.893G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    0.713G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    0.188G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    0.589G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.194M              |    0.689G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.277M              |    0.714G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.674M                 | 2.424G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.103M                |  0.115G    |\\n'\n",
      " '|   neck.lateral_convs         |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   4.128K               |   6.098M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   21.376K              |   11.222M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.369M                |  0.601G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.361M               |   0.545G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    0.178G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    47.002M |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    0.147G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.194M              |    0.172G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.951M                 | 4.516G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  1.048M                |  1.502G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.16M                |   76.186M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    10.368K             |    16.384M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    20.608K             |    8.192M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs      |   15.264K              |   23.436M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    3.816K              |    17.856M |\\n'\n",
      " '|    neck.downsample_convs.1   |    3.816K              |    4.464M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    3.816K              |    1.116M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    3.816K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.282M               |   0.148G   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    70.528K             |    0.113G  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    70.528K             |    28.211M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    70.528K             |    7.053M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    70.528K             |            |\\n'\n",
      " '|  head                        |  0.7M                  |  1.306G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.693M               |   1.25G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.111M              |    0.709G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.111M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.194M              |    0.18G   |\\n'\n",
      " '|    head.scale_heads.3        |    0.277M              |    0.181G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.463M                 | 1.847G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  85.368K               |  32.758M   |\\n'\n",
      " '|   neck.lateral_convs         |   38.496K              |   9.216M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   3.096K               |   1.452M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   16.032K              |   2.672M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.174M                |  0.107G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.167M               |   93.101M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    44.544M |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    11.75M  |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    36.806M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.281M                | 9.902G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.121M                |  0.425G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   5.16K                |   24.684M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    18.586M |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.4   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   26.72K               |   45.424M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    34.202M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    5.344K              |            |\\n'\n",
      " '|  head                        |  1.082M                |  5.012G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.072M               |   4.698G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    0.95G   |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    0.251G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    1.021G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.333M              |    1.214G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.48M               |    1.262G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.785M                | 5.515G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.104M                |  0.116G    |\\n'\n",
      " '|   neck.lateral_convs         |   41.6K                |   20.275M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   4.128K               |   6.098M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    4.646M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.3   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   21.376K              |   11.222M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    8.55M   |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.602M                |  0.934G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.592M               |   0.859G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    62.669M |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    0.255G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.333M              |    0.303G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.311M                | 6.34G      |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  1.054M                |  1.507G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs      |   15.264K              |   23.436M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    3.816K              |    17.856M |\\n'\n",
      " '|    neck.downsample_convs.1   |    3.816K              |    4.464M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    3.816K              |    1.116M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    3.816K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.282M               |   0.148G   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    70.528K             |    0.113G  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    70.528K             |    28.211M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    70.528K             |    7.053M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    70.528K             |            |\\n'\n",
      " '|  head                        |  0.178M                |  0.369G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.176M               |   0.35G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    36.928K             |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1        |    36.928K             |    59.904M |\\n'\n",
      " '|    head.scale_heads.2        |    46.208K             |    30.643M |\\n'\n",
      " '|    head.scale_heads.3        |    55.488K             |    23.328M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.435M                | 4.655G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  86.904K               |  33.986M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.032K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   3.096K               |   1.452M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    1.032K              |    1.162M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    1.032K              |    0.29M   |\\n'\n",
      " '|    neck.downsample_convs.2   |    1.032K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   16.032K              |   2.672M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    5.344K              |    2.138M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    5.344K              |    0.534M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    5.344K              |            |\\n'\n",
      " '|  head                        |  0.269M                |  0.157G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.259M               |   0.139G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    59.392M |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    15.667M |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    63.821M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"extra_dw\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: ib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.501M                 | 1.501G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.134M                |  0.496G    |\\n'\n",
      " '|   neck.lateral_convs         |   38.048K              |   40.346M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   24.96K               |   97.92M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    73.728M |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    18.432M |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.4   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   24.96K               |   42.432M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    4.992K              |            |\\n'\n",
      " '|  head                        |  0.105M                |  0.623G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.544G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    0.238G  |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    62.669M |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    78.336M |\\n'\n",
      " '|    head.scale_heads.3        |    27.84K              |    82.253M |\\n'\n",
      " '|    head.scale_heads.4        |    37.12K              |    83.232M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.443M                 | 0.644G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.114M                |  0.127G    |\\n'\n",
      " '|   neck.lateral_convs         |   36.992K              |   14.131M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   19.968K              |   24.192M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    18.432M |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   19.968K              |   10.483M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    4.992K              |            |\\n'\n",
      " '|  head                        |  67.6K                 |  0.134G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   64.96K               |   0.115G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    59.392M |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    15.667M |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    19.584M |\\n'\n",
      " '|    head.scale_heads.3        |    27.84K              |    20.563M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.733M                 | 1.067G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.367M                |  0.472G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs      |   72.704K              |   91.392M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    18.176K             |    69.632M |\\n'\n",
      " '|    neck.downsample_convs.1   |    18.176K             |    17.408M |\\n'\n",
      " '|    neck.downsample_convs.2   |    18.176K             |    4.352M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    18.176K             |            |\\n'\n",
      " '|   neck.pafpn_convs           |   72.704K              |   38.17M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    18.176K             |    29.082M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    18.176K             |    7.27M   |\\n'\n",
      " '|    neck.pafpn_convs.2        |    18.176K             |    1.818M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    18.176K             |            |\\n'\n",
      " '|  head                        |  0.104M                |  0.212G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.395M                 | 0.446G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  93.632K               |  35.251M   |\\n'\n",
      " '|   neck.lateral_convs         |   35.936K              |   7.578M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.08K               |    3.277M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    3.104K              |    1.229M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   14.976K              |   5.76M    |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   14.976K              |   2.496M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |            |\\n'\n",
      " '|  head                        |  39.76K                |  28.166M   |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   4.096M   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   37.12K               |   23.661M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    9.28K               |    14.848M |\\n'\n",
      " '|    head.scale_heads.1        |    9.28K               |    3.917M  |\\n'\n",
      " '|    head.scale_heads.2        |    18.56K              |    4.896M  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.986M                 | 5.337G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.137M                |  0.501G    |\\n'\n",
      " '|   neck.lateral_convs         |   41.12K               |   45.261M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.056K              |    26.214M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   24.96K               |   97.92M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    73.728M |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    18.432M |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.4   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   24.96K               |   42.432M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    4.992K              |            |\\n'\n",
      " '|  head                        |  0.646M                |  3.129G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   0.197G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.638M               |   2.893G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    0.713G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    0.188G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    0.589G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.194M              |    0.689G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.277M              |    0.714G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.689M                 | 2.441G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.117M                |  0.132G    |\\n'\n",
      " '|   neck.lateral_convs         |   40.064K              |   19.046M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   36.992K              |   78.336M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   19.968K              |   24.192M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    18.432M |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   19.968K              |   10.483M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    4.992K              |            |\\n'\n",
      " '|  head                        |  0.369M                |  0.601G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.361M               |   0.545G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    0.178G  |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    47.002M |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    0.147G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.194M              |    0.172G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.562M                 | 3.826G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.769M                |  1.048G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs      |   0.158M               |   0.202G   |\\n'\n",
      " '|    neck.downsample_convs.0   |    39.552K             |    0.154G  |\\n'\n",
      " '|    neck.downsample_convs.1   |    39.552K             |    38.4M   |\\n'\n",
      " '|    neck.downsample_convs.2   |    39.552K             |    9.6M    |\\n'\n",
      " '|    neck.downsample_convs.3   |    39.552K             |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.158M               |   83.059M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    39.552K             |    63.283M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    39.552K             |    15.821M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    39.552K             |    3.955M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    39.552K             |            |\\n'\n",
      " '|  head                        |  0.59M                 |  1.071G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.582M               |   1.015G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    0.532G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    0.135G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    0.169G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.249M              |    0.178G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 7.474M                 | 1.851G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  96.192K               |  36.89M    |\\n'\n",
      " '|   neck.lateral_convs         |   38.496K              |   9.216M   |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.592K              |    4.096M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    5.152K              |    2.048M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   14.976K              |   5.76M    |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   14.976K              |   2.496M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |            |\\n'\n",
      " '|  head                        |  0.174M                |  0.107G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   12.288M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.167M               |   93.101M  |\\n'\n",
      " '|    head.scale_heads.0.0      |    27.84K              |    44.544M |\\n'\n",
      " '|    head.scale_heads.1        |    27.84K              |    11.75M  |\\n'\n",
      " '|    head.scale_heads.2        |    0.111M              |    36.806M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.299M                | 9.972G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  0.139M                |  0.496G    |\\n'\n",
      " '|   neck.lateral_convs         |   42.4K                |   39.936M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    0.8K                |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    1.568K              |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.4.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   46.24K               |   0.314G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.4.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   24.96K               |   97.92M   |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    73.728M |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    18.432M |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.4   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   24.96K               |   42.432M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    31.949M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    7.987M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.4        |    4.992K              |            |\\n'\n",
      " '|  head                        |  1.082M                |  5.012G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   0.262G   |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.072M               |   4.698G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    0.95G   |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    0.251G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    1.021G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.333M              |    1.214G  |\\n'\n",
      " '|    head.scale_heads.4        |    0.48M               |    1.262G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 5\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 31.566M                | 6.669G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  1.31M                 |  1.836G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs      |   0.276M               |   0.355G   |\\n'\n",
      " '|    neck.downsample_convs.0   |    69.12K              |    0.27G   |\\n'\n",
      " '|    neck.downsample_convs.1   |    69.12K              |    67.584M |\\n'\n",
      " '|    neck.downsample_convs.2   |    69.12K              |    16.896M |\\n'\n",
      " '|    neck.downsample_convs.3   |    69.12K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.276M               |   0.145G   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    69.12K              |    0.111G  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    69.12K              |    27.648M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    69.12K              |    6.912M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    69.12K              |            |\\n'\n",
      " '|  head                        |  0.178M                |  0.369G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.176M               |   0.35G    |\\n'\n",
      " '|    head.scale_heads.0.0      |    36.928K             |    0.236G  |\\n'\n",
      " '|    head.scale_heads.1        |    36.928K             |    59.904M |\\n'\n",
      " '|    head.scale_heads.2        |    46.208K             |    30.643M |\\n'\n",
      " '|    head.scale_heads.3        |    55.488K             |    23.328M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 30.446M                | 4.659G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  97.728K               |  38.118M   |\\n'\n",
      " '|   neck.lateral_convs         |   40.032K              |   10.445M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    3.104K              |    4.915M  |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    6.176K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    30.752K             |    3.072M  |\\n'\n",
      " '|   neck.fpn_convs             |   27.744K              |   19.354M  |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    9.248K              |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    9.248K              |    3.686M  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    9.248K              |    0.922M  |\\n'\n",
      " '|   neck.downsample_convs      |   14.976K              |   5.76M    |\\n'\n",
      " '|    neck.downsample_convs.0   |    4.992K              |    4.608M  |\\n'\n",
      " '|    neck.downsample_convs.1   |    4.992K              |    1.152M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    4.992K              |            |\\n'\n",
      " '|   neck.pafpn_convs           |   14.976K              |   2.496M   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    4.992K              |    1.997M  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    4.992K              |    0.499M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    4.992K              |            |\\n'\n",
      " '|  head                        |  0.269M                |  0.157G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.259M               |   0.139G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    37.12K              |    59.392M |\\n'\n",
      " '|    head.scale_heads.1        |    37.12K              |    15.667M |\\n'\n",
      " '|    head.scale_heads.2        |    0.185M              |    63.821M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 3\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"ib\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn_type: convnext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxin/anaconda3/envs/ocd/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.728M                 | 1.01G      |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  neck                        |  0.361M                |  0.416G    |\\n'\n",
      " '|   neck.lateral_convs         |   73.984K              |   28.262M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    2.112K              |    13.107M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    4.16K               |    6.554M  |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    6.208K              |    2.458M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    61.504K             |    6.144M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.148M               |   0.313G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    36.928K             |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    36.928K             |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    36.928K             |    14.746M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    36.928K             |    3.686M  |\\n'\n",
      " '|   neck.downsample_convs      |   69.888K              |   36.691M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    17.472K             |    27.955M |\\n'\n",
      " '|    neck.downsample_convs.1   |    17.472K             |    6.989M  |\\n'\n",
      " '|    neck.downsample_convs.2   |    17.472K             |    1.747M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    17.472K             |            |\\n'\n",
      " '|   neck.pafpn_convs           |   69.888K              |   36.691M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    17.472K             |    27.955M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    17.472K             |    6.989M  |\\n'\n",
      " '|    neck.pafpn_convs.2        |    17.472K             |    1.747M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    17.472K             |            |\\n'\n",
      " '|  head                        |  0.104M                |  0.212G    |\\n'\n",
      " '|   head.conv_seg              |   2.64K                |   16.384M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 32, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.102M               |   0.194G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    18.496K             |    0.118G  |\\n'\n",
      " '|    head.scale_heads.1        |    18.496K             |    30.413M |\\n'\n",
      " '|    head.scale_heads.2        |    27.776K             |    23.27M  |\\n'\n",
      " '|    head.scale_heads.3        |    37.056K             |    21.485M |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 64\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    dropout_ratio=0.1,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 8.553M                 | 3.704G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  neck                        |  0.76M                 |  0.925G    |\\n'\n",
      " '|   neck.lateral_convs         |   0.12M                |   57.139M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    4.704K              |    29.491M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    7.776K              |    12.288M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    15.456K             |    6.144M  |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    92.256K             |    9.216M  |\\n'\n",
      " '|   neck.fpn_convs             |   0.332M               |   0.705G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    83.04K              |    0.531G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    83.04K              |    0.133G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    83.04K              |    33.178M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    83.04K              |    8.294M  |\\n'\n",
      " '|   neck.downsample_convs      |   0.154M               |   80.842M  |\\n'\n",
      " '|    neck.downsample_convs.0   |    38.496K             |    61.594M |\\n'\n",
      " '|    neck.downsample_convs.1   |    38.496K             |    15.398M |\\n'\n",
      " '|    neck.downsample_convs.2   |    38.496K             |    3.85M   |\\n'\n",
      " '|    neck.downsample_convs.3   |    38.496K             |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.154M               |   80.842M  |\\n'\n",
      " '|    neck.pafpn_convs.0        |    38.496K             |    61.594M |\\n'\n",
      " '|    neck.pafpn_convs.1        |    38.496K             |    15.398M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    38.496K             |    3.85M   |\\n'\n",
      " '|    neck.pafpn_convs.3        |    38.496K             |            |\\n'\n",
      " '|  head                        |  0.59M                 |  1.071G    |\\n'\n",
      " '|   head.conv_seg              |   7.76K                |   49.152M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 96, 1, 1)      |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   0.582M               |   1.015G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    83.136K             |    0.532G  |\\n'\n",
      " '|    head.scale_heads.1        |    83.136K             |    0.135G  |\\n'\n",
      " '|    head.scale_heads.2        |    0.166M              |    0.169G  |\\n'\n",
      " '|    head.scale_heads.3        |    0.249M              |    0.178G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 96\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/mnt/ssd2/xxx/repo/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 32.421M                | 7.958G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  neck                        |  1.298M                |  1.62G     |\\n'\n",
      " '|   neck.lateral_convs         |   0.166M               |   81.101M  |\\n'\n",
      " '|    neck.lateral_convs.0.conv |    6.272K              |    39.322M |\\n'\n",
      " '|    neck.lateral_convs.1.conv |    12.416K             |    19.661M |\\n'\n",
      " '|    neck.lateral_convs.2.conv |    24.704K             |    9.83M   |\\n'\n",
      " '|    neck.lateral_convs.3.conv |    0.123M              |    12.288M |\\n'\n",
      " '|   neck.fpn_convs             |   0.59M                |   1.253G   |\\n'\n",
      " '|    neck.fpn_convs.0.conv     |    0.148M              |    0.944G  |\\n'\n",
      " '|    neck.fpn_convs.1.conv     |    0.148M              |    0.236G  |\\n'\n",
      " '|    neck.fpn_convs.2.conv     |    0.148M              |    58.982M |\\n'\n",
      " '|    neck.fpn_convs.3.conv     |    0.148M              |    14.746M |\\n'\n",
      " '|   neck.downsample_convs      |   0.271M               |   0.142G   |\\n'\n",
      " '|    neck.downsample_convs.0   |    67.712K             |    0.108G  |\\n'\n",
      " '|    neck.downsample_convs.1   |    67.712K             |    27.085M |\\n'\n",
      " '|    neck.downsample_convs.2   |    67.712K             |    6.771M  |\\n'\n",
      " '|    neck.downsample_convs.3   |    67.712K             |            |\\n'\n",
      " '|   neck.pafpn_convs           |   0.271M               |   0.142G   |\\n'\n",
      " '|    neck.pafpn_convs.0        |    67.712K             |    0.108G  |\\n'\n",
      " '|    neck.pafpn_convs.1        |    67.712K             |    27.085M |\\n'\n",
      " '|    neck.pafpn_convs.2        |    67.712K             |    6.771M  |\\n'\n",
      " '|    neck.pafpn_convs.3        |    67.712K             |            |\\n'\n",
      " '|  head                        |  1.044M                |  1.874G    |\\n'\n",
      " '|   head.conv_seg              |   10.32K               |   65.536M  |\\n'\n",
      " '|    head.conv_seg.weight      |    (80, 128, 1, 1)     |            |\\n'\n",
      " '|    head.conv_seg.bias        |    (80,)               |            |\\n'\n",
      " '|   head.scale_heads           |   1.034M               |   1.799G   |\\n'\n",
      " '|    head.scale_heads.0.0      |    0.148M              |    0.945G  |\\n'\n",
      " '|    head.scale_heads.1        |    0.148M              |    0.24G   |\\n'\n",
      " '|    head.scale_heads.2        |    0.295M              |    0.3G    |\\n'\n",
      " '|    head.scale_heads.3        |    0.443M              |    0.314G  |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.fpn import OCDPAFPN\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "NUM_OUTS = 4\n",
    "OUT_CHANNEL = 128\n",
    "\n",
    "model = OCDPAFPN(\n",
    "    backbone=BACKBONE,\n",
    "    n_classes=80,\n",
    "    num_outs=NUM_OUTS,\n",
    "    dropout_ratio=0.1,\n",
    "    out_channel=OUT_CHANNEL,\n",
    "    fpn_type=\"convnext\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV4Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.887M                 | 0.858G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  conv5                       |  0.123M                |  12.288M   |\\n'\n",
      " '|   conv5.weight               |   (128, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv4                       |  12.416K               |  4.915M    |\\n'\n",
      " '|   conv4.weight               |   (128, 96, 1, 1)      |            |\\n'\n",
      " '|   conv4.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv3                       |  4.16K                 |  6.554M    |\\n'\n",
      " '|   conv3.weight               |   (64, 64, 1, 1)       |            |\\n'\n",
      " '|   conv3.bias                 |   (64,)                |            |\\n'\n",
      " '|  conv2                       |  1.056K                |  6.554M    |\\n'\n",
      " '|   conv2.weight               |   (32, 32, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (32,)                |            |\\n'\n",
      " '|  up1                         |  0.369M                |  0.148G    |\\n'\n",
      " '|   up1.conv.double_conv       |   0.369M               |   0.148G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.256K              |    0.102M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    73.728K             |    29.491M |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.128K              |    51.2K   |\\n'\n",
      " '|   up1.up                     |                        |   0.205M   |\\n'\n",
      " '|  up2                         |  92.352K               |  0.148G    |\\n'\n",
      " '|   up2.conv.double_conv       |   92.352K              |   0.148G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.128K              |    0.205M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    18.432K             |    29.491M |\\n'\n",
      " '|    up2.conv.double_conv.4    |    64                  |    0.102M  |\\n'\n",
      " '|   up2.up                     |                        |   0.41M    |\\n'\n",
      " '|  up3                         |  23.136K               |  0.149G    |\\n'\n",
      " '|   up3.conv.double_conv       |   23.136K              |   0.148G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    64                  |    0.41M   |\\n'\n",
      " '|    up3.conv.double_conv.3    |    4.608K              |    29.491M |\\n'\n",
      " '|    up3.conv.double_conv.4    |    32                  |    0.205M  |\\n'\n",
      " '|   up3.up                     |                        |   0.819M   |\\n'\n",
      " '|  outc.conv                   |  17                    |  0.102M    |\\n'\n",
      " '|   outc.conv.weight           |   (1, 16, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.25\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.279M                 | 0.997G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  conv5                       |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv5.weight               |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv4                       |  12.416K               |  4.915M    |\\n'\n",
      " '|   conv4.weight               |   (128, 96, 1, 1)      |            |\\n'\n",
      " '|   conv4.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv3                       |  4.16K                 |  6.554M    |\\n'\n",
      " '|   conv3.weight               |   (64, 64, 1, 1)       |            |\\n'\n",
      " '|   conv3.bias                 |   (64,)                |            |\\n'\n",
      " '|  conv2                       |  1.056K                |  6.554M    |\\n'\n",
      " '|   conv2.weight               |   (32, 32, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (32,)                |            |\\n'\n",
      " '|  up1                         |  0.574M                |  0.19G     |\\n'\n",
      " '|   up1.up                     |   0.131M               |   13.107M  |\\n'\n",
      " '|    up1.up.weight             |    (256, 128, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (128,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   0.443M               |   0.177G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.256K              |    0.102M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.147M              |    58.982M |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.256K              |    0.102M  |\\n'\n",
      " '|  up2                         |  0.144M                |  0.19G     |\\n'\n",
      " '|   up2.up                     |   32.832K              |   13.107M  |\\n'\n",
      " '|    up2.up.weight             |    (128, 64, 2, 2)     |            |\\n'\n",
      " '|    up2.up.bias               |    (64,)               |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.111M               |   0.177G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.128K              |    0.205M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    36.864K             |    58.982M |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.128K              |    0.205M  |\\n'\n",
      " '|  up3                         |  36K                   |  0.191G    |\\n'\n",
      " '|   up3.up                     |   8.224K               |   13.107M  |\\n'\n",
      " '|    up3.up.weight             |    (64, 32, 2, 2)      |            |\\n'\n",
      " '|    up3.up.bias               |    (32,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   27.776K              |   0.178G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    64                  |    0.41M   |\\n'\n",
      " '|    up3.conv.double_conv.3    |    9.216K              |    58.982M |\\n'\n",
      " '|    up3.conv.double_conv.4    |    64                  |    0.41M   |\\n'\n",
      " '|  outc.conv                   |  33                    |  0.205M    |\\n'\n",
      " '|   outc.conv.weight           |   (1, 32, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.25\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 9.441M                 | 3.559G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  conv5                       |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv5.weight               |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv4                       |  41.216K               |  16.384M   |\\n'\n",
      " '|   conv4.weight               |   (256, 160, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv3                       |  10.368K               |  16.384M   |\\n'\n",
      " '|   conv3.weight               |   (128, 80, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv2                       |  3.136K                |  19.661M   |\\n'\n",
      " '|   conv2.weight               |   (64, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (64,)                |            |\\n'\n",
      " '|  up1                         |  1.475M                |  0.591G    |\\n'\n",
      " '|   up1.conv.double_conv       |   1.475M               |   0.59G    |\\n'\n",
      " '|    up1.conv.double_conv.0    |    1.18M               |    0.472G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.512K              |    0.205M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.256K              |    0.102M  |\\n'\n",
      " '|   up1.up                     |                        |   0.41M    |\\n'\n",
      " '|  up2                         |  0.369M                |  0.591G    |\\n'\n",
      " '|   up2.conv.double_conv       |   0.369M               |   0.59G    |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.295M              |    0.472G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.256K              |    0.41M   |\\n'\n",
      " '|    up2.conv.double_conv.3    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.128K              |    0.205M  |\\n'\n",
      " '|   up2.up                     |                        |   0.819M   |\\n'\n",
      " '|  up3                         |  92.352K               |  0.593G    |\\n'\n",
      " '|   up3.conv.double_conv       |   92.352K              |   0.591G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    73.728K             |    0.472G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.128K              |    0.819M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    64                  |    0.41M   |\\n'\n",
      " '|   up3.up                     |                        |   1.638M   |\\n'\n",
      " '|  outc.conv                   |  33                    |  0.205M    |\\n'\n",
      " '|   outc.conv.weight           |   (1, 32, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.5\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 10.763M                | 4.093G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  conv5                       |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv5.weight               |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (512,)               |            |\\n'\n",
      " '|  conv4                       |  41.216K               |  16.384M   |\\n'\n",
      " '|   conv4.weight               |   (256, 160, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv3                       |  10.368K               |  16.384M   |\\n'\n",
      " '|   conv3.weight               |   (128, 80, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv2                       |  3.136K                |  19.661M   |\\n'\n",
      " '|   conv2.weight               |   (64, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (64,)                |            |\\n'\n",
      " '|  up1                         |  2.295M                |  0.761G    |\\n'\n",
      " '|   up1.up                     |   0.525M               |   52.429M  |\\n'\n",
      " '|    up1.up.weight             |    (512, 256, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (256,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   1.77M                |   0.708G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    1.18M               |    0.472G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.512K              |    0.205M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.59M               |    0.236G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.512K              |    0.205M  |\\n'\n",
      " '|  up2                         |  0.574M                |  0.761G    |\\n'\n",
      " '|   up2.up                     |   0.131M               |   52.429M  |\\n'\n",
      " '|    up2.up.weight             |    (256, 128, 2, 2)    |            |\\n'\n",
      " '|    up2.up.bias               |    (128,)              |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.443M               |   0.709G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.295M              |    0.472G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.256K              |    0.41M   |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.147M              |    0.236G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.256K              |    0.41M   |\\n'\n",
      " '|  up3                         |  0.144M                |  0.762G    |\\n'\n",
      " '|   up3.up                     |   32.832K              |   52.429M  |\\n'\n",
      " '|    up3.up.weight             |    (128, 64, 2, 2)     |            |\\n'\n",
      " '|    up3.up.bias               |    (64,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   0.111M               |   0.709G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    73.728K             |    0.472G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.128K              |    0.819M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    36.864K             |    0.236G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    0.128K              |    0.819M  |\\n'\n",
      " '|  outc.conv                   |  65                    |  0.41M     |\\n'\n",
      " '|   outc.conv.weight           |   (1, 64, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.5\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 34.902M                | 8.579G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  conv5                       |  0.369M                |  36.864M   |\\n'\n",
      " '|   conv5.weight               |   (384, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv4                       |  74.112K               |  29.491M   |\\n'\n",
      " '|   conv4.weight               |   (384, 192, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv3                       |  18.624K               |  29.491M   |\\n'\n",
      " '|   conv3.weight               |   (192, 96, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (192,)               |            |\\n'\n",
      " '|  conv2                       |  4.704K                |  29.491M   |\\n'\n",
      " '|   conv2.weight               |   (96, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (96,)                |            |\\n'\n",
      " '|  up1                         |  3.319M                |  1.328G    |\\n'\n",
      " '|   up1.conv.double_conv       |   3.319M               |   1.328G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    2.654M              |    1.062G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.768K              |    0.307M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.664M              |    0.265G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.384K              |    0.154M  |\\n'\n",
      " '|   up1.up                     |                        |   0.614M   |\\n'\n",
      " '|  up2                         |  0.83M                 |  1.329G    |\\n'\n",
      " '|   up2.conv.double_conv       |   0.83M                |   1.328G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.664M              |    1.062G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.384K              |    0.614M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.166M              |    0.265G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.192K              |    0.307M  |\\n'\n",
      " '|   up2.up                     |                        |   1.229M   |\\n'\n",
      " '|  up3                         |  0.208M                |  1.331G    |\\n'\n",
      " '|   up3.conv.double_conv       |   0.208M               |   1.329G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    0.166M              |    1.062G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.192K              |    1.229M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    41.472K             |    0.265G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    96                  |    0.614M  |\\n'\n",
      " '|   up3.up                     |                        |   2.458M   |\\n'\n",
      " '|  outc.conv                   |  49                    |  0.307M    |\\n'\n",
      " '|   outc.conv.weight           |   (1, 48, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.75\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 37.691M                | 9.763G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  conv5                       |  0.738M                |  73.728M   |\\n'\n",
      " '|   conv5.weight               |   (768, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (768,)               |            |\\n'\n",
      " '|  conv4                       |  74.112K               |  29.491M   |\\n'\n",
      " '|   conv4.weight               |   (384, 192, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv3                       |  18.624K               |  29.491M   |\\n'\n",
      " '|   conv3.weight               |   (192, 96, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (192,)               |            |\\n'\n",
      " '|  conv2                       |  4.704K                |  29.491M   |\\n'\n",
      " '|   conv2.weight               |   (96, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (96,)                |            |\\n'\n",
      " '|  up1                         |  5.163M                |  1.711G    |\\n'\n",
      " '|   up1.up                     |   1.18M                |   0.118G   |\\n'\n",
      " '|    up1.up.weight             |    (768, 384, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (384,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   3.983M               |   1.593G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    2.654M              |    1.062G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.768K              |    0.307M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    1.327M              |    0.531G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.768K              |    0.307M  |\\n'\n",
      " '|  up2                         |  1.291M                |  1.712G    |\\n'\n",
      " '|   up2.up                     |   0.295M               |   0.118G   |\\n'\n",
      " '|    up2.up.weight             |    (384, 192, 2, 2)    |            |\\n'\n",
      " '|    up2.up.bias               |    (192,)              |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.996M               |   1.594G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.664M              |    1.062G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.384K              |    0.614M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.332M              |    0.531G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.384K              |    0.614M  |\\n'\n",
      " '|  up3                         |  0.323M                |  1.713G    |\\n'\n",
      " '|   up3.up                     |   73.824K              |   0.118G   |\\n'\n",
      " '|    up3.up.weight             |    (192, 96, 2, 2)     |            |\\n'\n",
      " '|    up3.up.bias               |    (96,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   0.249M               |   1.595G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    0.166M              |    1.062G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.192K              |    1.229M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    82.944K             |    0.531G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    0.192K              |    1.229M  |\\n'\n",
      " '|  outc.conv                   |  97                    |  0.614M    |\\n'\n",
      " '|   outc.conv.weight           |   (1, 96, 1, 1)        |            |\\n'\n",
      " '|   outc.conv.bias             |   (1,)                 |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.75\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=1,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 1.888M                 | 0.866G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  conv5                       |  0.123M                |  12.288M   |\\n'\n",
      " '|   conv5.weight               |   (128, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv4                       |  12.416K               |  4.915M    |\\n'\n",
      " '|   conv4.weight               |   (128, 96, 1, 1)      |            |\\n'\n",
      " '|   conv4.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv3                       |  4.16K                 |  6.554M    |\\n'\n",
      " '|   conv3.weight               |   (64, 64, 1, 1)       |            |\\n'\n",
      " '|   conv3.bias                 |   (64,)                |            |\\n'\n",
      " '|  conv2                       |  1.056K                |  6.554M    |\\n'\n",
      " '|   conv2.weight               |   (32, 32, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (32,)                |            |\\n'\n",
      " '|  up1                         |  0.369M                |  0.148G    |\\n'\n",
      " '|   up1.conv.double_conv       |   0.369M               |   0.148G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.256K              |    0.102M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    73.728K             |    29.491M |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.128K              |    51.2K   |\\n'\n",
      " '|   up1.up                     |                        |   0.205M   |\\n'\n",
      " '|  up2                         |  92.352K               |  0.148G    |\\n'\n",
      " '|   up2.conv.double_conv       |   92.352K              |   0.148G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.128K              |    0.205M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    18.432K             |    29.491M |\\n'\n",
      " '|    up2.conv.double_conv.4    |    64                  |    0.102M  |\\n'\n",
      " '|   up2.up                     |                        |   0.41M    |\\n'\n",
      " '|  up3                         |  23.136K               |  0.149G    |\\n'\n",
      " '|   up3.conv.double_conv       |   23.136K              |   0.148G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    64                  |    0.41M   |\\n'\n",
      " '|    up3.conv.double_conv.3    |    4.608K              |    29.491M |\\n'\n",
      " '|    up3.conv.double_conv.4    |    32                  |    0.205M  |\\n'\n",
      " '|   up3.up                     |                        |   0.819M   |\\n'\n",
      " '|  outc.conv                   |  1.36K                 |  8.192M    |\\n'\n",
      " '|   outc.conv.weight           |   (80, 16, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.25\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 2.282M                 | 1.013G     |\\n'\n",
      " '|  backbone                    |  1.262M                |  0.382G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    backbone.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    backbone.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    backbone.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    backbone.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|  conv5                       |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv5.weight               |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv4                       |  12.416K               |  4.915M    |\\n'\n",
      " '|   conv4.weight               |   (128, 96, 1, 1)      |            |\\n'\n",
      " '|   conv4.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv3                       |  4.16K                 |  6.554M    |\\n'\n",
      " '|   conv3.weight               |   (64, 64, 1, 1)       |            |\\n'\n",
      " '|   conv3.bias                 |   (64,)                |            |\\n'\n",
      " '|  conv2                       |  1.056K                |  6.554M    |\\n'\n",
      " '|   conv2.weight               |   (32, 32, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (32,)                |            |\\n'\n",
      " '|  up1                         |  0.574M                |  0.19G     |\\n'\n",
      " '|   up1.up                     |   0.131M               |   13.107M  |\\n'\n",
      " '|    up1.up.weight             |    (256, 128, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (128,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   0.443M               |   0.177G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.256K              |    0.102M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.147M              |    58.982M |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.256K              |    0.102M  |\\n'\n",
      " '|  up2                         |  0.144M                |  0.19G     |\\n'\n",
      " '|   up2.up                     |   32.832K              |   13.107M  |\\n'\n",
      " '|    up2.up.weight             |    (128, 64, 2, 2)     |            |\\n'\n",
      " '|    up2.up.bias               |    (64,)               |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.111M               |   0.177G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.128K              |    0.205M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    36.864K             |    58.982M |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.128K              |    0.205M  |\\n'\n",
      " '|  up3                         |  36K                   |  0.191G    |\\n'\n",
      " '|   up3.up                     |   8.224K               |   13.107M  |\\n'\n",
      " '|    up3.up.weight             |    (64, 32, 2, 2)      |            |\\n'\n",
      " '|    up3.up.bias               |    (32,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   27.776K              |   0.178G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    64                  |    0.41M   |\\n'\n",
      " '|    up3.conv.double_conv.3    |    9.216K              |    58.982M |\\n'\n",
      " '|    up3.conv.double_conv.4    |    64                  |    0.41M   |\\n'\n",
      " '|  outc.conv                   |  2.64K                 |  16.384M   |\\n'\n",
      " '|   outc.conv.weight           |   (80, 32, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_small.e2400_r224_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.25\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 9.443M                 | 3.576G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  conv5                       |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv5.weight               |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv4                       |  41.216K               |  16.384M   |\\n'\n",
      " '|   conv4.weight               |   (256, 160, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv3                       |  10.368K               |  16.384M   |\\n'\n",
      " '|   conv3.weight               |   (128, 80, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv2                       |  3.136K                |  19.661M   |\\n'\n",
      " '|   conv2.weight               |   (64, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (64,)                |            |\\n'\n",
      " '|  up1                         |  1.475M                |  0.591G    |\\n'\n",
      " '|   up1.conv.double_conv       |   1.475M               |   0.59G    |\\n'\n",
      " '|    up1.conv.double_conv.0    |    1.18M               |    0.472G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.512K              |    0.205M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.295M              |    0.118G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.256K              |    0.102M  |\\n'\n",
      " '|   up1.up                     |                        |   0.41M    |\\n'\n",
      " '|  up2                         |  0.369M                |  0.591G    |\\n'\n",
      " '|   up2.conv.double_conv       |   0.369M               |   0.59G    |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.295M              |    0.472G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.256K              |    0.41M   |\\n'\n",
      " '|    up2.conv.double_conv.3    |    73.728K             |    0.118G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.128K              |    0.205M  |\\n'\n",
      " '|   up2.up                     |                        |   0.819M   |\\n'\n",
      " '|  up3                         |  92.352K               |  0.593G    |\\n'\n",
      " '|   up3.conv.double_conv       |   92.352K              |   0.591G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    73.728K             |    0.472G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.128K              |    0.819M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    18.432K             |    0.118G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    64                  |    0.41M   |\\n'\n",
      " '|   up3.up                     |                        |   1.638M   |\\n'\n",
      " '|  outc.conv                   |  2.64K                 |  16.384M   |\\n'\n",
      " '|   outc.conv.weight           |   (80, 32, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.5\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 10.768M                | 4.126G     |\\n'\n",
      " '|  backbone                    |  7.203M                |  1.708G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   backbone.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    backbone.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    backbone.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    backbone.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|  conv5                       |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv5.weight               |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (512,)               |            |\\n'\n",
      " '|  conv4                       |  41.216K               |  16.384M   |\\n'\n",
      " '|   conv4.weight               |   (256, 160, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (256,)               |            |\\n'\n",
      " '|  conv3                       |  10.368K               |  16.384M   |\\n'\n",
      " '|   conv3.weight               |   (128, 80, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (128,)               |            |\\n'\n",
      " '|  conv2                       |  3.136K                |  19.661M   |\\n'\n",
      " '|   conv2.weight               |   (64, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (64,)                |            |\\n'\n",
      " '|  up1                         |  2.295M                |  0.761G    |\\n'\n",
      " '|   up1.up                     |   0.525M               |   52.429M  |\\n'\n",
      " '|    up1.up.weight             |    (512, 256, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (256,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   1.77M                |   0.708G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    1.18M               |    0.472G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.512K              |    0.205M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.59M               |    0.236G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.512K              |    0.205M  |\\n'\n",
      " '|  up2                         |  0.574M                |  0.761G    |\\n'\n",
      " '|   up2.up                     |   0.131M               |   52.429M  |\\n'\n",
      " '|    up2.up.weight             |    (256, 128, 2, 2)    |            |\\n'\n",
      " '|    up2.up.bias               |    (128,)              |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.443M               |   0.709G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.295M              |    0.472G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.256K              |    0.41M   |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.147M              |    0.236G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.256K              |    0.41M   |\\n'\n",
      " '|  up3                         |  0.144M                |  0.762G    |\\n'\n",
      " '|   up3.up                     |   32.832K              |   52.429M  |\\n'\n",
      " '|    up3.up.weight             |    (128, 64, 2, 2)     |            |\\n'\n",
      " '|    up3.up.bias               |    (64,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   0.111M               |   0.709G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    73.728K             |    0.472G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.128K              |    0.819M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    36.864K             |    0.236G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    0.128K              |    0.819M  |\\n'\n",
      " '|  outc.conv                   |  5.2K                  |  32.768M   |\\n'\n",
      " '|   outc.conv.weight           |   (80, 64, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_medium.e500_r256_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.5\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 34.905M                | 8.603G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  conv5                       |  0.369M                |  36.864M   |\\n'\n",
      " '|   conv5.weight               |   (384, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv4                       |  74.112K               |  29.491M   |\\n'\n",
      " '|   conv4.weight               |   (384, 192, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv3                       |  18.624K               |  29.491M   |\\n'\n",
      " '|   conv3.weight               |   (192, 96, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (192,)               |            |\\n'\n",
      " '|  conv2                       |  4.704K                |  29.491M   |\\n'\n",
      " '|   conv2.weight               |   (96, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (96,)                |            |\\n'\n",
      " '|  up1                         |  3.319M                |  1.328G    |\\n'\n",
      " '|   up1.conv.double_conv       |   3.319M               |   1.328G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    2.654M              |    1.062G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.768K              |    0.307M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    0.664M              |    0.265G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.384K              |    0.154M  |\\n'\n",
      " '|   up1.up                     |                        |   0.614M   |\\n'\n",
      " '|  up2                         |  0.83M                 |  1.329G    |\\n'\n",
      " '|   up2.conv.double_conv       |   0.83M                |   1.328G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.664M              |    1.062G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.384K              |    0.614M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.166M              |    0.265G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.192K              |    0.307M  |\\n'\n",
      " '|   up2.up                     |                        |   1.229M   |\\n'\n",
      " '|  up3                         |  0.208M                |  1.331G    |\\n'\n",
      " '|   up3.conv.double_conv       |   0.208M               |   1.329G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    0.166M              |    1.062G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.192K              |    1.229M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    41.472K             |    0.265G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    96                  |    0.614M  |\\n'\n",
      " '|   up3.up                     |                        |   2.458M   |\\n'\n",
      " '|  outc.conv                   |  3.92K                 |  24.576M   |\\n'\n",
      " '|   outc.conv.weight           |   (80, 48, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "MODE = \"bilinear\"\n",
    "SCALE = 0.75\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                       | #parameters or shape   | #flops     |\\n'\n",
      " '|:-----------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                        | 37.699M                | 9.811G     |\\n'\n",
      " '|  backbone                    |  30.079M               |  4.464G    |\\n'\n",
      " '|   backbone.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    backbone.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   backbone.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    backbone.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    backbone.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   backbone.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    backbone.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    backbone.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    backbone.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    backbone.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    backbone.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|  conv5                       |  0.738M                |  73.728M   |\\n'\n",
      " '|   conv5.weight               |   (768, 960, 1, 1)     |            |\\n'\n",
      " '|   conv5.bias                 |   (768,)               |            |\\n'\n",
      " '|  conv4                       |  74.112K               |  29.491M   |\\n'\n",
      " '|   conv4.weight               |   (384, 192, 1, 1)     |            |\\n'\n",
      " '|   conv4.bias                 |   (384,)               |            |\\n'\n",
      " '|  conv3                       |  18.624K               |  29.491M   |\\n'\n",
      " '|   conv3.weight               |   (192, 96, 1, 1)      |            |\\n'\n",
      " '|   conv3.bias                 |   (192,)               |            |\\n'\n",
      " '|  conv2                       |  4.704K                |  29.491M   |\\n'\n",
      " '|   conv2.weight               |   (96, 48, 1, 1)       |            |\\n'\n",
      " '|   conv2.bias                 |   (96,)                |            |\\n'\n",
      " '|  up1                         |  5.163M                |  1.711G    |\\n'\n",
      " '|   up1.up                     |   1.18M                |   0.118G   |\\n'\n",
      " '|    up1.up.weight             |    (768, 384, 2, 2)    |            |\\n'\n",
      " '|    up1.up.bias               |    (384,)              |            |\\n'\n",
      " '|   up1.conv.double_conv       |   3.983M               |   1.593G   |\\n'\n",
      " '|    up1.conv.double_conv.0    |    2.654M              |    1.062G  |\\n'\n",
      " '|    up1.conv.double_conv.1    |    0.768K              |    0.307M  |\\n'\n",
      " '|    up1.conv.double_conv.3    |    1.327M              |    0.531G  |\\n'\n",
      " '|    up1.conv.double_conv.4    |    0.768K              |    0.307M  |\\n'\n",
      " '|  up2                         |  1.291M                |  1.712G    |\\n'\n",
      " '|   up2.up                     |   0.295M               |   0.118G   |\\n'\n",
      " '|    up2.up.weight             |    (384, 192, 2, 2)    |            |\\n'\n",
      " '|    up2.up.bias               |    (192,)              |            |\\n'\n",
      " '|   up2.conv.double_conv       |   0.996M               |   1.594G   |\\n'\n",
      " '|    up2.conv.double_conv.0    |    0.664M              |    1.062G  |\\n'\n",
      " '|    up2.conv.double_conv.1    |    0.384K              |    0.614M  |\\n'\n",
      " '|    up2.conv.double_conv.3    |    0.332M              |    0.531G  |\\n'\n",
      " '|    up2.conv.double_conv.4    |    0.384K              |    0.614M  |\\n'\n",
      " '|  up3                         |  0.323M                |  1.713G    |\\n'\n",
      " '|   up3.up                     |   73.824K              |   0.118G   |\\n'\n",
      " '|    up3.up.weight             |    (192, 96, 2, 2)     |            |\\n'\n",
      " '|    up3.up.bias               |    (96,)               |            |\\n'\n",
      " '|   up3.conv.double_conv       |   0.249M               |   1.595G   |\\n'\n",
      " '|    up3.conv.double_conv.0    |    0.166M              |    1.062G  |\\n'\n",
      " '|    up3.conv.double_conv.1    |    0.192K              |    1.229M  |\\n'\n",
      " '|    up3.conv.double_conv.3    |    82.944K             |    0.531G  |\\n'\n",
      " '|    up3.conv.double_conv.4    |    0.192K              |    1.229M  |\\n'\n",
      " '|  outc.conv                   |  7.76K                 |  49.152M   |\\n'\n",
      " '|   outc.conv.weight           |   (80, 96, 1, 1)       |            |\\n'\n",
      " '|   outc.conv.bias             |   (80,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.unet import MobileNetV4Unet\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "BACKBONE = \"mobilenetv4_conv_large.e500_r256_in1k\"\n",
    "MODE = \"convtranspose\"\n",
    "SCALE = 0.75\n",
    "\n",
    "model = MobileNetV4Unet(\n",
    "    backbone=BACKBONE,\n",
    "    mode=MODE,\n",
    "    n_classes=80,\n",
    "    width_scale=SCALE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 3.121M                 | 0.718G     |\\n'\n",
      " '|  model                    |  2.493M                |  0.382G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    model.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    model.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    model.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    model.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    model.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.185M                |  18.432M   |\\n'\n",
      " '|   conv11.weight           |   (192, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (192,)               |            |\\n'\n",
      " '|  conv1                    |  0.332M                |  0.133G    |\\n'\n",
      " '|   conv1.conv1             |   0.332M               |   0.133G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (192, 192, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.384K               |   0.154M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (192,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (192,)              |            |\\n'\n",
      " '|  conv2                    |  0.111M                |  0.177G    |\\n'\n",
      " '|   conv2.conv1             |   0.111M               |   0.177G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (64, 192, 3, 3)     |            |\\n'\n",
      " '|   conv2.bn1               |   0.128K               |   0.205M   |\\n'\n",
      " '|    conv2.bn1.weight       |    (64,)               |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (64,)               |            |\\n'\n",
      " '|  conv3                    |  0.578K                |  3.699M    |\\n'\n",
      " '|   conv3.conv1             |   0.576K               |   3.686M   |\\n'\n",
      " '|    conv3.conv1.weight     |    (1, 64, 3, 3)       |            |\\n'\n",
      " '|   conv3.bn1               |   2                    |   12.8K    |\\n'\n",
      " '|    conv3.bn1.weight       |    (1,)                |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (1,)                |            |\\n'\n",
      " '|  up                       |                        |  3.174M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_small.e2400_r224_in1k\", n_classes=1\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 9.567M                 | 2.453G     |\\n'\n",
      " '|  model                    |  8.435M                |  1.708G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    model.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    model.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    model.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    model.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv11.weight           |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (256,)               |            |\\n'\n",
      " '|  conv1                    |  0.59M                 |  0.236G    |\\n'\n",
      " '|   conv1.conv1             |   0.59M                |   0.236G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.512K               |   0.205M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv2                    |  0.295M                |  0.472G    |\\n'\n",
      " '|   conv2.conv1             |   0.295M               |   0.472G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (128, 256, 3, 3)    |            |\\n'\n",
      " '|   conv2.bn1               |   0.256K               |   0.41M    |\\n'\n",
      " '|    conv2.bn1.weight       |    (128,)              |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (128,)              |            |\\n'\n",
      " '|  conv3                    |  1.154K                |  7.386M    |\\n'\n",
      " '|   conv3.conv1             |   1.152K               |   7.373M   |\\n'\n",
      " '|    conv3.conv1.weight     |    (1, 128, 3, 3)      |            |\\n'\n",
      " '|   conv3.bn1               |   2                    |   12.8K    |\\n'\n",
      " '|    conv3.bn1.weight       |    (1,)                |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (1,)                |            |\\n'\n",
      " '|  up                       |                        |  5.325M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_medium.e500_r256_in1k\", n_classes=1\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 32.739M                | 5.751G     |\\n'\n",
      " '|  model                    |  31.31M                |  4.521G    |\\n'\n",
      " '|   model.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    model.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   48                   |   3.072M   |\\n'\n",
      " '|    model.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   model.blocks            |   30.078M              |   4.501G   |\\n'\n",
      " '|    model.blocks.0.0       |    25.632K             |    0.167G  |\\n'\n",
      " '|    model.blocks.1         |    0.114M              |    0.241G  |\\n'\n",
      " '|    model.blocks.2         |    3.216M              |    1.358G  |\\n'\n",
      " '|    model.blocks.3         |    26.229M             |    2.685G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.493M              |    49.632M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv11.weight           |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (256,)               |            |\\n'\n",
      " '|  conv1                    |  0.59M                 |  0.236G    |\\n'\n",
      " '|   conv1.conv1             |   0.59M                |   0.236G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.512K               |   0.512M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv2                    |  0.59M                 |  0.946G    |\\n'\n",
      " '|   conv2.conv1             |   0.59M                |   0.944G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv2.bn1               |   0.512K               |   2.048M   |\\n'\n",
      " '|    conv2.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv3                    |  2.306K                |  14.778M   |\\n'\n",
      " '|   conv3.conv1             |   2.304K               |   14.746M  |\\n'\n",
      " '|    conv3.conv1.weight     |    (1, 256, 3, 3)      |            |\\n'\n",
      " '|   conv3.bn1               |   2                    |   32K      |\\n'\n",
      " '|    conv3.bn1.weight       |    (1,)                |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (1,)                |            |\\n'\n",
      " '|  up                       |                        |  8.602M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_large.e500_r256_in1k\", n_classes=1\n",
    ")\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convtranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 3.913M                 | 0.607G     |\\n'\n",
      " '|  model                    |  2.493M                |  0.382G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    model.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    model.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    model.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    model.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    model.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.369M                |  36.864M   |\\n'\n",
      " '|   conv11.weight           |   (384, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (384,)               |            |\\n'\n",
      " '|  deconv1                  |  0.787M                |  78.746M   |\\n'\n",
      " '|   deconv1.conv1           |   0.786M               |   78.643M  |\\n'\n",
      " '|    deconv1.conv1.weight   |    (384, 128, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   0.256K               |   0.102M   |\\n'\n",
      " '|    deconv1.bn1.weight     |    (128,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (128,)              |            |\\n'\n",
      " '|  deconv2                  |  0.262M                |  0.105G    |\\n'\n",
      " '|   deconv2.conv1           |   0.262M               |   0.105G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (128, 128, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   0.256K               |   0.41M    |\\n'\n",
      " '|    deconv2.bn1.weight     |    (128,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (128,)              |            |\\n'\n",
      " '|  deconv3                  |  2.05K                 |  3.29M     |\\n'\n",
      " '|   deconv3.conv1           |   2.048K               |   3.277M   |\\n'\n",
      " '|    deconv3.conv1.weight   |    (128, 1, 4, 4)      |            |\\n'\n",
      " '|   deconv3.bn1             |   2                    |   12.8K    |\\n'\n",
      " '|    deconv3.bn1.weight     |    (1,)                |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (1,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    mode=\"convtranspose\",\n",
    "    n_classes=1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 12.077M                | 2.394G     |\\n'\n",
      " '|  model                    |  8.435M                |  1.708G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    model.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    model.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    model.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    model.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv11.weight           |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (512,)               |            |\\n'\n",
      " '|  deconv1                  |  2.098M                |  0.21G     |\\n'\n",
      " '|   deconv1.conv1           |   2.097M               |   0.21G    |\\n'\n",
      " '|    deconv1.conv1.weight   |    (512, 256, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   0.512K               |   0.205M   |\\n'\n",
      " '|    deconv1.bn1.weight     |    (256,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (256,)              |            |\\n'\n",
      " '|  deconv2                  |  1.049M                |  0.42G     |\\n'\n",
      " '|   deconv2.conv1           |   1.049M               |   0.419G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (256, 256, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   0.512K               |   0.819M   |\\n'\n",
      " '|    deconv2.bn1.weight     |    (256,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (256,)              |            |\\n'\n",
      " '|  deconv3                  |  4.098K                |  6.566M    |\\n'\n",
      " '|   deconv3.conv1           |   4.096K               |   6.554M   |\\n'\n",
      " '|    deconv3.conv1.weight   |    (256, 1, 4, 4)      |            |\\n'\n",
      " '|   deconv3.bn1             |   2                    |   12.8K    |\\n'\n",
      " '|    deconv3.bn1.weight     |    (1,)                |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (1,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    mode=\"convtranspose\",\n",
    "    n_classes=1,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 40.201M                | 6.626G     |\\n'\n",
      " '|  model                    |  31.31M                |  4.464G    |\\n'\n",
      " '|   model.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    model.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    model.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   model.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    model.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    model.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    model.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    model.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv11.weight           |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (512,)               |            |\\n'\n",
      " '|  deconv1                  |  4.195M                |  0.42G     |\\n'\n",
      " '|   deconv1.conv1           |   4.194M               |   0.419G   |\\n'\n",
      " '|    deconv1.conv1.weight   |    (512, 512, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   1.024K               |   0.41M    |\\n'\n",
      " '|    deconv1.bn1.weight     |    (512,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (512,)              |            |\\n'\n",
      " '|  deconv2                  |  4.195M                |  1.679G    |\\n'\n",
      " '|   deconv2.conv1           |   4.194M               |   1.678G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (512, 512, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   1.024K               |   1.638M   |\\n'\n",
      " '|    deconv2.bn1.weight     |    (512,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (512,)              |            |\\n'\n",
      " '|  deconv3                  |  8.194K                |  13.12M    |\\n'\n",
      " '|   deconv3.conv1           |   8.192K               |   13.107M  |\\n'\n",
      " '|    deconv3.conv1.weight   |    (512, 1, 4, 4)      |            |\\n'\n",
      " '|   deconv3.bn1             |   2                    |   12.8K    |\\n'\n",
      " '|    deconv3.bn1.weight     |    (1,)                |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (1,)                |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_large.e500_r256_in1k\", mode=\"convtranspose\", n_classes=1\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 3.167M                 | 1.01G      |\\n'\n",
      " '|  model                    |  2.493M                |  0.382G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    model.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    model.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    model.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    model.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    model.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.185M                |  18.432M   |\\n'\n",
      " '|   conv11.weight           |   (192, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (192,)               |            |\\n'\n",
      " '|  conv1                    |  0.332M                |  0.133G    |\\n'\n",
      " '|   conv1.conv1             |   0.332M               |   0.133G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (192, 192, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.384K               |   0.154M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (192,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (192,)              |            |\\n'\n",
      " '|  conv2                    |  0.111M                |  0.177G    |\\n'\n",
      " '|   conv2.conv1             |   0.111M               |   0.177G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (64, 192, 3, 3)     |            |\\n'\n",
      " '|   conv2.bn1               |   0.128K               |   0.205M   |\\n'\n",
      " '|    conv2.bn1.weight       |    (64,)               |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (64,)               |            |\\n'\n",
      " '|  conv3                    |  46.24K                |  0.296G    |\\n'\n",
      " '|   conv3.conv1             |   46.08K               |   0.295G   |\\n'\n",
      " '|    conv3.conv1.weight     |    (80, 64, 3, 3)      |            |\\n'\n",
      " '|   conv3.bn1               |   0.16K                |   1.024M   |\\n'\n",
      " '|    conv3.bn1.weight       |    (80,)               |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (80,)               |            |\\n'\n",
      " '|  up                       |                        |  3.174M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_small.e2400_r224_in1k\", n_classes=80\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 9.658M                 | 3.037G     |\\n'\n",
      " '|  model                    |  8.435M                |  1.708G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    model.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    model.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    model.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    model.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv11.weight           |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (256,)               |            |\\n'\n",
      " '|  conv1                    |  0.59M                 |  0.236G    |\\n'\n",
      " '|   conv1.conv1             |   0.59M                |   0.236G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.512K               |   0.205M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv2                    |  0.295M                |  0.472G    |\\n'\n",
      " '|   conv2.conv1             |   0.295M               |   0.472G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (128, 256, 3, 3)    |            |\\n'\n",
      " '|   conv2.bn1               |   0.256K               |   0.41M    |\\n'\n",
      " '|    conv2.bn1.weight       |    (128,)              |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (128,)              |            |\\n'\n",
      " '|  conv3                    |  92.32K                |  0.591G    |\\n'\n",
      " '|   conv3.conv1             |   92.16K               |   0.59G    |\\n'\n",
      " '|    conv3.conv1.weight     |    (80, 128, 3, 3)     |            |\\n'\n",
      " '|   conv3.bn1               |   0.16K                |   1.024M   |\\n'\n",
      " '|    conv3.bn1.weight       |    (80,)               |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (80,)               |            |\\n'\n",
      " '|  up                       |                        |  5.325M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_medium.e500_r256_in1k\", n_classes=80\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 32.921M                | 6.919G     |\\n'\n",
      " '|  model                    |  31.31M                |  4.521G    |\\n'\n",
      " '|   model.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    model.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   48                   |   3.072M   |\\n'\n",
      " '|    model.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   model.blocks            |   30.078M              |   4.501G   |\\n'\n",
      " '|    model.blocks.0.0       |    25.632K             |    0.167G  |\\n'\n",
      " '|    model.blocks.1         |    0.114M              |    0.241G  |\\n'\n",
      " '|    model.blocks.2         |    3.216M              |    1.358G  |\\n'\n",
      " '|    model.blocks.3         |    26.229M             |    2.685G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.493M              |    49.632M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.246M                |  24.576M   |\\n'\n",
      " '|   conv11.weight           |   (256, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (256,)               |            |\\n'\n",
      " '|  conv1                    |  0.59M                 |  0.236G    |\\n'\n",
      " '|   conv1.conv1             |   0.59M                |   0.236G   |\\n'\n",
      " '|    conv1.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv1.bn1               |   0.512K               |   0.512M   |\\n'\n",
      " '|    conv1.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv1.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv2                    |  0.59M                 |  0.946G    |\\n'\n",
      " '|   conv2.conv1             |   0.59M                |   0.944G   |\\n'\n",
      " '|    conv2.conv1.weight     |    (256, 256, 3, 3)    |            |\\n'\n",
      " '|   conv2.bn1               |   0.512K               |   2.048M   |\\n'\n",
      " '|    conv2.bn1.weight       |    (256,)              |            |\\n'\n",
      " '|    conv2.bn1.bias         |    (256,)              |            |\\n'\n",
      " '|  conv3                    |  0.184M                |  1.182G    |\\n'\n",
      " '|   conv3.conv1             |   0.184M               |   1.18G    |\\n'\n",
      " '|    conv3.conv1.weight     |    (80, 256, 3, 3)     |            |\\n'\n",
      " '|   conv3.bn1               |   0.16K                |   2.56M    |\\n'\n",
      " '|    conv3.bn1.weight       |    (80,)               |            |\\n'\n",
      " '|    conv3.bn1.bias         |    (80,)               |            |\\n'\n",
      " '|  up                       |                        |  8.602M    |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_large.e500_r256_in1k\", n_classes=80\n",
    ")\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convtranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 4.075M                 | 0.867G     |\\n'\n",
      " '|  model                    |  2.493M                |  0.382G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   1.261M               |   0.359G   |\\n'\n",
      " '|    model.blocks.0         |    10.368K             |    66.355M |\\n'\n",
      " '|    model.blocks.1         |    34.112K             |    54.579M |\\n'\n",
      " '|    model.blocks.2         |    0.272M              |    0.126G  |\\n'\n",
      " '|    model.blocks.3         |    0.819M              |    99.181M |\\n'\n",
      " '|    model.blocks.4.0       |    0.125M              |    12.48M  |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.369M                |  36.864M   |\\n'\n",
      " '|   conv11.weight           |   (384, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (384,)               |            |\\n'\n",
      " '|  deconv1                  |  0.787M                |  78.746M   |\\n'\n",
      " '|   deconv1.conv1           |   0.786M               |   78.643M  |\\n'\n",
      " '|    deconv1.conv1.weight   |    (384, 128, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   0.256K               |   0.102M   |\\n'\n",
      " '|    deconv1.bn1.weight     |    (128,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (128,)              |            |\\n'\n",
      " '|  deconv2                  |  0.262M                |  0.105G    |\\n'\n",
      " '|   deconv2.conv1           |   0.262M               |   0.105G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (128, 128, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   0.256K               |   0.41M    |\\n'\n",
      " '|    deconv2.bn1.weight     |    (128,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (128,)              |            |\\n'\n",
      " '|  deconv3                  |  0.164M                |  0.263G    |\\n'\n",
      " '|   deconv3.conv1           |   0.164M               |   0.262G   |\\n'\n",
      " '|    deconv3.conv1.weight   |    (128, 80, 4, 4)     |            |\\n'\n",
      " '|   deconv3.bn1             |   0.16K                |   1.024M   |\\n'\n",
      " '|    deconv3.bn1.weight     |    (80,)               |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (80,)               |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_small.e2400_r224_in1k\",\n",
    "    mode=\"convtranspose\",\n",
    "    n_classes=80,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 12.401M                | 2.912G     |\\n'\n",
      " '|  model                    |  8.435M                |  1.708G    |\\n'\n",
      " '|   model.conv_stem         |   0.864K               |   22.118M  |\\n'\n",
      " '|    model.conv_stem.weight |    (32, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   64                   |   1.638M   |\\n'\n",
      " '|    model.bn1.weight       |    (32,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (32,)               |            |\\n'\n",
      " '|   model.blocks            |   7.202M               |   1.684G   |\\n'\n",
      " '|    model.blocks.0.0       |    43.36K              |    0.278G  |\\n'\n",
      " '|    model.blocks.1         |    59.552K             |    0.144G  |\\n'\n",
      " '|    model.blocks.2         |    1.521M              |    0.657G  |\\n'\n",
      " '|    model.blocks.3         |    5.331M              |    0.581G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.248M              |    24.768M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv11.weight           |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (512,)               |            |\\n'\n",
      " '|  deconv1                  |  2.098M                |  0.21G     |\\n'\n",
      " '|   deconv1.conv1           |   2.097M               |   0.21G    |\\n'\n",
      " '|    deconv1.conv1.weight   |    (512, 256, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   0.512K               |   0.205M   |\\n'\n",
      " '|    deconv1.bn1.weight     |    (256,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (256,)              |            |\\n'\n",
      " '|  deconv2                  |  1.049M                |  0.42G     |\\n'\n",
      " '|   deconv2.conv1           |   1.049M               |   0.419G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (256, 256, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   0.512K               |   0.819M   |\\n'\n",
      " '|    deconv2.bn1.weight     |    (256,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (256,)              |            |\\n'\n",
      " '|  deconv3                  |  0.328M                |  0.525G    |\\n'\n",
      " '|   deconv3.conv1           |   0.328M               |   0.524G   |\\n'\n",
      " '|    deconv3.conv1.weight   |    (256, 80, 4, 4)     |            |\\n'\n",
      " '|   deconv3.bn1             |   0.16K                |   1.024M   |\\n'\n",
      " '|    deconv3.bn1.weight     |    (80,)               |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (80,)               |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_medium.e500_r256_in1k\",\n",
    "    mode=\"convtranspose\",\n",
    "    n_classes=80,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "('| module                    | #parameters or shape   | #flops     |\\n'\n",
      " '|:--------------------------|:-----------------------|:-----------|\\n'\n",
      " '| model                     | 40.848M                | 7.662G     |\\n'\n",
      " '|  model                    |  31.31M                |  4.464G    |\\n'\n",
      " '|   model.conv_stem         |   0.648K               |   16.589M  |\\n'\n",
      " '|    model.conv_stem.weight |    (24, 3, 3, 3)       |            |\\n'\n",
      " '|   model.bn1               |   48                   |   1.229M   |\\n'\n",
      " '|    model.bn1.weight       |    (24,)               |            |\\n'\n",
      " '|    model.bn1.bias         |    (24,)               |            |\\n'\n",
      " '|   model.blocks            |   30.078M              |   4.446G   |\\n'\n",
      " '|    model.blocks.0.0       |    25.632K             |    0.164G  |\\n'\n",
      " '|    model.blocks.1         |    0.114M              |    0.231G  |\\n'\n",
      " '|    model.blocks.2         |    3.216M              |    1.333G  |\\n'\n",
      " '|    model.blocks.3         |    26.229M             |    2.669G  |\\n'\n",
      " '|    model.blocks.4.0       |    0.493M              |    49.344M |\\n'\n",
      " '|   model.conv_head         |   1.229M               |            |\\n'\n",
      " '|    model.conv_head.weight |    (1280, 960, 1, 1)   |            |\\n'\n",
      " '|   model.norm_head         |   2.56K                |            |\\n'\n",
      " '|    model.norm_head.weight |    (1280,)             |            |\\n'\n",
      " '|    model.norm_head.bias   |    (1280,)             |            |\\n'\n",
      " '|  conv11                   |  0.492M                |  49.152M   |\\n'\n",
      " '|   conv11.weight           |   (512, 960, 1, 1)     |            |\\n'\n",
      " '|   conv11.bias             |   (512,)               |            |\\n'\n",
      " '|  deconv1                  |  4.195M                |  0.42G     |\\n'\n",
      " '|   deconv1.conv1           |   4.194M               |   0.419G   |\\n'\n",
      " '|    deconv1.conv1.weight   |    (512, 512, 4, 4)    |            |\\n'\n",
      " '|   deconv1.bn1             |   1.024K               |   0.41M    |\\n'\n",
      " '|    deconv1.bn1.weight     |    (512,)              |            |\\n'\n",
      " '|    deconv1.bn1.bias       |    (512,)              |            |\\n'\n",
      " '|  deconv2                  |  4.195M                |  1.679G    |\\n'\n",
      " '|   deconv2.conv1           |   4.194M               |   1.678G   |\\n'\n",
      " '|    deconv2.conv1.weight   |    (512, 512, 4, 4)    |            |\\n'\n",
      " '|   deconv2.bn1             |   1.024K               |   1.638M   |\\n'\n",
      " '|    deconv2.bn1.weight     |    (512,)              |            |\\n'\n",
      " '|    deconv2.bn1.bias       |    (512,)              |            |\\n'\n",
      " '|  deconv3                  |  0.656M                |  1.05G     |\\n'\n",
      " '|   deconv3.conv1           |   0.655M               |   1.049G   |\\n'\n",
      " '|    deconv3.conv1.weight   |    (512, 80, 4, 4)     |            |\\n'\n",
      " '|   deconv3.bn1             |   0.16K                |   1.024M   |\\n'\n",
      " '|    deconv3.bn1.weight     |    (80,)               |            |\\n'\n",
      " '|    deconv3.bn1.bias       |    (80,)               |            |')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the current dir (i.e. root dir of this repo) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.simple_baseline import MobilenetV4SimpleBaseline\n",
    "\n",
    "from fvcore.nn import (\n",
    "    FlopCountAnalysis,\n",
    "    flop_count_table,\n",
    ")\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=120)  # default width=80, causing early line break\n",
    "\n",
    "model = MobilenetV4SimpleBaseline(\n",
    "    backbone=\"mobilenetv4_conv_large.e500_r256_in1k\", mode=\"convtranspose\", n_classes=80\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "INPUT_SIZE = 320\n",
    "input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "flops = FlopCountAnalysis(model, input)\n",
    "print(\"--------------------\")\n",
    "pp.pprint(flop_count_table(flops))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
